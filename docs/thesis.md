# Введение
Несмотря на рост числа киберугроз и общий уровень осведомленности пользователей,
ответственность за обеспечение безопасности по-прежнему в значительной степени
лежит на специалистах по информационной безопасности. Однако даже они не в
состоянии предусмотреть все возможные векторы атак. При этом существует группа
пользователей — разработчики, которые часто работают с недоверенным кодом и
обладают достаточными знаниями, чтобы, например, отключать некоторые меры защиты
(вроде запрета на копирование команд с sudo), но при этом могут не иметь
глубоких технических знаний в области безопасности. Для них особенно важно иметь
доступ к простым и эффективным средствам изоляции.

Однако существующие решения, такие как Docker, LXC, AppArmor, SELinux,
systemd-nspawn или Podman, изначально проектировались для профессионального
использования — в серверных или корпоративных инфраструктурах. Они предполагают
наличие административных прав, знание внутреннего устройства Linux и часто
требуют предварительной настройки. Более того, многие из них ориентированы не на
запуск отдельных процессов, а на полноценную оркестрацию окружений: с настройкой
томов, сетей, ресурсов, зависимостей, политик безопасности и доступа. В
результате попытка использовать такие инструменты для простой задачи — например,
разовое исполнение небольшого скрипта, скопированного с форума или
сгенерированного нейросетью — приводит к тому, что пользователь либо тратит
неоправданно много времени на настройку, либо отказывается от идеи изоляции
вовсе. Так как он вряд ли будет готов тратить время на чтение документации и
написание конфигурации ради скрипта, который, как ему кажется, будет работать
пару секунд. В результате вопрос изоляции и безопасности откладывается «на
потом» — до первого инцидента.

А так как проблема безопасного исполнения недоверенного кода сегодня стоит не
только перед специалистами в области информационной безопасности, но и перед
широкой аудиторией пользователей, которые регулярно сталкиваются с
необходимостью запускать потенциально опасные программы, то ее решение требует
инструментов новой направленности — достаточно надёжных, чтобы обеспечить
защиту, и достаточно простых, чтобы их было удобно использовать по принципу
«одна команда — и системе ничего не угрожает» (в большинстве случаев).

Целью данной работы является создание удобного в использовании инструмента,
позволяющего запускать недоверенный код в изолированной среде без необходимости
в привилегированных операциях и сложной конфигурации.

Для достижения поставленной цели необходимо решить следующие задачи:
1. Проанализировать существующие инструменты контейнеризации и их ограничения.
1. Определить ключевые требования к программному решению с учетом безопасности и
   удобства использования.
1. Разработать архитектуру программного решения.
1. Реализовать прототип программного решения.
1. Провести тестирование прототипа на соответствие требуемым критериям.


# Обзор существующих решений
Для формирования целостного представления о современных инструментах для
изоляции был проведен первичный сбор данных из нескольких авторитетных
источников. Основой для начального анализа послужили следующие ресурсы:

- [awesome-linux-containers](https://github.com/Friz-zy/awesome-linux-containers)
  — A curated list of awesome Linux Containers frameworks, libraries and
  software
- [awesome-containers](https://github.com/pditommaso/awesome-containers) — A
  curated list of awesome Linux containers related technologies inspired by
  other Awesome lists
- [Open Repository for Container Tools](https://github.com/containers/) — A
  collection of open source tools that create, configure, and work with
  containers

На основании информации из указанных источников была составлена обобщенная
таблица, включающая свыше **восьмидесяти** инструментов, связанных с
изолированным исполнением кода. Для сужения круга анализа использовались три
критерия (на момент 20.04.2025):
1. Популярность проекта: инструмент должен иметь не менее 1к звёзд (stars) на
   GitHub или аналогичной метрикой с другого хостинга — данный показатель, хоть
   и не является абсолютной метрикой качества, отражает уровень внимания
   сообщества.
1. Актуальность разработки: проект не должен находиться в архиве и иметь
   коммиты, слитые PR или решенные issues в течение последнего года — это
   исключает заброшенные и потенциально небезопасные решения.
1. Иметь открытый исходный код - почему.

После фильтрации осталась выборка из инструментов, активно поддерживаемых и
востребованных сообществом, которая представлена в таблице ниже:

| Название   | Звезд | Активность | Описание |
|------------|-------|------------|----------|
| **docker** | 69600 | 2025-04-20 |          |

Из данного списка были отобраны только те инструменты, которые предназначены для
создания изолированных сред исполнения. В него не вошли средства,
специализирующиеся, например, исключительно на мониторинге, аудите, анализе
образов или отладке контейнеров.

Отобранные решения можно классифицировать по назначению и архитектурным
особенностям на четыре основные группы:
1. Контейнерные менеджеры — комплексные системы для управления окружениями;
1. Инструменты с повышенной изоляцией — решения, использующие виртуализацию,
   эмуляцию системных вызовов или другие подходы для усиления безопасности;
1. Средства пользовательской изоляции — утилиты, позволяющие запускать процессы
   в контролируемой среде без дополнительных привилегий;
1. OCI-совместимые рантаймы — низкоуровневые компоненты, обеспечивающие
   исполнение контейнеров в соответствии с Open Container Initiative. Далее
   рассмотрим каждую группу подробнее.

## Контейнерные менеджеры
К этой категории относятся инструменты, которые предоставляют пользователю
полный цикл работы с изолированными окружениями: от создания контейнера до его
запуска, конфигурации, обновления и удаления. Это универсальные решения,
сочетающие в себе механизмы изоляции, управление файловыми системами, настройку
сетей, взаимодействие с реестрами образов и, зачастую, поддержку оркестрации. В
большинстве случаев они ориентированы на производственные среды: серверные,
облачные и корпоративные инфраструктуры, где важны масштабируемость, мониторинг,
сетевые политики и безопасность.

### Docker
Docker был разработан в 2013 году компанией dotCloud (впоследствии
переименованной в Docker Inc.) и за считанные годы стал одной из самых
узнаваемых технологий в мире разработки и эксплуатации программного обеспечения.
Он появился в тот момент, когда индустрия остро нуждалась в стандартизированном
способе упаковывать приложения вместе со всеми зависимостями, не полагаясь на
особенности окружения, в котором они будут запущены. Уже к 2015 году Docker
приобрел массовую популярность, а его экосистема начала стремительно расти:
появились реестры образов, инструменты оркестрации и полноценные
DevOps-платформы, основанные на контейнерах.

Тем не менее, при всех своих достоинствах, Docker не всегда подходит для других
задач — в частности, для изоляции недоверенного кода в пользовательских
сценариях. Архитектура Docker построена вокруг отдельного фонового демона
dockerd, который запускается с привилегиями суперпользователя и управляет всем
процессом запуска контейнеров. Это означает, что даже если команда запускается
от имени обычного пользователя, фактическое выполнение происходит с повышенными
правами, через взаимодействие с демоном.

Кроме того, запуск Docker-контейнера требует установки и настройки самого
Docker, что само по себе может быть нетривиальной задачей, особенно в
дистрибутивах, не имеющих полной поддержки по умолчанию. Пользователю нужно не
только понимать архитектуру образов и слоёв, но и быть готовым к созданию
Dockerfile, настройки сети, томов и прочих параметров. Это резко усложняет его
использование в сценариях, где требуется просто и быстро изолировать выполнение
одного-единственного скрипта. Особенно это чувствуется в пользовательских средах
без прав администратора, где установка Docker попросту невозможна без
вмешательства в системную конфигурацию.

Таким образом Docker оказывается не самым подходящим инструментом для цели,
которая была поставлена в данной работе, безопасного и изолированного выполнения
недоверенного кода в пользовательской среде. Его архитектурные особенности,
требования к привилегиям и относительная тяжеловесность делают его избыточным в
ситуациях, где главную роль играют простота, скорость и отсутствие необходимости
в настройке.

### LXC и LXD
LXC (Linux Containers) появился в 2008 году как первая попытка собрать воедино
все возможности изоляции, которые к тому времени уже были в ядре Linux. Он не
требует гипервизора и позволяет запускать процессы прямо на хост-системе, но
так, будто они работают в собственной, полностью отдельной среде. Это делает LXC
лёгким и быстрым по сравнению с классической виртуализацией — никакой эмуляции
железа, минимум накладных расходов, всё работает почти напрямую.

Сильные стороны LXC чувствуются сразу при первоначальном изучении: это
инструмент, который даёт разработчику или системному инженеру практически полный
контроль. Настроить пользовательские идентификаторы, cgroups, capabilities — всё
доступно и подробно настраивается. Но именно эта свобода и становится
опасностью. Без хорошего понимания устройства Linux быстро наткнешься на
тонкости с правами, безопасностью и взаимодействием между контейнером и хостом.

Кроме того, LXC больше ориентирован на долгоживущие контейнеры — с полноценной
init-системой, постоянным состоянием и отдельной жизнью. Для задач временной
изоляции, например, одноразового запуска подозрительного скрипта, его
использование оказывается слишком сложным, тяжеловесным и избыточным.

Со временем, чтобы упростить работу с LXC, появилась надстройка LXD — более
высокоуровневый инструмент, добавляющий REST API, автоматическую конфигурацию,
управление снапшотами и удобную командную строку. При этом сама архитектура
осталась прежней: LXC и LXD позволяют запускать полноценные «системные»
контейнеры, поведение которых близко к виртуальным машинам. Это особенно удобно
для тестирования, развертывания инфраструктуры или изоляции служб в рамках
одного хоста. Что, к сожалению, не является целью данной работы. Таким образом
LXD не является аналогом, а имеет другой вектор направленности.

### Podman
Podman появился в 2018 году как попытка переосмыслить контейнеризацию с учётом
накопленного опыта и слабых мест Docker. Разработанный Red Hat, он с самого
начала стремился решить два главных недостатка предшественника: необходимость
фонового демона и запуск контейнеров с привилегиями.

На первый взгляд, Podman почти неотличим от Docker — команды те же, поведение
схожее, образы совместимы. Но за внешней схожестью скрывается иная архитектура.
Вместо единого демона, который требует root-доступ и централизованно управляет
контейнерами, Podman запускает каждый контейнер как обычный процесс, от имени
пользователя. Это простое на первый взгляд решение меняет очень многое: оно
устраняет потребность в лишнем фоновом сервисе, уменьшает поверхность атаки и
делает систему более предсказуемой.

Особенно хорошо Podman показывает себя в больших системах: там, где важна
безопасность по умолчанию, где root-доступ ограничен, где контейнеры живут долго
и интегрируются в более сложные цепочки — CI/CD, автоматизация, управляемая
инфраструктура.

Тем не менее, несмотря на более современную архитектуру, Podman остаётся прежде
всего инструментом для разработчиков, инженеров и тех, кто регулярно работает с
контейнерами. Для обычного пользователя, перед которым стоит задача запустить
потенциально опасный скрипт в изолированной среде, Podman всё ещё может
показаться громоздким. Нужно установить зависимости, разобраться с тем, как
именно запускаются rootless-контейнеры, как работают user namespaces, как
правильно монтировать директории и т. д. То есть, даже без демона, это всё ещё
контейнерная платформа — мощная, гибкая, но не мгновенно понятная.

## Инструменты с повышенной безопасностью
В неё попадают решения, в которых изоляция и защита явно приоритетнее
производительности, удобства или совместимости. Они создавались не столько ради
запуска абстрактного «контейнера», сколько ради четкой цели: сделать так, чтобы
изолированный процесс точно не повлиял на систему, даже если он полностью
скомпрометирован.

**gVisor**, разработанный Google, — это не контейнерная система в привычном
смысле, а скорее слой между приложением и ядром Linux. Он реализует собственную
«виртуальную» реализацию системных вызовов, фактически создавая второе,
минимальное ядро, работающее в пространстве пользователя. Процессы не получают
прямого доступа к системным вызовам хоста, все обращения к ядру фильтруются и
обрабатываются gVisor-ом. Такая модель изоляции обеспечивает гораздо более
жёсткий контроль и серьезно снижает вероятность выхода из контейнера, но и дает
о себе знать — она медленнее, требовательнее, сложнее в отладке. Особенно это
чувствуется при запуске чего-то не совсем стандартного или ресурсоемкого. Тем не
менее, для запуска подозрительного кода, где риск важнее скорости, gVisor
оказывается вполне подходящим решением.

**Firecracker**, в свою очередь, — продукт Amazon, созданный специально для
запуска микро виртуальных машин (микро-ВМ) в облаке. В отличие от gVisor, он не
эмулирует ядро, а запускает полноценные виртуальные машины поверх KVM, но делает
это настолько быстро и экономно, что граница между виртуализацией и
контейнеризацией почти стирается. Каждая такая микро-ВМ изолирована аппаратно,
загружается за миллисекунды и почти не требует ресурсов. На выходе — уровень
защиты, сравнимый с полноценной виртуалкой, но со скоростью и лёгкостью
контейнеров. Подход впечатляющий, но и требующий. Для использования Firecracker
нужны права администратора, явное управление образами ядра и root-файловой
системой, понимание архитектуры виртуализации. В повседневной разработке он
скорее избыточен, но для инфраструктуры — идеален.

Таким образом, и gVisor, и Firecracker представляют собой шаг в сторону от
классических контейнеров: они сложнее, но и безопаснее. Если задача требует не
просто изоляции, а доверия к этой изоляции — они одни из лучших кандидатов. Но
обычному пользователю, которому просто нужно «чтобы скрипт не тронул систему»,
они могут показаться чересчур громоздкими и требовательными.

## Контейнерные рантаймы низкого уровня
Контейнерные рантаймы низкого уровня — это инструменты, которые обычно остаются
вне поля зрения, но именно они запускают контейнер. Когда мы используем знакомые
утилиты вроде Docker или Podman, всё в итоге сводится к вызову конкретного
рантайма, который берет на себя всю низкоуровневую работу: создает пространства
имён, настраивает ограничения, монтирует нужные директории и запускает процесс.
Большинство пользователей напрямую с ними не взаимодействуют, но от выбора
рантайма зависит, насколько быстро и безопасно будет работать контейнер.

Первым и до сих пор самым распространённым таким инструментом стал **runc**. Он
был создан как часть Docker, а позже стал отдельным проектом под управлением
Open Container Initiative. Его главная ценность — это стандартизованность.
Практически любая платформа, поддерживающая OCI, совместима с runc.

*crun*

*youki*

Таким образом, все три рантайма решают одну и ту же задачу, но с разным
подходом: runc — стабильный, crun — быстрый, youki — безопасный. Однако они
остаются компонентами инфраструктуры — их использование предполагает, что поверх
есть некий управляющий слой. В отрыве от таких систем они пригодны скорее для
интеграции, чем для самостоятельного применения обычными пользователями.

## Инструменты пользовательской изоляции
Одним из заметных решений в области пользовательской изоляции является
**udocker**. Его основная цель — предоставить возможность запуска контейнеров на
системах, где установка Docker невозможна или нежелательна, в первую очередь — в
пользовательском пространстве, без необходимости обладать административными
правами.

*nsjail*

*firejail*

*apparmor*

*bubblewrap*


# Обзор механизмов контейнеризации
*Тут краткое описание главы*

## Namespaces
Механизм пространств имён (namespaces) в Linux позволяет изолировать различные
аспекты среды выполнения процессов. С его помощью можно добиться того, чтобы
процессы «не видели» остальную часть системы: они получают ограниченный обзор —
свой собственный PID-пространство, файловую систему, сеть, список пользователей
и т. д. (будет рассмотрено позднее) На практике это означает, что процесс может
считать, что он — единственный на системе, тогда как на самом деле изолировано
лишь его окружение.

Пространства имён стали основой для большинства современных решений по
контейнеризации, так как позволяют задать минимальный уровень изоляции без
обращения к полноценной виртуализации.

## cgroups

## seccomp
Seccomp применим к изоляции в более узком смысле: он не скрывает систему, как
namespaces, и не ограничивает ресурсы, как cgroups, а напрямую запрещает
определенные действия. Пример — запрет на выполнение mount, ptrace, clone или
обращения к сетевым интерфейсам. Такой подход особенно полезен при запуске кода
из недоверенных источников, так как минимизирует потенциальный вред даже при
выходе за пределы контейнера.

## selinux

# Linux namespaces
Linux namespaces — это один из ключевых механизмов, лежащих в основе
контейнеризации. Именно благодаря ним процессы в изолированных окружениях могут
«не видеть» друг друга, будто работают на разных машинах, хотя физически
находятся на одном ядре. Это не какая-то новая надстройка, а часть ядра Linux,
развивающаяся уже более двух десятилетий.

Первые шаги в сторону изоляции в Linux начались еще в начале 2000-х годов, но в
полноценную систему пространства имён оформились с появлением CLONE_NEWNS в ядре
2.4.19 (2002 год), а позже начали появляться и остальные. Их развитие шло
постепенно: один namespace — одна изолированная часть системы. Сейчас существует
семь основных пространств имён, каждый из которых отвечает за свою область
изоляции: процессы, пользователи, сеть, монтирование, IPC, hostname и контроль
групп. Всё вместе это позволяет запускать процесс в «песочнице», где у него свои
PID'ы, свои смонтированные директории, своя сеть и даже свой root-пользователь,
не совпадающий с root'ом на хосте.

Интересный исторический момент связан с тем, почему именно namespace
монтирования в системных вызовах обозначается как CLONE_NEWNS, а не, скажем,
CLONE_NEWMOUNT. Всё дело в том, что он был первым реализованным пространством
имен в ядре Linux. На тот момент ещё не существовало общей концепции
"namespaces" как набора взаимосвязанных механизмов — был просто механизм
изоляции точек монтирования, и сокращённое newns (от new namespace) казалось
вполне логичным. Уже позже, когда начали появляться другие типы пространств
имён, их стали именовать более явно: CLONE_NEWPID, CLONE_NEWNET, CLONE_NEWUSER и
так далее.

Основная идея namespaces — дать процессу иллюзию того, что он находится в
собственной системе. При этом, в отличие от виртуальных машин, здесь нет полной
эмуляции: ядро одно, ресурсы общие, а изоляция реализована средствами самого
ядра, что делает такую модель намного более легкой и быстрой.

Благодаря этому namespaces стали основой для таких инструментов, как Docker,
LXC, Podman, Firejail, Bubblewrap и многих других. Они позволяют запускать
процессы в контейнерах без виртуализации и без необходимости поднимать отдельную
ОС. Более того, namespaces можно использовать напрямую — например, с помощью
unshare или более удобных оберток.

## User
User namespace — один из ключевых механизмов изоляции в Linux, появившийся в
ядре 3.8. Он позволяет процессам внутри изолированной среды иметь другие
идентификаторы пользователя и групп, чем на хосте. Благодаря этому обычный
пользователь может запустить процесс с правами root внутри контейнера, не
получая настоящего root-доступа на системе. Другими словами, он позволяет
запускать «привилегированные» процессы в изолированной среде, где эти привилегии
действуют только внутри и не имеют силы за её пределами.

Эта особенность открыла дорогу так называемым rootless-контейнерам —
контейнерам, которые можно запускать без административных прав. Именно user
namespace делает возможной изоляцию, не требующую вмешательства системного
администратора, что особенно важно в пользовательских и десктопных сценариях.

На практике он часто используется вместе с другими пространствами имён,
поскольку доступ к ним (например, к монтированию файловых систем или созданию
собственных PID-деревьев) тоже требует user namespace.

## Mount
Mount namespace даёт каждому контейнеру своё собственное представление о том,
как устроена файловая система. Это позволяет перенастроить точки монтирования
так, чтобы процессы внутри видели только то, что им разрешено, и в том виде, в
каком это задумал автор окружения. Директории можно подменить, сделать
доступными только для чтения, заменить на временные или вообще исключить — всё
это будет касаться только контейнера, а хост же останется нетронутым. Один и тот
же файл но в разных пространствах имен может оказаться в совершенно разных
местах, с разными правами и даже под разными именами.

В Linux, где почти всё — это файл: устройства, процессы, сокеты, настройки —
возможность контролировать, какие именно файлы видны и как они доступны,
оказывается критически важной. Неудивительно, что именно mount namespace
появился первым: он дает очень точный и мощный инструмент управления средой
исполнения.

## UTS
UTS namespace отвечает за изоляцию идентификаторов хоста — имени машины
(hostname) и домена (domainname). Это может показаться несущественным по
сравнению с пространствами имён, которые изолируют процессы или файловую
систему, но на практике дает важную гибкость. Это удобно и для организации
логов, и для отладки, и просто для визуального разделения сред.

## PID
PID namespace изолирует процессы: внутри него каждый запущенный процесс получает
собственный идентификатор, независимый от остальной системы. Это значит, что
контейнер не только не будет иметь доступа к процессам за пределами своего
пространства имен, но и также даже не знать о их существовании.

Особенно важно то, что внутри такого namespace можно создать собственное дерево
процессов с отдельным init-процессом (обычно с PID 1), который будет выполнять
те же функции, что и в полноценной системе — обрабатывать сигналы, управлять
жизненным циклом дочерних процессов и так далее. Это приближает поведение
контейнера к виртуальной машине, но без всей тяжести гипервизоров.

## Network
Network namespace позволяет каждому контейнеру иметь собственный сетевой стек.
Это значит, что у него будут свои интерфейсы, таблицы маршрутизации, правила
iptables, сокеты и даже отдельный экземпляр loopback-интерфейса (lo). В
результате контейнер можно отключить от сети вовсе, подключить к виртуальному
мосту, настроить NAT или дать прямой доступ к физическому интерфейсу — всё это
делается независимо от основной системы.

Такой подход особенно удобен для сценариев, где важно контролировать, с кем и
как общается запущенный процесс. Например, можно запустить подозрительное
приложение с полной изоляцией от интернета, сохранив при этом доступ к локальным
файлам. Или наоборот — дать выход в сеть, но запретить доступ к внутренним
сервисам хоста

## IPC
IPC namespace отвечает за изоляцию механизмов межпроцессного взаимодействия —
таких как очереди сообщений, семафоры и общая память. Без него процессы внутри
разных контейнеров могут влиять друг друга, использовать одни и те же участки
памяти или вмешиваться в чужие взаимодействия. Это может привести не только к
ошибкам, но и к серьезным уязвимостям.

Когда используется отдельный IPC namespace, каждый контейнер получает
собственное пространство для таких объектов, полностью отделенное от остальной
системы. Это особенно важно, если в контейнере работает что-то чувствительное к
совместному доступу — например, PostgreSQL или Redis.


# Проектирование архитектуры
*Тут краткое описание главы*

## Выбор инструментов изоляции
*Тут краткое описание раздела*

В первую очередь внимание падает на LXC. Это зрелое решение, позволяющее
разворачивать контейнеры, близкие по поведению к полноценным системам. У него
широкие возможности: отдельная сеть, снапшоты, интеграция с init-системой. Но
всё это сказывается на использовании — LXC рассчитан на долгоживущие контейнеры,
где важна устойчивость и контроль. В контексте кратковременных изолированных
процессов — это уже лишнее.

AppArmor использует другой подход. Это не контейнер, не песочница, а скорее
фильтр — он описывает, к каким ресурсам может обращаться программа. Это мощный
механизм, особенно в сочетании с остальной политикой безопасности системы. Но
для динамического запуска или гибкой настройки под каждый новый скрипт он
подходит плохо. Профили создаются отдельно, требуют установки с правами
администратора и не меняются на лету. Его применение имеет смысл тогда, когда
известно поведение программы и оно не будет меняться.

Всё это подводит к bubblewrap. Этот инструмент выделяется на фоне остальных
своей минималистичной моделью: никаких конфигов, никаких профилей, только
командная строка, в которой напрямую указывается, какие изоляции применить. Он
создавался как часть Flatpak и ориентирован на запуск приложений от обычного
пользователя, без привлечения root. Это делает его особенно подходящим для
задач, где хочется жестко ограничить процесс, но не вовлекать лишнюю сложность.
Пространства имён, tmpfs, readonly точки монтирования , ограничение доступа —
всё явно прописывается при запуске.

## Выбор языка программирования
Когда базовая технология изоляции определена — в данном случае это Bubblewrap —
остаётся решить, каким образом строить вокруг нее удобную оболочку. Сам
Bubblewrap — это утилита командной строки, и взаимодействие с ней всегда
сводится к вызову процесса с набором параметров. Подход прямой, но быстро
становится громоздким: количество флагов растёт, логика усложняется, а
необходимость реагировать на разные сценарии требует хоть какой-то структуры.

На этом этапе становится ясно, что нужен язык, в котором можно было бы быстро
собрать утилиту, обрабатывающую аргументы, управляя логикой подготовки окружения
и запуском. Python оказался уместным выбором. Он легко читается, стандартная
библиотека закрывает почти все базовые потребности — от работы с путями и
файлами до запуска процессов и логирования. Никакой дополнительной сборки или
компиляции не требуется, зависимости минимальны, запуск возможен на большинстве
современных Linux-систем без установки дополнительных компонентов, Python чаще
всего входит в стандартную поставку.

Это не самый производительный инструмент, но в этой задаче и не требуется
высокая производительность, так как это не CPU-bound задача. Гораздо важнее
простота изменений и прозрачность логики.

### argparse
argparse — стандартный инструмент для обработки аргументов командной строки.
Главное удобство в том, что логика определения и логика разбора аргументов
объединяются в одном месте: один раз описываются флаги, типы значений, что
является обязательным, а что — опциональным. Дальше argparse сам разбирает всё
на нужные элементы, проверяет корректность, выдает ошибки при неверном вводе и
даже генерирует справку, которую не нужно писать отдельно, что намного удобнее
чем обрабатывать sys.argv вручную. Такой подход не только делает код короче, но
и заметно снижает шанс допустить ошибку в обработке пользовательского ввода.

Кроме этого, argparse полезен в архитектуре, где параметры можно задавать не
только для одной команды, но и как составные части — например, с флагами,
которые активируют разные режимы работы. Учитывая, что основа инструмента
строится вокруг запуска изолированных окружений с множеством вариантов — таких
как  приватный том, оверлей, сохранение состояния, удаление и т. д. — без
чёткого описания структуры командной строки всё быстро деградировало бы в сложно
поддерживаемую кодовую базу с множеством условных операторов.

### shlex
shlex, в отличие от argparse, работает на другом уровне — он парсит строки в
формате shell. Это удобно, если некоторые параметры передаются как готовый кусок
командной строки, который нужно разложить на отдельные аргументы, чтобы
корректно обработать дополнительные флаги, которые нужно просто передать дальше
без вмешательства. Потому что независимо от того, насколько много сценариев
использования можно предусмотреть, не стоит ограничивать пользователя, который
умеет работать с linux namespaces, от более точной настройки окружения.

### logging
Отладка инструментов, работающих с пространствами имён, монтированием, правами и
запуском других процессов — задача не тривиальная. Когда поведение процесса
зависит не только от входных аргументов, но и от состояния окружения, порядка
вызовов и других малозначительных деталей, вывод на stdout или простые print()
быстро перестают быть удобными. Для таких случаев и существует logging.

Он позволяет управлять уровнем сообщений: во время разработки можно включить
подробный отладочный режим, а в стабильной сборке — оставить только
предупреждения и ошибки. Всё это без переписывания кода. Вместо того чтобы раз
за разом закомментировать строки с отладочным выводом, достаточно поменять
уровень логирования — и инструмент становится тише.

Кроме того, можно точно настроить формат сообщений: добавить время, имя файла,
строку, уровень важности. Это особенно полезно, если лог пишется в файл или
используется в CI. В случае ошибок будет видно не только что пошло не так, но и
где именно, и при каких условиях.

### sys, os, shutil, Path
Работа с окружением на низком уровне редко обходится без стандартных библиотек
sys, os, shutil и pathlib. Все они решают разные задачи, и каждая из них дает
удобный доступ к какой-то стороне взаимодействия с операционной системой.

sys — один из самых базовых модулей. Он нужен для работы с аргументами командной
строки, завершения программы с нужным кодом или, например, перенаправления
вывода ошибок. Никакой логики, только прямое взаимодействие с механизмами,
которые предоставляет сам интерпретатор.

os — это удобная обертка над API операционной системы. Работа с переменными
окружения, запуск внешних процессов, создание директорий, установка прав — всё
это делается через эту библиотеку. Именно os даёт доступ к системным вызовам,
которые не обернуты в более высокоуровневые модули.

shutil предоставляет удобные функции для работы с файлами и каталогами,
значительно упрощая такие операции, когда требуется выполнить более сложные
действия с файлами, которые выходят за рамки базовых возможностей os, такие как
рекурсивное удаление, копирование и перемещение директорий.

Наконец, Path из модуля pathlib — современная альтернатива привычной работе со
строковыми путями. Вместо склеивания с os.path.join или разборов вручную, Path
позволяет манипулировать файловой системой как с объектами. Путь становится не
просто строкой, а полноценным элементом логики. Это упрощает код, делает его
читаемее и меньше подверженным ошибкам. Особенно, если путь нужно не просто
напечатать, а проверить, создать или что-то в нём найти.

