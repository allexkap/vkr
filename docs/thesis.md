# Введение
Несмотря на рост числа киберугроз и общий уровень осведомленности пользователей,
ответственность за обеспечение безопасности по-прежнему в значительной степени
лежит на специалистах по информационной безопасности. Однако даже они не в
состоянии предусмотреть все возможные векторы атак. При этом существует группа
пользователей — разработчики, которые часто работают с недоверенным кодом и
обладают достаточными знаниями, чтобы, например, отключать некоторые меры защиты
(вроде запрета на копирование команд с sudo), но при этом могут не иметь
глубоких технических знаний в области безопасности. Для них особенно важно иметь
доступ к простым и эффективным средствам изоляции.

Однако существующие решения, такие как Docker, LXC, AppArmor, SELinux,
systemd-nspawn или Podman, изначально проектировались для профессионального
использования — в серверных или корпоративных инфраструктурах. Они предполагают
наличие административных прав, знание внутреннего устройства Linux и часто
требуют предварительной настройки. Более того, многие из них ориентированы не на
запуск отдельных процессов, а на полноценную оркестрацию окружений: с настройкой
томов, сетей, ресурсов, зависимостей, политик безопасности и доступа. В
результате попытка использовать такие инструменты для простой задачи — например,
разовое исполнение небольшого скрипта, скопированного с форума или
сгенерированного нейросетью — приводит к тому, что пользователь либо тратит
неоправданно много времени на настройку, либо отказывается от идеи изоляции
вовсе. Так как он вряд ли будет готов тратить время на чтение документации и
написание конфигурации ради скрипта, который, как ему кажется, будет работать
пару секунд. В результате вопрос изоляции и безопасности откладывается «на
потом» — до первого инцидента.

А так как проблема безопасного исполнения недоверенного кода сегодня стоит не
только перед специалистами в области информационной безопасности, но и перед
широкой аудиторией пользователей, которые регулярно сталкиваются с
необходимостью запускать потенциально опасные программы, то ее решение требует
инструментов новой направленности — достаточно надёжных, чтобы обеспечить
защиту, и достаточно простых, чтобы их было удобно использовать по принципу
«одна команда — и системе ничего не угрожает» (в большинстве случаев).

Целью данной работы является создание удобного в использовании инструмента,
позволяющего запускать недоверенный код в изолированной среде без необходимости
в привилегированных операциях и сложной конфигурации.

Для достижения поставленной цели необходимо решить следующие задачи:
1. Проанализировать существующие инструменты контейнеризации и их ограничения.
1. Определить ключевые требования к программному решению с учетом безопасности и
   удобства использования.
1. Разработать архитектуру программного решения.
1. Реализовать прототип программного решения.
1. Провести тестирование прототипа на соответствие требуемым критериям.


# Обзор существующих решений
Для формирования целостного представления о современных инструментах для
изоляции был проведен первичный сбор данных из нескольких авторитетных
источников. Основой для начального анализа послужили следующие ресурсы:

- [awesome-linux-containers](https://github.com/Friz-zy/awesome-linux-containers)
  — A curated list of awesome Linux Containers frameworks, libraries and
  software
- [awesome-containers](https://github.com/pditommaso/awesome-containers) — A
  curated list of awesome Linux containers related technologies inspired by
  other Awesome lists
- [Open Repository for Container Tools](https://github.com/containers/) — A
  collection of open source tools that create, configure, and work with
  containers

На основании информации из указанных источников была составлена обобщенная
таблица, включающая свыше **восьмидесяти** инструментов, связанных с
изолированным исполнением кода. Для сужения круга анализа использовались три
критерия (на момент 20.04.2025):
1. Популярность проекта: инструмент должен иметь не менее 1к звёзд (stars) на
   GitHub или аналогичной метрикой с другого хостинга — данный показатель, хоть
   и не является абсолютной метрикой качества, отражает уровень внимания
   сообщества.
1. Актуальность разработки: проект не должен находиться в архиве и иметь
   коммиты, слитые PR или решенные issues в течение последнего года — это
   исключает заброшенные и потенциально небезопасные решения.
1. Иметь открытый исходный код - почему.

После фильтрации осталась выборка из инструментов, активно поддерживаемых и
востребованных сообществом, которая представлена в таблице ниже:

| Название   | Звезд | Активность | Описание |
|------------|-------|------------|----------|
| **docker** | 69600 | 2025-04-20 |          |

Из финального списка были отобраны только те инструменты, которые предназначены
для создания изолированных сред исполнения. В него не вошли средства,
специализирующиеся исключительно на мониторинге, аудите, анализе образов или
отладке контейнеров.

Отобранные решения можно классифицировать по назначению и архитектурным
особенностям на четыре основные группы:
1. Контейнерные менеджеры — комплексные системы для управления окружениями;
1. Инструменты с повышенной изоляцией — решения, использующие виртуализацию,
   эмуляцию системных вызовов или другие подходы для усиления безопасности;
1. Средства пользовательской изоляции — утилиты, позволяющие запускать процессы
   в контролируемой среде без дополнительных привилегий;
1. OCI-совместимые рантаймы — низкоуровневые компоненты, обеспечивающие
   исполнение контейнеров в соответствии с Open Container Initiative. Далее
   рассмотрим каждую группу подробнее.

## Контейнерные менеджеры
К этой категории относятся инструменты, которые предоставляют пользователю
полный цикл работы с изолированными окружениями: от создания контейнера до его
запуска, конфигурации, обновления и удаления. Это универсальные решения,
сочетающие в себе механизмы изоляции, управление файловыми системами, настройку
сетей, взаимодействие с реестрами образов и, зачастую, поддержку оркестрации. В
большинстве случаев они ориентированы на производственные среды: серверные,
облачные и корпоративные инфраструктуры, где важны масштабируемость, мониторинг,
сетевые политики и безопасность.

### Docker
Docker был разработан в 2013 году компанией dotCloud (впоследствии
переименованной в Docker Inc.) и за считанные годы стал одной из самых
узнаваемых технологий в мире разработки и эксплуатации программного обеспечения.
Он появился в тот момент, когда индустрия остро нуждалась в стандартизированном
способе упаковывать приложения вместе со всеми зависимостями, не полагаясь на
особенности окружения, в котором они будут запущены. Уже к 2015 году Docker
приобрел массовую популярность, а его экосистема начала стремительно расти:
появились реестры образов, инструменты оркестрации и полноценные
DevOps-платформы, основанные на контейнерах.

Тем не менее, при всех своих достоинствах, Docker не всегда подходит для других
задач — в частности, для изоляции недоверенного кода в пользовательских
сценариях. Архитектура Docker построена вокруг отдельного фонового демона
dockerd, который запускается с привилегиями суперпользователя и управляет всем
процессом запуска контейнеров. Это означает, что даже если команда запускается
от имени обычного пользователя, фактическое выполнение происходит с повышенными
правами, через взаимодействие с демоном.

Кроме того, запуск Docker-контейнера требует установки и настройки самого
Docker, что само по себе может быть нетривиальной задачей, особенно в
дистрибутивах, не имеющих полной поддержки по умолчанию. Пользователю нужно не
только понимать архитектуру образов и слоёв, но и быть готовым к созданию
Dockerfile, настройки сети, томов и прочих параметров. Это резко усложняет его
использование в сценариях, где требуется просто и быстро изолировать выполнение
одного-единственного скрипта. Особенно это чувствуется в пользовательских средах
без прав администратора, где установка Docker попросту невозможна без
вмешательства в системную конфигурацию.

Таким образом Docker оказывается не самым подходящим инструментом для цели,
которая была поставлена в данной работе, безопасного и изолированного выполнения
недоверенного кода в пользовательской среде. Его архитектурные особенности,
требования к привилегиям и относительная тяжеловесность делают его избыточным в
ситуациях, где главную роль играют простота, скорость и отсутствие необходимости
в настройке.

### LXC и LXD
LXC (Linux Containers) появился в 2008 году как первая попытка собрать воедино
все возможности изоляции, которые к тому времени уже были в ядре Linux. Он не
требует гипервизора и позволяет запускать процессы прямо на хост-системе, но
так, будто они работают в собственной, полностью отдельной среде. Это делает LXC
лёгким и быстрым по сравнению с классической виртуализацией — никакой эмуляции
железа, минимум накладных расходов, всё работает почти напрямую.

Сильные стороны LXC чувствуются сразу при первоначальном изучении: это
инструмент, который даёт разработчику или системному инженеру практически полный
контроль. Настроить пользовательские идентификаторы, cgroups, capabilities — всё
доступно и подробно настраивается. Но именно эта свобода и становится
опасностью. Без хорошего понимания устройства Linux быстро наткнешься на
тонкости с правами, безопасностью и взаимодействием между контейнером и хостом.

Кроме того, LXC больше ориентирован на долгоживущие контейнеры — с полноценной
init-системой, постоянным состоянием и отдельной жизнью. Для задач временной
изоляции, например, одноразового запуска подозрительного скрипта, его
использование оказывается слишком сложным, тяжеловесным и избыточным.

Со временем, чтобы упростить работу с LXC, появилась надстройка LXD — более
высокоуровневый инструмент, добавляющий REST API, автоматическую конфигурацию,
управление снапшотами и удобную командную строку. При этом сама архитектура
осталась прежней: LXC и LXD позволяют запускать полноценные «системные»
контейнеры, поведение которых близко к виртуальным машинам. Это особенно удобно
для тестирования, развертывания инфраструктуры или изоляции служб в рамках
одного хоста. Что, к сожалению, не является целью данной работы. Таким образом
LXD не является аналогом, а имеет другой вектор направленности.

### podman
Podman появился в 2018 году как попытка переосмыслить контейнеризацию с учётом
накопленного опыта и слабых мест Docker. Разработанный Red Hat, он с самого
начала стремился решить два главных недостатка предшественника: необходимость
фонового демона и запуск контейнеров с привилегиями.

На первый взгляд, Podman почти неотличим от Docker — команды те же, поведение
схожее, образы совместимы. Но за внешней схожестью скрывается иная архитектура.
Вместо единого демона, который требует root-доступ и централизованно управляет
контейнерами, Podman запускает каждый контейнер как обычный процесс, от имени
пользователя. Это простое на первый взгляд решение меняет очень многое: оно
устраняет потребность в лишнем фоновом сервисе, уменьшает поверхность атаки и
делает систему более предсказуемой.

Особенно хорошо Podman показывает себя в больших системах: там, где важна
безопасность по умолчанию, где root-доступ ограничен, где контейнеры живут долго
и интегрируются в более сложные цепочки — CI/CD, автоматизация, управляемая
инфраструктура.

Тем не менее, несмотря на более современную архитектуру, Podman остаётся прежде
всего инструментом для разработчиков, инженеров и тех, кто регулярно работает с
контейнерами. Для обычного пользователя, перед которым стоит задача запустить
потенциально опасный скрипт в изолированной среде, Podman всё ещё может
показаться громоздким. Нужно установить зависимости, разобраться с тем, как
именно запускаются rootless-контейнеры, как работают user namespaces, как
правильно монтировать директории и т. д. То есть, даже без демона, это всё ещё
контейнерная платформа — мощная, гибкая, но не мгновенно понятная.
