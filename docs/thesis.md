# Список сокращений и условных обозначений
**API** – Application Programming Interface  
**CI** – Continuous Integration  
**CLI** – Command-Line Interface  
**CPU** – Central Processing Unit  
**GNU** – GNU's Not UNIX  
**GUI** – Graphical User Interface  
**IPC** – Inter-Process Communication  
**KVM** – Kernel-based Virtual Machine  
**LXC** – Linux Containers  
**LXD** – Linux Container Daemon  
**NAT** – Network Address Translation  
**OCI** – Open Container Initiative  
**PID** – Process Identifier  
**PyPI** – Python Package Index  
**REST** – Representational State Transfer  
**SSH** – Secure Shell  
**SUID** – Set User Identifier  
**UID** – User Identifier  
**UTS** – UNIX Time-sharing System  
**VM** – Virtual Machine


# Термины и определения
**CPU bound** – тип задачи, при котором производительность ограничена скоростью
процессора  
**Loopback** – виртуальный сетевой интерфейс, используемый для связи с самим
собой  
**Rootless** – режим работы, не требующий прав суперпользователя  
**Виртуализация** – создание логически изолированных сред на одной физической
машине  
**Гипервизор** – программа, управляющая виртуальными машинами и распределяющая
ресурсы между ними  
**Демон** – фоновый процесс, работающий без участия пользователя  
**Дистрибутив** – готовый к установке комплект программного обеспечения на базе
ядра, включающий системные утилиты, менеджер пакетов и конфигурацию по умолчанию  
**Изоляция** – разделение процессов, ресурсов или окружений таким образом, чтобы
они не влияли друг на друга и не имели прямого доступа к данным вне своей среды  
**Контейнер** – изолированная среда для запуска приложения с его зависимостями  
**Монтирование** – подключение файловой системы или директории в структуру
основной файловой системы для доступа к ее содержимому  
**Оркестрация** – координация и контроль жизненного цикла компонентов приложений
в распределенной среде с учетом зависимостей, масштабирования и
отказоустойчивости  
**Рантайм** – среда выполнения  
**Сокет** – конченая точка для сетевого обмена данными между процессами  
**Фреймворк** – набор библиотек и инструментов, задающий структуру и шаблон для
разработки  
**Эксплойт** – код или техника, использующая уязвимость в системе для получения
доступа или выполнения действий  
**Эмуляция** – воспроизведение поведения одной системы средствами другой


# Введение
Несмотря на рост числа киберугроз и общий уровень осведомленности пользователей,
ответственность за обеспечение безопасности по-прежнему в значительной степени
лежит на специалистах по информационной безопасности. Однако даже они не в
состоянии предусмотреть все возможные векторы атак. При этом существует группа
пользователей – разработчики, которые часто работают с недоверенным кодом и
обладают достаточными знаниями, чтобы, например, отключать некоторые меры защиты
(вроде запрета на копирование команд с sudo), но при этом могут не иметь
глубоких технических знаний в области безопасности.

Существующие решения, такие как Docker, LXC, AppArmor или Podman, изначально
проектировались для профессионального использования – в серверных или
корпоративных инфраструктурах. Они предполагают наличие повышенных привилегий,
знание внутреннего устройства Linux и часто требуют предварительной настройки.
Более того, многие из них ориентированы не на запуск отдельных процессов, а на
полноценную оркестрацию окружений: с настройкой томов, сетей, ресурсов,
зависимостей, политик безопасности и доступа.

В результате попытка использовать такие инструменты для простой задачи –
например, разовое исполнение небольшого скрипта, скопированного с форума или
сгенерированного нейросетью – приводит к тому, что пользователь отказывается от
идеи изоляции вовсе. Так как он вряд ли будет готов тратить неоправданно много
времени на чтение документации и написание конфигурации ради скрипта, который,
как ему кажется, будет работать пару секунд. В результате вопрос изоляции и
безопасности откладывается «на потом» – до первого инцидента.

А так как проблема безопасного исполнения недоверенного кода сегодня стоит не
только перед специалистами в области информационной безопасности, но и перед
широкой аудиторией пользователей, которые регулярно сталкиваются с
необходимостью запускать потенциально опасные программы, то ее решение требует
инструментов новой направленности – достаточно надежных, чтобы обеспечить
защиту, и достаточно простых, чтобы их было удобно использовать по принципу
«одна команда – и системе ничего не угрожает» (в большинстве случаев).

Целью данной работы является повышение пользовательской безопасности за счет
создания инструмента запуска недоверенного кода в изолированной среде без
необходимости в использовании привилегированных операций.

Для достижения поставленной цели необходимо решить следующие задачи:
1. Проанализировать существующие инструменты контейнеризации и их ограничения.
1. Определить ключевые требования к программному решению с учетом безопасности и
   удобства использования.
1. Разработать программное решение и провести его тестирование.
1. Провести сравнение разработанного решения с существующими аналогами.


# Обзор существующих решений
Для формирования целостного представления о современных инструментах для
изоляции был проведен первичный сбор данных из нескольких авторитетных
источников. Основой для начального анализа послужили следующие ресурсы:

- awesome-linux-containers – Подборка фреймворков, библиотек и программного
  обеспечения для Linux-контейнеров;
- awesome-containers – Подборка технологий, связанных с Linux-контейнерами,
  вдохновленная другими «Awesome» списками;
- Open Repository for Container Tools – Коллекция инструментов с открытым
  исходным кодом для создания, настройки и работы с контейнерами.

На основании информации из указанных источников была составлена обобщенная
таблица, включающая свыше восьмидесяти инструментов, связанных с изолированным
исполнением кода. Для сужения круга анализа использовались три критерия,
значения которых в работе зафиксированы на момент 20.04.2025:

- Популярность проекта оценивается с использованием открытых количественных
  метрик, таких как количество звезд (число пользователей, добавивших проект в
  избранное) на GitHub или аналогичных показателей на других платформах. Эти
  метрики отражают уровень вовлеченности и интереса сообщества к проекту.
- Актуальность разработки: проект не должен находиться в архиве и иметь
  коммиты, слитые PR или решенные проблемы (issues) в течение последнего года –
  это исключает заброшенные и потенциально небезопасные решения.
- Открытый исходный код – это позволяет обеспечить прозрачность, проверяемость
  и возможность модификации кода сообществом, что критично для доверия и
  долгосрочной поддержки инструментов.

После фильтрации получилась выборка инструментов. Она представлена в таблице 1.

Таблица 1 – Отфильтрованный список инструментов
| Название   | Звезд | Активность | Описание |
|------------|-------|------------|----------|
| **docker** | 69600 | 2025-04-20 |          |

Из данного списка были отобраны только те инструменты, основной задачей которых
является создание изолированной среды исполнения. Средства, предназначенные
исключительно для вспомогательных задач – таких как аудит, мониторинг, отладка
или анализ контейнеров – в обзор не включались.

Отобранные инструменты можно условно разделить на несколько групп. Первую
составляют полноценные системы управления контейнерами. Эти инструменты
предоставляют полный цикл работы с контейнерами: от подготовки образов до
управления жизненным циклом окружений.

Во вторую входят решения, сфокусированные на безопасности. Они применяют
аппаратную или программную изоляцию, моделируют системные вызовы или используют
собственные интерфейсы, снижая вероятность выхода процесса за пределы
контролируемого пространства.

Третья – низкоуровневые инструменты, соответствующие спецификации OCI, которые
не управляют окружением целиком, а отвечают только за непосредственный запуск
контейнера в уже подготовленной среде.

Инструменты из каждой группы решают свои задачи и подходят под разные сценарии,
рассмотрим их дальше по отдельности.

## Контейнерные менеджеры
Такие решения, как Docker, LXC/LXD и Podman, выходят за рамки задач изоляции как
таковой – они предоставляют полноценную инфраструктуру для упаковки, запуска и
управления приложениями в контейнерной среде. Их пользователь получает развитую
экосистему – от форматов образов и репозиториев до инструментов сетевой
настройки, логирования и мониторинга.

### Docker
Docker был разработан в 2013 году компанией dotCloud (впоследствии
переименованной в Docker Inc.) и за считанные годы стал одной из самых
узнаваемых технологий в мире разработки и эксплуатации программного обеспечения.
Он появился в тот момент, когда индустрия остро нуждалась в стандартизированном
способе упаковывать приложения вместе со всеми зависимостями, не полагаясь на
особенности окружения, в котором они будут запущены. Уже к 2015 году Docker
приобрел массовую популярность, а его экосистема начала стремительно расти:
появились реестры образов, инструменты оркестрации и полноценные
DevOps-платформы, основанные на контейнерах.

Тем не менее, при всех своих достоинствах, таких как высокая популярность и
экосистема, удобство использования, поддержка образов, оркестрация,
портируемость и стандартизация рабочих процессов, Docker не всегда подходит для
других задач – в частности, для изоляции недоверенного кода в пользовательских
сценариях. Архитектура Docker построена вокруг отдельного фонового демона
dockerd, который запускается с привилегиями суперпользователя и управляет всем
процессом запуска контейнеров.

Также в пользовательских средах без прав администратора, установка Docker
попросту невозможна без вмешательства в системную конфигурацию. Все
вышеперечисленное резко усложняет его использование в сценариях, где требуется
просто и быстро изолировать выполнение одного единственного скрипта.

### LXC и LXD
LXC (Linux Containers) появился в 2008 году как первая попытка собрать воедино
все возможности изоляции, которые к тому времени уже были в ядре Linux. Он не
требует гипервизора и позволяет запускать процессы прямо на хост-системе, но
так, будто они работают в собственной, полностью отдельной среде. Это делает LXC
легким и быстрым по сравнению с классической виртуализацией – никакой эмуляции
железа, минимум накладных расходов.

Сильные стороны LXC видны сразу при первоначальном изучении: это инструмент,
который дает разработчику или системному инженеру практически полный контроль.
Настроить пользовательские идентификаторы, cgroups, capabilities – все доступно
и подробно настраивается. Но именно эта свобода и становится опасностью. Без
глубокого знания Linux неизбежно возникнут сложности с правами, безопасностью и
интеграцией контейнера с хост-системой.

Кроме того, LXC больше ориентирован на долгоживущие контейнеры – с полноценной
init-системой и постоянным состоянием. Для задач временной изоляции, например,
одноразового запуска подозрительного скрипта, его использование оказывается
слишком сложным, тяжеловесным и избыточным.

Со временем, чтобы упростить работу с LXC, появился LXD (Linux Container Daemon)
– более высокоуровневый инструмент, добавляющий REST API, автоматическую
конфигурацию, управление снапшотами и удобную командную строку. При этом сама
архитектура осталась прежней: LXC и LXD позволяют запускать полноценные
«системные» контейнеры, поведение которых близко к виртуальным машинам.

### Podman
Podman появился в 2018 году как попытка переосмыслить контейнеризацию с учетом
накопленного опыта и слабых мест Docker. Разработанный Red Hat, он с самого
начала стремился решить два главных недостатка предшественника: необходимость
фонового демона и запуск контейнеров с привилегиями.

На первый взгляд, Podman почти неотличим от Docker – команды те же, поведение
схожее, образы совместимы. Но за внешней схожестью скрывается иная архитектура.
Вместо единого демона, который требует root-доступ и централизованно управляет
контейнерами, Podman запускает каждый контейнер как обычный процесс, от имени
пользователя. Это простое на первый взгляд решение меняет очень многое: оно
устраняет потребность в лишнем фоновом сервисе, уменьшает поверхность атаки и
делает систему более предсказуемой.

Особенно хорошо Podman показывает себя в системах: где важна безопасность по
умолчанию, где root-доступ ограничен, где контейнеры живут долго и интегрируются
в более сложные цепочки – CI/CD, автоматизация, управляемая инфраструктура.

Тем не менее, несмотря на более современную архитектуру, Podman остается прежде
всего инструментом для разработчиков, инженеров и тех, кто регулярно работает с
контейнерами. Для обычного пользователя, перед которым стоит задача запустить
потенциально опасный скрипт в изолированной среде, Podman все еще может
показаться громоздким. Нужно установить зависимости, разобраться с тем, как
именно запускаются rootless-контейнеры, как работают user namespaces, как
правильно монтировать директории и т. д. То есть, даже без демона, это все еще
контейнерная платформа – мощная, гибкая, но не очевидно понятная.

## Инструменты с усиленной безопасностью
gVisor, разработанный Google, – реализует собственную «виртуальную» реализацию
системных вызовов, фактически создавая второе, минимальное ядро, работающее в
пространстве пользователя. Процессы не получают прямого доступа к системным
вызовам хоста, все обращения к ядру фильтруются и обрабатываются gVisor-ом.
Такая модель изоляции обеспечивает гораздо более жесткий контроль и серьезно
снижает вероятность выхода из контейнера, но и дает о себе знать – она
медленнее, требовательнее, сложнее в отладке.

## Контейнерные рантаймы низкого уровня
Инструменты вроде runc, crun и youki представляют собой низкоуровневые
контейнерные рантаймы, которые отвечают исключительно за запуск уже
подготовленных контейнеров. Они реализуют работу с пространствами имен, cgroups
и файловыми системами, строго следуя спецификации OCI. runc – эталонная
реализация, написанная на Go и широко используемая как основа для других
решений. crun написан на C и заметно выигрывает в скорости по сравнению с runc –
особенно в системах с ограниченными ресурсами или при массовом запуске
контейнеров. youki разрабатывается на Rust и отличается строгостью архитектуры:
упор делается на предсказуемое поведение и защиту от типичных низкоуровневых
ошибок, вроде утечек памяти или гонок данных.

## Инструменты пользовательской изоляции
Инструменты, такие как uDocker, FireJail и bubblwrap, можно отнести к категории
утилит пользовательской изоляции – они не требуют прав суперпользователя и
работают в рамках возможностей обычного пользователя, предоставляя при этом
базовые или расширенные механизмы ограничения окружения. Их цель – предоставить
легкий и контролируемый способ запускать недоверенные или ограниченные процессы,
без вмешательства в системную конфигурацию и без необходимости поднимать службы.

### uDocker
udocker позволяет запускать контейнеризированные приложения без привилегий и без
установленного Docker-демона. Он ориентирован на пользователей, работающих в
ограниченных средах, например, на кластерах, где доступ к root закрыт и
установка системных контейнеров невозможна. Инструмент написан на Python и
ориентирован в первую очередь на переносимость.

### FireJail
FireJail представляет собой инструмент для изоляции приложений, ориентированный
на упрощение защиты пользовательских процессов в Linux-системах. Его
особенностью является использование предопределенных профилей безопасности,
которые автоматически применяют политики изоляции для популярных программ
(например, браузеров, медиаплееров или офисных приложений).

В отличие от инструментов, требующих глубокой интеграции с инфраструктурой
(таких как Docker или LXC), FireJail направлен на изоляцию отдельных процессов в
рамках существующей системы. Он не требует запуска фоновых служб или сложной
подготовки образов.

### bubblewrap
bubblewrap представляет собой минималистичный инструмент для изоляции процессов,
основанный на механизмах пространств имен Linux. Его важной особенностью
является возможность запуска приложений в изолированном окружении без
необходимости в привилегиях суперпользователя. В отличие от более сложных
систем, bubblewrap фокусируется на базовой изоляции файловой системы, сети и
процессов, предоставляя пользователю прямой контроль через командную строку.
Инструмент не требует предварительной настройки демонов или сложных
конфигурационных файлов, так как все параметры задаются через аргументы
командной строки, что делает его удобным для интеграции в скрипты или
автоматизированные сценарии. bubblewrap разрабатывался как часть экосистемы
Flatpak, что подтверждает его надежность и соответствие требованиям современных
дистрибутивов.


# Обзор механизмов контейнеризации
Контейнеризация в Linux – это не отдельная технология, а набор функциональных
компонентов, предоставляемых ядром. Они решают разные задачи, но если
скомбинировать их вместе, то можно ограничить процесс: в доступе к системе, в
использовании ресурсов, в поведении. Таким образом можно обойтись без
виртуальной машины, если задать жесткие рамки.

## Namespaces
Если нужно, чтобы запущенный процесс не взаимодействовал напрямую с остальной
системой, первым шагом почти всегда становится использование пространств имен.
Они позволяют изолировать отдельные части окружения так, что каждый процесс
видит свою «копию» этих ресурсов, не влияющую на остальную систему.

Эта идея оказалась настолько гибкой, что на нее теперь опирается почти все, что
связано с контейнерами, так как позволяют задать минимальный уровень изоляции
без обращения к полноценной виртуализации.

Данный механизм детальнее будет рассмотрен позднее.

## cgroups
Когда среда изолирована, остается вопрос – сколько ресурсов ей можно дать. Без
ограничений один процесс может занять всю память или загрузить процессор до
предела. Контроль за этим берут на себя cgroups (control group). Они разбивают
доступные ресурсы на группы и распределяют их между процессами. И делают это на
уровне ядра, что гарантирует предсказуемость: даже если процесс пытается обойти
ограничения, они все равно срабатывают. Поддерживаются ограничения на CPU,
память, ввод-вывод и другие подсистемы. Вторая версия cgroups упростила
конфигурацию и сделала поведение более стабильным, но общая логика осталась
прежней.

## seccomp
Ограничить видимость и ресурсы недостаточно для надежной изоляции, так как
процесс может делать произвольные системные вызовы. Чаще всего это mount,
ptrace, execve и другие критичные операции, через которые можно повлиять на
окружение. Именно тут вступает в силу Seccomp (secure computing mode). Он
позволяет фильтровать какие вызовы разрешены, а какие нет. Все, что выходит за
пределы, блокируется. Это снижает риск так как даже если процесс получил доступ
к какому-то ресурсу, без системного вызова он не сможет им воспользоваться.

## SELinux
SELinux представляет собой дополнительный уровень контроля, который работает не
через изоляцию или ограничение ресурсов, а через систему политик. Она задает,
какие процессы и при каких условиях могут взаимодействовать с другими
компонентами системы. Даже если у приложения формально есть права, и оно
выполняется в изолированном окружении, SELinux может запретить доступ к ресурсу,
если такой доступ не прописан явно.

В контексте rootless-инструментов – то есть утилит, работающих без прав
суперпользователя – SELinux выступает как внешняя система правил, полностью
находящаяся вне зоны управления приложения: процесс не знает о его наличии
напрямую, не может изменить активную политику, переключить режим работы или
запросить дополнительные разрешения. Ошибка будет выглядеть как обычный отказ в
доступе, без явной связи с SELinux.


# Linux namespaces
Linux namespaces – это один из основных механизмов, лежащих в основе
контейнеризации. Именно благодаря ним процессы в изолированных окружениях «не
видеть» друг друга, как будто работают на разных машинах, хотя физически
находятся на одном ядре. Это не какая-то новая надстройка, а часть ядра Linux,
развивающаяся уже более двух десятилетий.

Первые шаги в сторону изоляции в Linux начались еще в начале 2000-х годов, но в
полноценную систему пространства имен оформились с появлением CLONE_NEWNS в ядре
2.4.19 (2002 год), а позже начали появляться и остальные. Их развитие шло
постепенно: один namespace – одна изолированная часть системы. Все вместе это
позволяет запускать процесс в «песочнице», где у него свои PID'ы, свои
смонтированные директории, своя сеть и даже свой root-пользователь, не
совпадающий с root'ом на хосте.

Интересный исторический момент связан с тем, почему именно namespace
монтирования в системных вызовах обозначается как CLONE_NEWNS, а не, скажем,
CLONE_NEWMOUNT. Все дело в том, что он был первым реализованным пространством
имен в ядре Linux. На тот момент еще не существовало общей концепции
«namespaces» как набора взаимосвязанных механизмов – был просто механизм
изоляции точек монтирования, и сокращенное newns (от new namespace) казалось
вполне логичным. Уже позже, когда начали появляться другие типы пространств
имен, их стали именовать более явно: CLONE_NEWPID, CLONE_NEWNET, CLONE_NEWUSER и
так далее.

Основная идея namespaces – обеспечить процессу видимость работы в собственной
системе. При этом, в отличие от виртуальных машин, здесь нет полной эмуляции:
ядро одно, ресурсы общие, а изоляция реализована средствами самого ядра, что
делает такую модель намного более легкой и быстрой.

Благодаря этому namespaces стали основой для таких инструментов, как Docker,
LXC, Podman, Firejail, Bubblewrap и других. Они позволяют запускать процессы в
контейнерах на том же ядре без виртуализации и без необходимости поднимать
отдельную ОС. Более того, namespaces можно использовать напрямую – например, с
помощью unshare или более удобных оберток (инструментов, упрощающих работу с
низкоуровневыми функциями).

## User namespace
User namespace – один из ключевых механизмов изоляции в Linux, появившийся в
ядре 3.8, который позволяет процессам внутри изолированной среды иметь отличные
от хостовых идентификаторы пользователя и групп. Благодаря этому обычный
пользователь может запустить процесс с правами root внутри контейнера, не
получая настоящего root-доступа на системе. Другими словами, пространство имен
user позволяет запускать «привилегированные» процессы в изолированной среде, где
эти привилегии действуют только внутри и не имеют силы за ее пределами. Эта
особенность сделала возможным появление rootless-контейнеров, которые можно
запускать без повышенных прав.

На практике оно часто используется вместе с другими пространствами имен,
поскольку доступ к ним (например, к монтированию файловых систем или созданию
собственных PID-деревьев) тоже требует user namespace.

## Mount namespace
Mount namespace дает каждому контейнеру свое собственное представление о том,
как устроена файловая система. Это позволяет перенастроить точки монтирования
так, чтобы процессы внутри видели только то, что им разрешено, и в том виде, в
каком это задумал автор окружения. Директории можно подменить, сделать
доступными только для чтения, заменить на временные или вообще исключить – все
это будет касаться только контейнера, а хост же останется нетронутым. Один и тот
же файл, но в разных пространствах имен может оказаться в совершенно разных
местах, с разными правами и даже под разными именами.

В Linux, где почти все – это файл: устройства, процессы, сокеты, настройки –
возможность контролировать, какие именно файлы видны и как они доступны,
оказывается критически важной. Неудивительно, что именно пространство имен mount
появилось первым: он дает очень точный и мощный инструмент управления средой
исполнения.

## UTS namespace
UTS namespace отвечает за изоляцию идентификаторов хоста – имени машины
(hostname) и домена (domainname). Это может показаться несущественным по
сравнению с пространствами имен, которые изолируют процессы или файловую
систему, но на практике дает важную гибкость. Это удобно и для организации
логов, и для отладки, и просто для визуального разделения сред.

## PID namespace
PID namespace изолирует процессы: внутри него каждый запущенный процесс получает
собственный идентификатор, независимый от остальной системы. Это значит, что
контейнер не только не будет иметь доступа к процессам за пределами своего
пространства имен, но и также даже не знать о их существовании.

Особенно важно то, что внутри такого namespace можно создать собственное дерево
процессов с отдельным init-процессом (обычно с PID 1), который будет выполнять
те же функции, что и в полноценной системе – обрабатывать сигналы, управлять
жизненным циклом дочерних процессов и так далее. Это приближает поведение
контейнера к виртуальной машине, но без всей тяжести гипервизоров.

## Network namespace
Network namespace позволяет каждому контейнеру иметь собственный сетевой стек.
Это значит, что у него будут свои интерфейсы, таблицы маршрутизации, правила
iptables, сокеты и даже отдельный экземпляр loopback-интерфейса (lo). В
результате контейнер можно отключить от сети вовсе, подключить к виртуальному
мосту, настроить NAT или дать прямой доступ к физическому интерфейсу – все это
делается независимо от основной системы.

Такой подход особенно удобен для сценариев, где важно контролировать, с кем и
как общается запущенный процесс. Например, можно запустить подозрительное
приложение с полной изоляцией от интернета, сохранив при этом доступ к локальным
файлам. Или наоборот – дать выход в сеть, но запретить доступ к внутренним
сервисам хоста.

## IPC namespace
IPC (Inter-Process Communication) namespace отвечает за изоляцию механизмов
межпроцессного взаимодействия – таких как очереди сообщений, семафоры и общая
память. Без него процессы внутри разных контейнеров могут оказывать влияние друг
на друга (использовать одни и те же участки общей памяти и т. д.).


# Проектирование архитектуры
В этой главе определяется стек технологий, используемый при разработке утилиты,
а именно: механизмы изоляции и готовые низкоуровневые инструменты, язык
программирования и сопутствующие библиотеки.

## Выбор инструментов изоляции
Разработка механизма изоляции «с нуля» – через прямое использование clone,
unshare и других системных вызовов – дает высокий уровень контроля, так как
можно явно задать, какие пространства имен использовать, как накладывать
ограничения и в каком порядке. Однако такой подход плохо масштабируется в рамках
прикладных утилит. Эти вызовы чувствительны к контексту выполнения: важен
порядок операций и права процесса на каждом промежуточном этапе. Ошибка в одном
месте может привести к тому, что изоляция окажется неполной, или, наоборот,
процесс потеряет доступ к нужным ресурсам.

И когда дело касается инструментов для виртуализации, в первую очередь внимание
падает на LXC. Это решение позволяет разворачивать контейнеры, близкие по
поведению к полноценным системам. У него широкие возможности: отдельная сеть,
снапшоты, интеграция с init-системой. Но все это оказывает влияние на его
использование – LXC рассчитан на долгоживущие контейнеры, где важна устойчивость
и контроль. В контексте кратковременных изолированных процессов – его
использование не оправдано.

Docker на первый взгляд может показаться универсальным решением для изоляции,
однако его архитектура ориентирована на другие цели. Он требует установки демона
с root-доступом. Создание и использование образов подразумевает работу с
dockerfile, сборку, загрузку и хранение слоев, что делает его избыточным для
сценариев разового запуска.

AppArmor использует другой подход, так как это не контейнер, а фильтр – он
описывает, к каким ресурсам может обращаться программа. Это мощный механизм,
особенно в сочетании с остальной политикой безопасности системы. Но для
динамического запуска или гибкой настройки под каждый новый скрипт он подходит
плохо.

Firejail, предлагает готовые профили безопасности и удобство использования, но
требует прав суперпользователя для установки, так как ему необходим SUID-bit,
что ограничивает его применение в rootless-сценариях.

bubblewrap выделяется на фоне остальных своей минималистичной моделью: никаких
файлов конфигурации, никаких профилей, только командная строка, в которой
напрямую указывается, какие изоляции применить. Он был создан как часть Flatpak
и ориентирован на запуск приложений от обычного пользователя. Все его параметры
явно прописываются при запуске.

## Выбор языка программирования
Когда базовая технология изоляции определена – в данном случае это Bubblewrap –
остается решить, каким образом строить вокруг нее удобную оболочку. Сам
Bubblewrap – это утилита командной строки, и взаимодействие с ней всегда
сводится к вызову процесса с набором параметров. Подход прямой, но быстро
становится громоздким: количество флагов и аргументов растет, логика
усложняется, и необходимость в разных сценариях требует хоть какой-то структуры.

На этом этапе становится ясно, что нужен язык, в котором можно было бы быстро
собрать утилиту, обрабатывающую аргументы, управляя логикой подготовки окружения
и запуском. Python оказался уместным выбором. Код на Python легко читается,
стандартная библиотека закрывает почти все базовые потребности – от работы с
путями и файлами до запуска процессов и логирования. Никакой дополнительной
сборки или компиляции не требуется, зависимости минимальны, запуск возможен на
большинстве современных Linux-систем без установки дополнительных компонентов,
Python чаще всего входит в стандартную поставку дистрибутивов.

Это не самый производительный инструмент, но в этой задаче и не требуется
высокая производительность, так как это не CPU-bound задача. Гораздо важнее
простота изменений и прозрачность логики.

## Финальный обзор стека
В результате получается следующий стек технологий изображенные на рисунке 1.

![Image Placeholder]()  
Рисунок 1 – Используемый стек

Изоляция обеспечивается за счет стандартных механизмов, предоставляемых ядром
Linux, а именно namespaces, cgroups, seccomp. Задача защиты пользовательской
директории от модификации с сохранением функциональности и работоспособности
большинства программ решается за счет overlayfs. Работу с этими низкоуровневыми
механизмами берет на себя bubblewrap. Она избавляет от необходимости вручную
настраивать изоляцию, но в то же время не добавляет собственных абстракций,
сохраняя прямой и точный контроль над создаваемыми окружениями. Так как
bubblewrap является очень легковесной оберткой над механизмами ядра, он по
определению не берет на себя дополнительную работу, связанную с управлением
настройками и содержимым окружений. Разрабатываемое программное обеспечение,
выполняет конфигурационную работу: подгружает конфиги, анализирует параметры
командной строки и переменных окружения и генерирует необходимые десятки
параметров bwrap'у. Затем передает ему управление через системный вызов execvp,
позволяя минимизировать накладные расходы и сохранить ожидаемое поведение
приложений.

Принцип защиты от удаления и изменения файлов и директорий изображен на рисунке
2.

![Image Placeholder]()  
Рисунок 2 – Принцип изоляции пользовательской директории

Когда процесс запускается в изолированном окружении с этим режимом, то с его
точки зрения, он имеет доступ ко всем файлам. Однако, как видно из рисунка 1,
доступ к реальным корневой (/) и домашней (~) директориям доступен только в
режиме чтения (ro). Если просто запустить процесс без разрешения на запись в
домашнюю директорию, то в лучшем случае он потеряет часть функциональности, а в
худшем случае и работоспособность. Чтобы защитить хостовую файловую систему,
предоставив доступ на чтение к ее содержимому, используется overlayfs. Она
сохраняет все изменения, вносимые в файловую систему, в отдельном слое. Таким
образом запущенный процесс в изолированной среде по-прежнему может сохранять,
изменять, удалять файлы и директории, но эти изменения не будут видны за
пределами его окружения. Это позволяет защищать файловую систему хоста от ошибок
в скриптах, остаточных файлов кэша и логов и целенаправленного вреда. Также опыт
использования показал, что часто удобно позволять процессу напрямую
взаимодействовать с некоторыми директориями хоста, к примеру с текущей рабочей,
чтобы сразу получить результаты работы программы ней и быть уверенным что нигде
за ее пределами влияния на хост оказано не было.


# Разработка
Данная глава детализирует процесс создания программного обеспечения для
псевдо-изолированного (или изолированного, в зависимости от настроек запуска)
исполнения кода. Рассматриваются используемые библиотеки, общая структура с
описанием предназначения каждого модуля (файла) и каждой функции.

## Библиотеки
**argparse** – стандартный инструмент для обработки аргументов командной строки.
Главное удобство в том, что описание структуры аргументов и разбор фактически
переданных значений аргументов объединяются в одном месте: один раз описываются
флаги, типы значений, что является обязательным, а что – опциональным. Дальше
argparse сам разбирает все на нужные элементы, проверяет корректность, выдает
ошибки при неверном вводе и даже генерирует документацию, которую не нужно
писать отдельно, что намного удобнее чем обрабатывать sys.argv вручную.

Кроме этого, argparse полезен в архитектуре, где параметры можно задавать не
только для одной команды, но и как составные части – например, с флагами,
которые активируют разные режимы работы. Учитывая, что основа инструмента
строится вокруг запуска изолированных окружений с множеством вариантов – таких
как приватный том, оверлей, сохранение состояния, удаление и т. д. – без четкого
описания структуры командной строки все быстро деградировало бы в сложно
поддерживаемую кодовую базу с множеством условных операторов.

**shlex**, в отличие от argparse, работает на другом уровне – он парсит строки в
формате shell. Это удобно, если некоторые параметры передаются как готовый кусок
командной строки, который нужно разложить на отдельные аргументы, чтобы
корректно обработать дополнительные флаги, которые нужно просто передать дальше
без вмешательства. Потому что независимо от того, насколько много сценариев
использования можно предусмотреть, не стоит ограничивать пользователя, который
умеет работать с linux namespaces, от более точной настройки окружения.

**logging** позволяет управлять уровнем сообщений: во время разработки можно
включить подробный отладочный режим, а в стабильной сборке – оставить только
предупреждения и ошибки. Все это без переписывания кода. Вместо того чтобы раз
за разом закомментировать строки с отладочным выводом, достаточно поменять
уровень логирования – и инструмент становится тише.

Кроме того, можно точно настроить формат сообщений: добавить время, имя файла,
строку, уровень важности. Это особенно полезно, если лог пишется в файл или
используется в CI. В случае ошибок будет видно не только что пошло не так, но и
где именно, и при каких условиях.

Работа с окружением на низком уровне редко обходится без стандартных библиотек
sys, os, shutil и pathlib. Все они решают разные задачи, и каждая из них дает
удобный доступ к какой-то стороне взаимодействия с операционной системой.

**sys** – один из базовых модулей. Он нужен для работы с аргументами командной
строки, завершения программы с нужным кодом или, например, перенаправления
вывода ошибок и прямое взаимодействие с механизмами, которые предоставляет сам
интерпретатор.

**os** – это удобная обертка над API операционной системы. Работа с переменными
окружения, запуск внешних процессов, создание директорий, установка прав.

**shutil** предоставляет функции для работы с файлами и директориями, которые
выходят за рамки возможностей os, такие как рекурсивное удаление, копирование и
перемещение.

## Общая структура
Проект состоит из нескольких модулей:

- __main__.py – точка входа в приложение, отвечает за обработку аргументов
  командной строки, построение параметров вызова bubblewrap;
- conf.py – отвечает за загрузку и интерпретацию конфигурационных файлов, в
  которых задаются дополнительные пути, доступные в изолированной среде;
- path.py – модуль, реализующий функцию расширенного поиска по шаблонам путей с
  использованием переменных окружения и регулярных выражений.

### Основная логика
Запуск начинается с проверки наличия bubblewrap в системе – если он отсутствует,
выполнение завершается. Далее обрабатываются аргументы, среди которых можно
указать:

- имя окружения (если не указано, выводится автоматически из имени исполняемого
  файла или программы);
- режим изоляции домашней директории;
- подключение сетевого пространства имен;
- директории конфигурации и хранилища;
- дополнительные флаги очистки или удаления;
- аргументы, которые будут напрямую переданы в bubblewrap (для большей
  гибкости).

Если изоляция ранее не создавалась, для нее создается каталог, в котором, в
зависимости от режима, размещаются либо верхний слой overlayfs, либо привязанный
подкаталог для монтирования. Сбор аргументов bubblewrap происходит поэтапно:
сначала флаги пространств имен, затем базовые монтирования (/, /proc, /dev),
затем – домашний каталог, текущая директория (если указано), runtime-пути, и
пути из конфигурационных файлов. Конфигурация может быть задана как общая
(default.cfg), так и специфичная для конкретного приложения.

Визуальное представление этой логике изображено на рисунке 3.

![Image Placeholder]()  
Рисунок 3 – Основная логика

После подготовки всех аргументов производится вызов os.execvp, передающий
управление bubblewrap.

### Конфигурация
Загрузка конфигурации (рисунок 4) построена на двухуровневой модели: если
присутствует файл, специфический для текущего окружения, он используется в
первую очередь. В противном случае подгружается общий файл. При первом запуске,
если ни один файл не существует, создается шаблон с базовыми
runtime-директориями – это минимально необходимый набор, чтобы GUI-приложения
могли запуститься в Wayland-сессии.

![Image Placeholder]()  
Рисунок 4 – Загрузка конфигурации

### Модуль сопоставления путей
Данный модуль – path.py, – предоставляет собственную реализацию glob функции,
позволяющую интерпретировать шаблоны с переменными окружения и полноценными
регулярными выражениями, обеспечивая гибкость при описании путей. В стандартной
библиотеке Python для этих целей используется модуль pathlib, реализующий
механизм сопоставления путей с шаблонами, аналогичный Unix shell-стилю. Однако
стандартный pathlib.glob имеет ряд ограничений, препятствующих его использованию
в более сложных сценариях. В частности, он не поддерживает переменные окружения
и регулярные выражения, что значительно снижает его гибкость.

Для решения данной проблемы был реализован модуль (рисунок 5), предоставляющий
расширенную версию функции. Во-первых, он позволяет формировать шаблоны путей,
динамически зависящие от окружения. А во-вторых, поддерживает регулярные
выражения (regex). В частности, становится возможным явно задавать границы строк
(^, $), использовать квантификаторы (+, *, ?), группы, классы символов ([0-9],
[a-z], и т. д.).

![Image Placeholder]()  
Рисунок 5 – Рекурсивное сопоставление путей

Примером практической задачи, в которой стандартный glob оказывается
недостаточным, может служить необходимость отличить файл «wayland-1» от
«wayland-1.conf». При использовании шаблона «wayland-*» оба файла будут найдены,
так как шаблон соответствует любой последовательности символов после префикса
«wayland-». Однако если требуется выбрать только файлы с числовыми суффиксами,
например «wayland-1», «wayland-2», и исключить конфигурационные файлы вроде
«wayland-1.conf», стандартный инструмент оказывается неприменим. В разработанном
решении для этого можно использовать шаблон «wayland-[0-9]+$».

## Функции
**parse_args()** – данная функция является стандартным паттерном при работе с
библиотекой argparse. Она задает аргументы командной строки, настраивает их
параметры и поведение, специальным образом обрабатывает варианты по умолчанию и
введенные значения, а затем возвращает их в удобном объекте.

**check_bwrap()** – простейшая проверка, без которой запуск не имеет смысла.
Убеждается, что bubblewrap установлен в системе, иначе печатает сообщение об
ошибке и прерывает выполнение. bwrap – это единственный внешний бинарный модуль,
от которого зависит wraplify.

**main()** – главная точка входа в приложение. Сначала вызывается check_bwrap()
– без него дальнейшие действия невозможны, так как bubblewrap является
необходимой зависимостью разработанной утилиты. Затем разбираются аргументы с
помощью parse_args().

После этого начинается формирование аргументов для bubblewrap. Включаются
стандартные неймспейсы (--unshare-*), защита от зомби (--die-with-parent),
монтирование системных директорий (/proc, /dev, /run). Затем добавляется логика,
связанная с домашним каталогом: либо временный tmpfs, либо overlay с верхним
уровнем, либо постоянный bind.

Аналогично добавляются текущая директория и XDG_RUNTIME_DIR, если они нужны.
Дополнительно подгружаются пользовательские настройки из конфигурации через
conf.load_config(). В конце собирается итоговый список аргументов для
bubblewrap, логируются для отладки, и вызывается os.execvp() – фактически,
wraplify самозаменяется на bwrap.

**parse_config(config_path: Path)** – открывает указанный конфигурационный файл
и разбирает его по строкам, для обработки которых используется функция glob().
Возвращается множество всех совпавших путей. Это дает пользователю гибкость:
можно указать шаблоны, соответствующие целым классам сокетов или временных
директорий (например, wayland и pipewire).

**load_config(config_path: Path, name: str)** – определяет, какой конфиг
использовать: сначала пробует найти специфический файл для приложения по имени,
если такого нет – откатывается к default.cfg. Возвращает множество путей,
которые затем будут подключены внутрь sandbox-а при запуске.

**sub_env(var: str)** – вспомогательная функция для подстановки переменных
окружения в шаблоне. Используется при разборе строк в конфигурации.

**expandvars(text: str)** – расширяет переменные окружения в переданной строке.
Применяется регулярное выражение для поиска переменных окружения в виде ${NAME}
(используется формат bash переменных) и замены их на соответствующие значения из
os.environ.

**_glob(pattern: str, path: Path, dbg_offset='') -> set[Path]** – функция
рекурсивного сопоставления пути. Работает как pathlib.glob, но с важным
отличием: она использует регулярные выражения вместо wildcard-символов (*, ?).
Каждый уровень пути сопоставляется отдельно, и, если совпадение найдено,
происходит углубление в соответствующую директорию. Если на каком-то этапе
возникает PermissionError, он логируется. Дополнительный аргумент dbg_offset
используется исключительно для отладочного вывода – он визуально показывает
глубину рекурсии в логах, добавляя отступы.

**glob(pattern: str) -> set[Path]** – публичная функция модуля. Приводит шаблон
к финальному виду, сначала удаляя лишние слеши и применяя expandvars(), затем
вызывает _glob(), начиная обход с корня файловой системы. Это тот интерфейс,
который используют функции из conf.py, чтобы собрать пути, указанные в
пользовательском конфиге.


# Демонстрация
Данная глава демонстрирует возможности разработанной утилиты.

## Описание условных обозначений в листингах
Демонстрационные листинги в данной главе имеют следующую структуру,
представленную в листинге 1.

Листинг 1 – Структура листингов
```
[<user>@<hostname> <workdir>]<usertype> <command> # <comment>

<output>
```

Теперь рассмотрим каждый элемент подробнее:

- user – имя пользователя от имени которого исполняется команда;
- hostname – имя хоста, в примерах либо «host» – что значит, что команда
  исполняется на хостовой (основной) системе, либо «wrap» – значит что команда
  исполняется внутри изолированной среды созданной разработанной утилитой;
- workdir – путь до текущей рабочей директории, «~» – это корень домашней
  директории текущего пользователя;
- usertype – либо «$» – обычный пользователь, либо «#» – root пользователь;
- command – исполняемая команда;
- comment – комментарий к команде;
- output – результат исполнения команды, может содержать несколько строк или
  отсутствовать.

Дополнительно создадим псевдоним (alias) для более удобного использования
утилиты с помощью команды `alias wraplify="uvx wraplify"`. Утилита uvx
автоматически скачает пакет с pypi при первом запуске.

## Подготовка стенда
Дальше во всех примерах предполагается, что данная структура файлов и директорий
из листинга 2 присутствует в корне домашней директории пользователя.

Листинг 2 – Команды для создания демонстрационной иерархии
```
[user@host ~]$ mkdir -p dir/subdir1
[user@host ~]$ mkdir -p dir/subdir2
[user@host ~]$ mkdir -p dir/subdir3/nested_dir
[user@host ~]$ touch dir/file1.txt
[user@host ~]$ touch dir/file2.log
[user@host ~]$ touch dir/file3.csv
[user@host ~]$ touch dir/subdir1/subfile1.txt
[user@host ~]$ touch dir/subdir1/subfile2.md
[user@host ~]$ touch dir/subdir2/subfile3.json
[user@host ~]$ touch dir/subdir3/subfile4.xml
[user@host ~]$ touch dir/subdir3/nested_dir/nested_file1.txt
[user@host ~]$ touch dir/subdir3/nested_dir/nested_file2.dat
[user@host ~]$ mkdir -p dir/empty_dir
[user@host ~]$ mkdir -p dir/subdir3/another_empty_dir
[user@host ~]$ tree dir
dir
|-- empty_dir
|-- file1.txt
|-- file2.log
|-- file3.csv
|-- subdir1
|   |-- subfile1.txt
|   `-- subfile2.md
|-- subdir2
|   `-- subfile3.json
`-- subdir3
    |-- another_empty_dir
    |-- nested_dir
    |   |-- nested_file1.txt
    |   `-- nested_file2.dat
    `-- subfile4.xml
7 directories, 9 files
[user@host ~]$
```

## Режим по умолчанию
Пример, приведенный в листинге 3, показывает базовую логику автоматического
создания изолированных окружений для каждого запускаемого приложения в
отдельности.

Видно, что в режиме по умолчанию разработанная утилита полностью изолирует
пользовательскую домашнюю директорию, а также сохраняет все изменения отдельно,
для каждого запущенного приложения.

Листинг 3 – Демонстрация общего принципа разных окружений
```
[user@host ~]$ ls           # видим что на хосте присутствует host_file файл
host_file
[user@host ~]$ wraplify bash               # запускаем разработанную утилиту
[user@wrap ~]$ touch wrap_file              # создаем файл внутри контейнера
[user@wrap ~]$ ls            # видим что файла с хоста нет внутри контейнера
wrap_file
[user@wrap ~]$ exit                                  # выходим из контейнера
exit
[user@host ~]$ ls # на хосте по прежнему есть файл host_file и нет wrap_file
host_file
[user@host ~]$ wraplify bash   # повторно запускам утилиту с той же командой
[user@wrap ~]$ ls         # видим файл, который был создан внутри контейнера
wrap_file
[user@wrap ~]$ exit                                  # выходим из контейнера
exit
[user@host ~]$ wraplify sh                  # запускаем уже другую программу
sh-5.2$ ls                                              # никаких файлов нет
sh-5.2$ exit                                         # выходим из контейнера
exit
[user@host ~]$
```

## Режим OverlayFS
Этот пример (листинг 4) демонстрирует работу утилиты в режиме OverlayFS, когда
все пользовательские данные доступны, но их редактирование и удаление не
оказывает влияния на хостовую файловую систему.

Листинг 4 – Демонстрация OverlayFS
```
[user@host ~]$ wraplify --overlay bash # заходим в изолированное окружение с
                                                          # флагом --overlay
[user@wrap ~]$ ls                         # видим что папка с хоста на месте
dir
[user@wrap ~]$ find dir -name "*2*" -exec rm -vrf {} \;  # удаляем все файлы
                                                        # содержащие цифру 2
removed 'dir/subdir1/subfile2.md'
removed 'dir/subdir2/subfile3.json'
removed directory 'dir/subdir2'
find: 'dir/subdir2': No such file or directory
removed 'dir/subdir3/nested_dir/nested_file2.dat'
removed 'dir/file2.log'
[user@wrap ~]$ tree dir       # выводим оставшееся содержимое директории dir
dir
|-- empty_dir
|-- file1.txt
|-- file3.csv
|-- subdir1
|   `-- subfile1.txt
`-- subdir3
    |-- another_empty_dir
    |-- nested_dir
    |   `-- nested_file2.dat
    `-- subfile4.xml
6 directories, 5 files
[user@wrap ~]$ exit                                  # выходим из контейнера
exit
[user@host ~]$ tree dir      # и выводим содержимое хостовой директории dir,
                                     # видим, что все осталось без изменений
dir
|-- empty_dir
|-- file1.txt
|-- file2.log
|-- file3.csv
|-- subdir1
|   |-- subfile1.txt
|   `-- subfile2.md
|-- subdir2
|   `-- subfile3.json
`-- subdir3
    |-- another_empty_dir
    |-- nested_dir
    |   |-- nested_file1.txt
    |   `-- nested_file2.dat
    `-- subfile4.xml
7 directories, 9 files
[user@host ~]$ tree ~/.local/state/wraplify/bash/   # а все измененные файлы
                                                # хранятся в отдельном месте
/home/user/.local/state/wraplify/bash/
|-- home
|-- upper
|   `-- dir
|   |-- file2.log
|   |-- subdir1
|   |   `-- subfile2.md
|   |-- subdir2
|   `-- subdir3
|       `-- nested_dir
|           `-- nested_file2.dat
`-- work
    `-- work [error opening dir]
9 directories, 4 files
[user@host ~]$
```

## Приложение с графическим интерфейсом
Данный пример показывает, что даже приложение с графическим интерфейсом работает
без дополнительных настроек. Команды запуска представлены в листинге 5,
результат на рисунке 6.

Листинг 5 – Демонстрация запуска GUI приложений
```
[user@host ~]$ wraplify firefox
[user@host ~]$
```

![Image Placeholder]()  
Рисунок 6 – Просмотр локальных файлов через firefox

## Режим монтирования
В данном случае (листинг 6) можно видеть, как была смонтирована только рабочая
директория (вывод команды `tree ~`), и причем напрямую, без overlayfs.

Это означает что все изменения напрямую будут вноситься в хостовую систему, но
только внутри рабочей директории.

Используется данный режим, когда нужно перенести в контейнер текущую папку с
хоста, но, чтобы все изменения за ее пределами не оказывали влияния на систему.

Листинг 6 – Демонстрация монтирования текущей директории
```
[user@host ~]$ cd dir/subdir3                  # переходим в поддиректорию
[user@host subdir3]$ wraplify --current-dir bash # заходим в изолированное
                                            # окружение с флагом --overlay
[user@wrap subdir3]$ ls
another_empty_dir nested_dir subfile4.xml
[user@wrap subdir3]$ tree ~                      # выводим содержимое всей
                                             # пользовательской директории
/home/user
`-- dir
    `-- subdir3
    |-- another_empty_dir
    |-- nested_dir
    |   |-- nested_file1.txt
    |   `-- nested_file2.dat
    `-- subfile4.xml
5 directories, 3 files
[user@wrap subdir3]$ touch file_from_env         # создаем файл находясь в
                                                 # изолированном окружении
[user@wrap subdir3]$ exit                                # выходим из него
exit
[user@host subdir3]$ ls  # и видим что файл создался и на хостовой системе
another_empty_dir file_from_env nested_dir subfile4.xml
[user@wrap subdir3]
```

## Очистка окружений
В листинге 7 производится очистка окружений. Добавлена дополнительная проверка
подтверждения, которая в интерактивном режиме убеждается у пользователя, какие
директории должны быть удалены.

Листинг 7 – Демонстрация очистки созданных окружений
```
[user@host ~]$ wraplify --clean-all
Remove directory '/home/vkr/.config/wraplify'? [y/N] y
Remove directory '/home/vkr/.local/state/wraplify'? [y/N] y
[user@host ~]$
```


# Тестирование
Разработка инструмента для изоляции недоверенного кода требует проверки его
соответствия ключевым требованиям: безопасности и удобству использования.

Цель тестирования – подтвердить выполнение сформулированных требований:

- Отсутствие уязвимостей, связанных с утечкой данных, эскалацией привилегий или
  неконтролируемым доступом к ресурсам хоста;
- Интуитивность интерфейса, минимальное время запуска и совместимость с
  типовыми сценариями, включая работу с GUI-приложениями.

## Проверка изоляции пространств имен
Цель данного раздела проверить, что процессы в изолированной среде не имеют
доступа к ресурсам хост-системы за пределами выделенных пространств имен. Для
этого было протестировано каждое пространство имен:
1. **User Namespace** – проверки подтвердили, что процессы внутри изолированной
   среды не обладают привилегиями root на хосте. Попытки изменить системные
   файлы, такие как /etc/passwd, завершались ошибкой доступа, несмотря на UID 0
   внутри контейнера.
1. **PID Namespace** – команда ps aux, выполненная в изолированной среде,
   отображала только внутренние процессы, что свидетельствует об отсутствии
   видимости процессов хост-системы.
1. **Mount Namespace** – файловая система была изолирована: при выполнении ls ~
   отображалось только содержимое разрешенных директорий.
1. **Network Namespace** – сетевой стек контейнера оказался полностью
   изолирован. Команда ip a показывала только виртуальные интерфейсы, созданные
   внутри среды. Интерфейсы хост-системы не были доступны.
1. **UTS Namespace** – команда uname -n показала, что имя хоста в изолированной
   среде отличалось от имени хоста, что подтверждает корректную настройку.
1. **IPC Namespace** – при выполнении ipcs не обнаруживались объекты
   межпроцессного взаимодействия, принадлежащие хост-системе, что говорит о
   полной изоляции IPC-ресурсов.

Разработанная утилита успешно проходит проверки, описанные выше. Что вполне
ожидаемо, так как низкоуровневая настройка пространств имен лежит на надежном
компоненте bubblewrap.

## Проверка защиты от известных эксплойтов
Проверки ниже позволяют убедиться, что изолированная среда устойчива к
эксплуатации уязвимостей, включая известные CVE (Common Vulnerabilities and
Exposures), и предотвращает эскалацию привилегий или доступ к ресурсам хоста:
1. Dirty COW (CVE-2016-5195) – тест с использованием эксплойта, направленного на
   модификацию защищенного файла в системе, завершился неудачей. Попытка
   получить доступ к защищенным областям памяти была заблокирована на уровне
   ядра, как и ожидалось.
1. Эксплойт через /proc/self/exe (CVE-2019-5736) – попытка подмены исполняемого
   файла внутри контейнера с использованием уязвимости была заблокирована.
   Сценарий завершился ошибкой доступа, что подтверждает корректную изоляцию и
   защиту файловой системы.
1. Доступ к устройствам хоста – проверки взаимодействия с критичными
   устройствами, такими как /dev/mem, /dev/sda и /dev/kvm, показали, что
   изолированная среда надежно блокирует все попытки открытия и модификации. Все
   действия завершались с ошибками «Operation not permitted».

Результаты тестирования подтверждают устойчивость инструмента к ряду атак,
направленных на обход ограничений изоляции и нарушение целостности системы.

## Проверка удобства использования
Проверен запуск приложения с графическим интерфейсом. Приложение успешно
запускалось, интерфейс отображался корректно (рисунок 6), взаимодействие с
пользователем (мышь, клавиатура, окна) осуществлялось без сбоев, дополнительных
настроек разработанная утилита от пользователя не требовала.

## Оценка производительности
Для повышения объективности были проведены сравнительные замеры времени запуска
простейшей команды echo в различных сценариях с использованием утилиты
hyperfine, позволяющей производить точные микробенчмарки. Выбор на команду echo
пал так как время ее работы пренебрежимо мало, что позволяет точнее оценить
вклад именно утилит для создания изолированного окружения. hyperfine
автоматизирует процесс сбора статистики, он запускает требуемое приложение сотни
раз, замеряя время каждой итерации, а затем высчитывает характеристики
полученных данных.

Результаты измерений представлены в таблице 2.

Таблица 2 – Сравнение времени запуска команд
| Команда    | Среднее время, мс | Стандартное отклонение, мс | User time, мс | System time, мс |
|------------|-------------------|----------------------------|---------------|-----------------|
| echo       | 0.45              | ± 0.04                     | 0.28          | 0.13            |
| bubblewrap | 3.5               | ± 0.2                      | 0.2           | 0.7             |
| wraplify   | 34.7              | ± 1.9                      | 26.4          | 5.3             |
| uvx        | 49                | ± 0.4                      | 33.9          | 12.8            |
| docker     | 216.3             | ± 13.0                     | 6.9           | 5.9             |

И те же самые данные в графическом виде представлены на рисунке 7.

![Image Placeholder]()  
Рисунок 7 – Сравнение времени запуска команд

Рассмотрим результаты подробнее:

- команда echo служит базовым ориентиром: менее 0.5 мс;
- bubblewrap показывает, что изоляция на уровне пространств имен в чистом виде
  вносит около 3 мс задержки, что говорит об эффективности низкоуровневого
  механизма;
- wraplify в виде CLI-инструмента, написанного на Python, демонстрирует среднее
  время запуска 34.7 мс. Основной вклад вносит запуск интерпретатора Python.
- uvx реализует подход, схожий с pipx, позволяет автоматически загрузить пакет
  с PyPI и запустить его, что дает возможность в одну команду запустить
  разработанное программное обеспечение на любой системе, где установлены
  python, bubblewrap и uvx, конечно;
- docker демонстрирует наибольшее время запуска: каждая команда взаимодействует
  с фоновым демоном dockerd, который управляет контейнерами.

Тестирование показало, что разработанное решение отличается значительно меньшими
накладными расходами по сравнению с Docker. В сценариях, где важны безопасность
и минимальное вмешательство в систему, оно демонстрирует приемлемое время
запуска и подходит для интерактивного использования. Даже с учетом инициализации
среды и обработки логики запуска, среднее время старта остается в пределах
нескольких десятков миллисекунд. Это делает инструмент удобным выбором для
безопасного исполнения однократных задач, включая запуск скриптов, утилит и
других приложений.


# Доставка
Когда инструмент начинает работать стабильно, его нужно подготовить к
использованию вне локальной среды. Это значит не только обеспечить установку, но
и сделать ее повторяемой: зависимости должны устанавливаться корректно, команды
выполняться одинаково, а окружение не требовать ручной доводки. Даже если
утилита рассчитана на узкий круг задач, от того, как она оформлена и
распространяется, зависит, насколько быстро ее смогут использовать другие.

Формат распространения выбирается исходя из того, кто и как будет использовать
результат. Иногда достаточно обычного архива с бинарным файлом В других случаях
удобнее упаковать все в Python-пакет и выложить в PyPI. А если требуется
зафиксировать окружение и исключить лишние зависимости, подойдет сборка в
контейнер.

Но, к сожалению, последний самый контролируемый вариант для данной утилиты
совершенно не подходит, поскольку она ориентирована на использование в
rootless-сценариях, где доступ к системному контейнерному движку либо ограничен,
либо отсутствует вовсе. Кроме того, контейнер – это, по сути, изолированная
система, тогда как цель утилиты – интеграция с существующим окружением
пользователя, с сохранением его привычной среды, путей и настроек.

## Python Package Index
PyPI (Python Package Index) – это централизованное хранилище для
Python-библиотек и утилит, своего рода каталог, откуда любой может установить
пакет с помощью pip. Это упрощает распространение: достаточно один раз выгрузить
проект, и он становится доступен через стандартные инструменты во всех системах,
где установлен Python.

Поэтому если цель – сделать инструмент доступным другим разработчикам, особенно
в экосистеме Python, публикация туда является логичным выбором. Она не требует
настройки стороннего хранилища, и сам процесс сводится к нескольким командам.
Все, что нужно – правильно оформить проект: указать метаинформацию, зависимости
и путь к исполняемому скрипту.

Это не единственный способ доставки, но один из самых очевидных, когда речь идет
о Python-утилите, которую планируется запускать из командной строки

## Конфигурация пакета
Чтобы опубликовать пакет на PyPI, нужно выполнить несколько базовых требований,
и первое из них – подготовить корректную структуру проекта и метаданные. PyPI
ожидает, что в составе проекта будет файл pyproject.toml, в котором указаны,
метаданные проекта, зависимости, настройки сборки.

pyproject.toml постепенно вытеснил setup.py и стал основным способом описания
Python-проектов. Причина довольно понятная – со временем в setup.py начинала
появляться не только метаинформация, но и логика, что противоречило его
использованию в качестве универсального формата. Требовалось что-то более
структурированное, что можно было бы легко читать и обрабатывать автоматически.

Новый формат решает проблемы setup.py за счет разделения обязанностей: вся
информация о проекте – его имя, версия, авторы, список зависимостей – теперь
явно задается в одном месте, без смешивания с кодом. При этом pyproject.toml
может использоваться не только setuptools, но и другими инструментами – flit,
poetry, uv, и это делает экосистему более гибкой.

Листинг 8 – Пример минимальной конфигураций проекта
```
[project]
name = "wraplify"
version = "0.2.3"
description = "Wraplify simplifies the process of isolating untrusted code by
providing a user-friendly Python wrapper around bubblewrap"
readme = "README.md"
requires-python = ">=3.13"
dependencies = []
```

Этого достаточно, чтобы pip и другие аналогичные инструменты понимали, как
собрать и установить пакет. Если скрипт предполагается запускать из терминала, в
pyproject.toml можно также указать точку входа – команду, которая будет
устанавливаться как исполняемая, что в данном случае очень удобно:

Листинг 9 – Указание точки входа
```
[project.scripts]
wraplify = "main:main"
```

## Сборка и загрузка пакета
Для публикации на PyPI одного pyproject.toml недостаточно. Помимо описания
проекта, необходим специально подготовленный образ, представляющий собой пакет
строго определенной структуры, который соответствует требованиям Python
Packaging Authority. Он представляет собой либо sdist (source distribution),
либо wheel (формат .whl), а чаще – оба варианта одновременно. Это делается для
того, чтобы охватить как можно больше сценариев установки: исходники можно
собрать под специфическую платформу, а предсобранный образ ставится сразу, если
все совпадает по окружению.

Формат sdist – это tar.gz-архив с исходным кодом и всей метаинформацией о
пакете. Он дает максимальную гибкость, но требует компиляции на стороне
пользователя при установке, что очевидно, занимает дополнительное время и
требует некоторых вычислительных ресурсов целевой системы. В отличие от него,
wheel – это бинарный формат: предварительно собранный и готовый к установке.
Если пакет не зависит от платформы (например, написан полностью на Python), то
wheel будет универсальным – py3-none-any. Кроме того, wheel позволяет избежать
потенциальных проблем, связанных с отсутствием необходимых компиляторов или
библиотек на целевой системе.


# Заключение
Был проведен обзор более 80 инструментов для контейнеризации и изоляции, и
определены их ограничения. Существующие решения чаще всего имеют направленность
на оркестрацию и требуют заранее подготовленных образов, либо требуют
привилегированных прав или имеют комплексную первоначальную конфигурацию,
которая оказывается сложной для неподготовленного пользователя. В рамках
поставленной в данной работе задачи эти ограничения являются недостатками. На их
основе были сформулированы требования к разрабатываемого программному
обеспечению.

Был выбран Bubblewrap в качестве основы так как скрывает особенности
низкоуровнего конфигурирования окружений, однако не создает дополнительных
абстракций, а также поддерживает rootless режим и не добавляет накладных
расходов.

Разработан wraplify – инструмент, поддерживающий режим частичной или полной
изоляции домашней директории. Специально разработанный режим частичной изоляции
позволяет процессам внутри окружения читать файлы с хостовой системы, однако
возможность изменить что-либо на хосте отсутствует так как все вносимые
изменения хранятся отдельно и будут видны лишь внутри данного окружения. Таким
образом пользователь может запускать программы, которые будут иметь доступ ко
всем файлам хоста, и использовать их для своих целей, без риска повреждения
основной системы.

В ходе тестирования было подтверждено соответствие требованиям безопасности:
процессы не могут получить доступ к ресурсам хоста, окружение защищенно от
популярных эксплойтов, осуществляющих выход за пределы изолированного окружения.
Дополнительно была продемонстрирована высокая скорость запуска.

Инструмент упакован в Python-пакет и размещен на PyPI (The Python Package
Index), что существенно упрощает установку в системах, поддерживающих Python
3.13+.

Разработанный инструмент wraplify успешно решает поставленные задачи, предлагая
простой и безопасный способ запуска недоверенного кода. Он не подвержен
недостаткам существующих решений. Тестирование подтвердило его устойчивость к
известным атакам и эксплойтам. Для повседневного использования разработчиками и
пользователями без глубоких навыков конфигурирования Linux он является
оптимальным решением.

Таким образом, поставленная в данной работе цель создания удобного
непривилегированного инструмента для запуска недоверенного кода в изолированной
среде успешно достигнута.


# Список использованных источников
1. The internals and the latest trends of container runtimes (2023) [Электронный
   ресурс]. Режим доступа:
   https://medium.com/nttlabs/the-internals-and-the-latest-trends-of-container-runtimes-2023-22aa111d7a93
   (Дата обращения 01.04.2025).
1. Awesome Linux Containers [Электронный ресурс]. Режим доступа:
    https://github.com/Friz-zy/awesome-linux-containers
    (Дата обращения 20.04.2025).
1. Awesome Containers [Электронный ресурс]. Режим доступа:
    https://github.com/pditommaso/awesome-containers (Дата обращения 20.04.2025).
1. Containers [Электронный ресурс]. Режим доступа:
    https://github.com/containers/ (Дата обращения 20.04.2025).
1. What is Docker? [Электронный ресурс]. Режим доступа:
    https://docs.docker.com/get-started/docker-overview/
    (Дата обращения 20.04.2025).
1. Базовые возможности LXD – системы контейнеров в Linux [Электронный ресурс].
    Режим доступа: https://habr.com/ru/articles/496492/
    (Дата обращения 20.04.2025).
1. Rootless containers using Podman [Электронный ресурс]. Режим доступа:
    https://www.redhat.com/en/blog/rootless-containers-podman
    (Дата обращения 01.04.2025).
1. What is gVisor? [Электронный ресурс]. Режим доступа: https://gvisor.dev/docs/
    (Дата обращения 20.04.2025).
1. runc [Электронный ресурс]. Режим доступа:
    https://github.com/opencontainers/runc (Дата обращения 20.04.2025).
1. An introduction to crun, a fast and low-memory footprint container runtime
    [Электронный ресурс]. Режим доступа:
    https://www.redhat.com/en/blog/introduction-crun (Дата обращения 20.04.2025).
1. Youki User and Developer Documentation [Электронный ресурс]. Режим доступа:
    https://youki-dev.github.io/youki/youki.html (Дата обращения 20.04.2025).
1. udocker [Электронный ресурс]. Режим доступа:
    https://github.com/indigo-dc/udocker (Дата обращения 20.04.2025).
1. Firejail [Электронный ресурс]. Режим доступа:
    https://wiki.archlinux.org/title/Firejail (Дата обращения 20.04.2025).
1. Bubblewrap [Электронный ресурс]. Режим доступа:
    https://wiki.archlinux.org/title/Bubblewrap (Дата обращения 20.04.2025).
1. namespaces(7) [Электронный ресурс]. Режим доступа:
    https://man.archlinux.org/man/namespaces.7 (Дата обращения 21.04.2025).
1. cgroups(7) [Электронный ресурс]. Режим доступа:
    https://man.archlinux.org/man/cgroups.7 (Дата обращения 23.04.2025).
1. seccomp(2) [Электронный ресурс]. Режим доступа:
    https://man.archlinux.org/man/seccomp.2 (Дата обращения 23.04.2025).
1. selinux(8) [Электронный ресурс]. Режим доступа:
    https://man7.org/linux/man-pages/man8/selinux.8.html
    (Дата обращения 23.04.2025).
1. Containers and Threads from the POV of `clone` [Электронный ресурс]. Режим
    доступа:
    https://minin.tech/posts/containers-and-threads-from-the-pov-of-clone/
    (Дата обращения 21.04.2025).
1. user_namespaces(7) [Электронный ресурс]. Режим доступа:
    https://man.archlinux.org/man/core/man-pages/user_namespaces.7
    (Дата обращения 21.04.2025).
1. mount_namespaces(7) [Электронный ресурс]. Режим доступа:
    https://man.archlinux.org/man/core/man-pages/mount_namespaces.7
    (Дата обращения 21.04.2025).
1. utc_namespaces(7) [Электронный ресурс]. Режим доступа:
    https://man.archlinux.org/man/core/man-pages/utc_namespaces.7
    (Дата обращения 21.04.2025).
1. pid_namespaces(7) [Электронный ресурс]. Режим доступа:
    https://man.archlinux.org/man/core/man-pages/pid_namespaces.7
    (Дата обращения 21.04.2025).
1. network_namespaces(7) [Электронный ресурс]. Режим доступа:
    https://man.archlinux.org/man/core/man-pages/network_namespaces.7
    (Дата обращения 21.04.2025).
1. ipc_namespaces(7) [Электронный ресурс]. Режим доступа:
    https://man.archlinux.org/man/core/man-pages/ipc_namespaces.7
    (Дата обращения 21.04.2025).
1. clone(2) [Электронный ресурс]. Режим доступа:
    https://man.archlinux.org/man/clone.2 (Дата обращения 21.04.2025).
1. unshare(2) [Электронный ресурс]. Режим доступа:
    https://man.archlinux.org/man/unshare.2 (Дата обращения 21.04.2025).
1. The Python Standard Library [Электронный ресурс]. Режим доступа:
    https://docs.python.org/3.13/library/index.html (Дата обращения 22.04.2025).
1. CVE-2016-5195 [Электронный ресурс]. Режим доступа:
    https://nvd.nist.gov/vuln/detail/cve-2016-5195 (Дата обращения 23.04.2025).
1. CVE-2019-5736 [Электронный ресурс]. Режим доступа:
    https://nvd.nist.gov/vuln/detail/cve-2019-5736 (Дата обращения 23.04.2025).
1. Common questions [Электронный ресурс]. Режим доступа: https://pypi.org/help/
    (Дата обращения 24.04.2025).
1. Writing your pyproject.toml [Электронный ресурс]. Режим доступа:
    https://packaging.python.org/en/latest/guides/writing-pyproject-toml/
    (Дата обращения 24.04.2025).
1. Python Packaging Authority [Электронный ресурс]. Режим доступа:
    https://www.pypa.io/en/latest/ (Дата обращения 24.04.2025).
1. Package Formats [Электронный ресурс]. Режим доступа:
    https://packaging.python.org/en/latest/discussions/package-formats/
    (Дата обращения 24.04.2025).
