# Введение
Несмотря на рост числа киберугроз и общий уровень осведомленности пользователей,
ответственность за обеспечение безопасности по-прежнему в значительной степени
лежит на специалистах по информационной безопасности. Однако даже они не в
состоянии предусмотреть все возможные векторы атак. При этом существует группа
пользователей — разработчики, которые часто работают с недоверенным кодом и
обладают достаточными знаниями, чтобы, например, отключать некоторые меры защиты
(вроде запрета на копирование команд с sudo), но при этом могут не иметь
глубоких технических знаний в области безопасности. Для них особенно важно иметь
доступ к простым и эффективным средствам изоляции.

Однако существующие решения, такие как Docker, LXC, AppArmor, SELinux,
systemd-nspawn или Podman, изначально проектировались для профессионального
использования — в серверных или корпоративных инфраструктурах. Они предполагают
наличие административных прав, знание внутреннего устройства Linux и часто
требуют предварительной настройки. Более того, многие из них ориентированы не на
запуск отдельных процессов, а на полноценную оркестрацию окружений: с настройкой
томов, сетей, ресурсов, зависимостей, политик безопасности и доступа. В
результате попытка использовать такие инструменты для простой задачи — например,
разовое исполнение небольшого скрипта, скопированного с форума или
сгенерированного нейросетью — приводит к тому, что пользователь либо тратит
неоправданно много времени на настройку, либо отказывается от идеи изоляции
вовсе. Так как он вряд ли будет готов тратить время на чтение документации и
написание конфигурации ради скрипта, который, как ему кажется, будет работать
пару секунд. В результате вопрос изоляции и безопасности откладывается «на
потом» — до первого инцидента.

А так как проблема безопасного исполнения недоверенного кода сегодня стоит не
только перед специалистами в области информационной безопасности, но и перед
широкой аудиторией пользователей, которые регулярно сталкиваются с
необходимостью запускать потенциально опасные программы, то ее решение требует
инструментов новой направленности — достаточно надёжных, чтобы обеспечить
защиту, и достаточно простых, чтобы их было удобно использовать по принципу
«одна команда — и системе ничего не угрожает» (в большинстве случаев).

Целью данной работы является создание удобного в использовании инструмента,
позволяющего запускать недоверенный код в изолированной среде без необходимости
в привилегированных операциях и сложной конфигурации.

Для достижения поставленной цели необходимо решить следующие задачи:
1. Проанализировать существующие инструменты контейнеризации и их ограничения.
1. Определить ключевые требования к программному решению с учетом безопасности и
   удобства использования.
1. Разработать архитектуру программного решения.
1. Реализовать прототип программного решения.
1. Провести тестирование прототипа на соответствие требуемым критериям.


# Обзор существующих решений
Для формирования целостного представления о современных инструментах для
изоляции был проведен первичный сбор данных из нескольких авторитетных
источников. Основой для начального анализа послужили следующие ресурсы:

- [awesome-linux-containers](https://github.com/Friz-zy/awesome-linux-containers)
  — A curated list of awesome Linux Containers frameworks, libraries and
  software
- [awesome-containers](https://github.com/pditommaso/awesome-containers) — A
  curated list of awesome Linux containers related technologies inspired by
  other Awesome lists
- [Open Repository for Container Tools](https://github.com/containers/) — A
  collection of open source tools that create, configure, and work with
  containers

На основании информации из указанных источников была составлена обобщенная
таблица, включающая свыше **восьмидесяти** инструментов, связанных с
изолированным исполнением кода. Для сужения круга анализа использовались три
критерия (на момент 20.04.2025):
1. Популярность проекта: инструмент должен иметь не менее 1к звёзд (stars) на
   GitHub или аналогичной метрикой с другого хостинга — данный показатель, хоть
   и не является абсолютной метрикой качества, отражает уровень внимания
   сообщества.
1. Актуальность разработки: проект не должен находиться в архиве и иметь
   коммиты, слитые PR или решенные issues в течение последнего года — это
   исключает заброшенные и потенциально небезопасные решения.
1. Иметь открытый исходный код - почему.

После фильтрации осталась выборка из инструментов, активно поддерживаемых и
востребованных сообществом, которая представлена в таблице ниже:

| Название   | Звезд | Активность | Описание |
|------------|-------|------------|----------|
| **docker** | 69600 | 2025-04-20 |          |

Из данного списка были отобраны только те инструменты, которые предназначены для
создания изолированных сред исполнения. В него не вошли средства,
специализирующиеся, например, исключительно на мониторинге, аудите, анализе
образов или отладке контейнеров.

Отобранные решения можно классифицировать по назначению и архитектурным
особенностям на четыре основные группы:
1. Контейнерные менеджеры — комплексные системы для управления окружениями;
1. Инструменты с повышенной изоляцией — решения, использующие виртуализацию,
   эмуляцию системных вызовов или другие подходы для усиления безопасности;
1. Средства пользовательской изоляции — утилиты, позволяющие запускать процессы
   в контролируемой среде без дополнительных привилегий;
1. OCI-совместимые рантаймы — низкоуровневые компоненты, обеспечивающие
   исполнение контейнеров в соответствии с Open Container Initiative. Далее
   рассмотрим каждую группу подробнее.

## Контейнерные менеджеры
К этой категории относятся инструменты, которые предоставляют пользователю
полный цикл работы с изолированными окружениями: от создания контейнера до его
запуска, конфигурации, обновления и удаления. Это универсальные решения,
сочетающие в себе механизмы изоляции, управление файловыми системами, настройку
сетей, взаимодействие с реестрами образов и, зачастую, поддержку оркестрации. В
большинстве случаев они ориентированы на производственные среды: серверные,
облачные и корпоративные инфраструктуры, где важны масштабируемость, мониторинг,
сетевые политики и безопасность.

### Docker
Docker был разработан в 2013 году компанией dotCloud (впоследствии
переименованной в Docker Inc.) и за считанные годы стал одной из самых
узнаваемых технологий в мире разработки и эксплуатации программного обеспечения.
Он появился в тот момент, когда индустрия остро нуждалась в стандартизированном
способе упаковывать приложения вместе со всеми зависимостями, не полагаясь на
особенности окружения, в котором они будут запущены. Уже к 2015 году Docker
приобрел массовую популярность, а его экосистема начала стремительно расти:
появились реестры образов, инструменты оркестрации и полноценные
DevOps-платформы, основанные на контейнерах.

Тем не менее, при всех своих достоинствах, Docker не всегда подходит для других
задач — в частности, для изоляции недоверенного кода в пользовательских
сценариях. Архитектура Docker построена вокруг отдельного фонового демона
dockerd, который запускается с привилегиями суперпользователя и управляет всем
процессом запуска контейнеров. Это означает, что даже если команда запускается
от имени обычного пользователя, фактическое выполнение происходит с повышенными
правами, через взаимодействие с демоном.

Кроме того, запуск Docker-контейнера требует установки и настройки самого
Docker, что само по себе может быть нетривиальной задачей, особенно в
дистрибутивах, не имеющих полной поддержки по умолчанию. Пользователю нужно не
только понимать архитектуру образов и слоёв, но и быть готовым к созданию
Dockerfile, настройки сети, томов и прочих параметров. Это резко усложняет его
использование в сценариях, где требуется просто и быстро изолировать выполнение
одного-единственного скрипта. Особенно это чувствуется в пользовательских средах
без прав администратора, где установка Docker попросту невозможна без
вмешательства в системную конфигурацию.

Таким образом Docker оказывается не самым подходящим инструментом для цели,
которая была поставлена в данной работе, безопасного и изолированного выполнения
недоверенного кода в пользовательской среде. Его архитектурные особенности,
требования к привилегиям и относительная тяжеловесность делают его избыточным в
ситуациях, где главную роль играют простота, скорость и отсутствие необходимости
в настройке.

### LXC и LXD
LXC (Linux Containers) появился в 2008 году как первая попытка собрать воедино
все возможности изоляции, которые к тому времени уже были в ядре Linux. Он не
требует гипервизора и позволяет запускать процессы прямо на хост-системе, но
так, будто они работают в собственной, полностью отдельной среде. Это делает LXC
лёгким и быстрым по сравнению с классической виртуализацией — никакой эмуляции
железа, минимум накладных расходов, всё работает почти напрямую.

Сильные стороны LXC чувствуются сразу при первоначальном изучении: это
инструмент, который даёт разработчику или системному инженеру практически полный
контроль. Настроить пользовательские идентификаторы, cgroups, capabilities — всё
доступно и подробно настраивается. Но именно эта свобода и становится
опасностью. Без хорошего понимания устройства Linux быстро наткнешься на
тонкости с правами, безопасностью и взаимодействием между контейнером и хостом.

Кроме того, LXC больше ориентирован на долгоживущие контейнеры — с полноценной
init-системой, постоянным состоянием и отдельной жизнью. Для задач временной
изоляции, например, одноразового запуска подозрительного скрипта, его
использование оказывается слишком сложным, тяжеловесным и избыточным.

Со временем, чтобы упростить работу с LXC, появилась надстройка LXD — более
высокоуровневый инструмент, добавляющий REST API, автоматическую конфигурацию,
управление снапшотами и удобную командную строку. При этом сама архитектура
осталась прежней: LXC и LXD позволяют запускать полноценные «системные»
контейнеры, поведение которых близко к виртуальным машинам. Это особенно удобно
для тестирования, развертывания инфраструктуры или изоляции служб в рамках
одного хоста. Что, к сожалению, не является целью данной работы. Таким образом
LXD не является аналогом, а имеет другой вектор направленности.

### Podman
Podman появился в 2018 году как попытка переосмыслить контейнеризацию с учётом
накопленного опыта и слабых мест Docker. Разработанный Red Hat, он с самого
начала стремился решить два главных недостатка предшественника: необходимость
фонового демона и запуск контейнеров с привилегиями.

На первый взгляд, Podman почти неотличим от Docker — команды те же, поведение
схожее, образы совместимы. Но за внешней схожестью скрывается иная архитектура.
Вместо единого демона, который требует root-доступ и централизованно управляет
контейнерами, Podman запускает каждый контейнер как обычный процесс, от имени
пользователя. Это простое на первый взгляд решение меняет очень многое: оно
устраняет потребность в лишнем фоновом сервисе, уменьшает поверхность атаки и
делает систему более предсказуемой.

Особенно хорошо Podman показывает себя в больших системах: там, где важна
безопасность по умолчанию, где root-доступ ограничен, где контейнеры живут долго
и интегрируются в более сложные цепочки — CI/CD, автоматизация, управляемая
инфраструктура.

Тем не менее, несмотря на более современную архитектуру, Podman остаётся прежде
всего инструментом для разработчиков, инженеров и тех, кто регулярно работает с
контейнерами. Для обычного пользователя, перед которым стоит задача запустить
потенциально опасный скрипт в изолированной среде, Podman всё ещё может
показаться громоздким. Нужно установить зависимости, разобраться с тем, как
именно запускаются rootless-контейнеры, как работают user namespaces, как
правильно монтировать директории и т. д. То есть, даже без демона, это всё ещё
контейнерная платформа — мощная, гибкая, но не мгновенно понятная.

## Инструменты с повышенной безопасностью
В неё попадают решения, в которых изоляция и защита явно приоритетнее
производительности, удобства или совместимости. Они создавались не столько ради
запуска абстрактного «контейнера», сколько ради четкой цели: сделать так, чтобы
изолированный процесс точно не повлиял на систему, даже если он полностью
скомпрометирован.

**gVisor**, разработанный Google, — это не контейнерная система в привычном
смысле, а скорее слой между приложением и ядром Linux. Он реализует собственную
«виртуальную» реализацию системных вызовов, фактически создавая второе,
минимальное ядро, работающее в пространстве пользователя. Процессы не получают
прямого доступа к системным вызовам хоста, все обращения к ядру фильтруются и
обрабатываются gVisor-ом. Такая модель изоляции обеспечивает гораздо более
жёсткий контроль и серьезно снижает вероятность выхода из контейнера, но и дает
о себе знать — она медленнее, требовательнее, сложнее в отладке. Особенно это
чувствуется при запуске чего-то не совсем стандартного или ресурсоемкого. Тем не
менее, для запуска подозрительного кода, где риск важнее скорости, gVisor
оказывается вполне подходящим решением.

**Firecracker**, в свою очередь, — продукт Amazon, созданный специально для
запуска микро виртуальных машин (микро-ВМ) в облаке. В отличие от gVisor, он не
эмулирует ядро, а запускает полноценные виртуальные машины поверх KVM, но делает
это настолько быстро и экономно, что граница между виртуализацией и
контейнеризацией почти стирается. Каждая такая микро-ВМ изолирована аппаратно,
загружается за миллисекунды и почти не требует ресурсов. На выходе — уровень
защиты, сравнимый с полноценной виртуалкой, но со скоростью и лёгкостью
контейнеров. Подход впечатляющий, но и требующий. Для использования Firecracker
нужны права администратора, явное управление образами ядра и root-файловой
системой, понимание архитектуры виртуализации. В повседневной разработке он
скорее избыточен, но для инфраструктуры — идеален.

Таким образом, и gVisor, и Firecracker представляют собой шаг в сторону от
классических контейнеров: они сложнее, но и безопаснее. Если задача требует не
просто изоляции, а доверия к этой изоляции — они одни из лучших кандидатов. Но
обычному пользователю, которому просто нужно «чтобы скрипт не тронул систему»,
они могут показаться чересчур громоздкими и требовательными.

## Контейнерные рантаймы низкого уровня
Контейнерные рантаймы низкого уровня — это инструменты, которые обычно остаются
вне поля зрения, но именно они запускают контейнер. Когда мы используем знакомые
утилиты вроде Docker или Podman, всё в итоге сводится к вызову конкретного
рантайма, который берет на себя всю низкоуровневую работу: создает пространства
имён, настраивает ограничения, монтирует нужные директории и запускает процесс.
Большинство пользователей напрямую с ними не взаимодействуют, но от выбора
рантайма зависит, насколько быстро и безопасно будет работать контейнер.

Первым и до сих пор самым распространённым таким инструментом стал **runc**. Он
был создан как часть Docker, а позже стал отдельным проектом под управлением
Open Container Initiative. Его главная ценность — это стандартизованность.
Практически любая платформа, поддерживающая OCI, совместима с runc.

*crun*

*youki*

Таким образом, все три рантайма решают одну и ту же задачу, но с разным
подходом: runc — стабильный, crun — быстрый, youki — безопасный. Однако они
остаются компонентами инфраструктуры — их использование предполагает, что поверх
есть некий управляющий слой. В отрыве от таких систем они пригодны скорее для
интеграции, чем для самостоятельного применения обычными пользователями.

## Инструменты пользовательской изоляции
Одним из заметных решений в области пользовательской изоляции является
**udocker**. Его основная цель — предоставить возможность запуска контейнеров на
системах, где установка Docker невозможна или нежелательна, в первую очередь — в
пользовательском пространстве, без необходимости обладать административными
правами.

*nsjail*

*firejail*

*apparmor*

*bubblewrap*


# Обзор механизмов контейнеризации

## Namespaces
Механизм пространств имён (namespaces) в Linux позволяет изолировать различные
аспекты среды выполнения процессов. С его помощью можно добиться того, чтобы
процессы «не видели» остальную часть системы: они получают ограниченный обзор —
свой собственный PID-пространство, файловую систему, сеть, список пользователей
и т. д. (будет рассмотрено позднее) На практике это означает, что процесс может
считать, что он — единственный на системе, тогда как на самом деле изолирован
лишь его контекст.

Пространства имён стали основой для большинства современных решений по
контейнеризации, так как позволяют задать минимальный уровень изоляции без
обращения к полноценной виртуализации. При этом они не обеспечивают полной
безопасности — лишь создают границы, которые можно использовать в сочетании с
другими механизмами контроля.
