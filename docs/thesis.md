# Список сокращений и условных обозначений
**API** – Application Programming Interface – программный интерфейс приложения  
**CI/CD** – Continuous Integration / Continuous Delivery – непрерывная
интеграция / доставка  
**CLI** – Command Line Interface – интерфейс командной строки  
**CPU** – Central Processing Unit – центральный процессор  
**GUI** – Graphical User Interface – графический интерфейс пользователя  
**KVM** – Kernel-based Virtual Machine – виртуализация на уровне ядра  
**OCI** – Open Container Initiative – стандарт контейнеризации  
**PID** – Process Identifier – идентификатор процесса  
**REST** – Representational State Transfer – архитектурный стиль взаимодействия
с API  
**SSH** – Secure Shell – безопасный протокол удалённого доступа к системе  
**UID** – User Identifier – уникальный идентификатор пользователя  
**VM** – Virtual Machine – виртуальная машина  
**YAML** – YAML Ain't Markup Language – формат сериализации данных, удобный для
конфигураций


# Термины и определения
**Изоляция** – Ограничение взаимодействия процесса с системой – включая файловую
систему, сеть, IPC и идентификаторы пользователей.  
**Контейнер** – Изолированная среда выполнения, позволяющая запускать приложения
с ограниченным доступом к ресурсам системы, используя общее ядро ОС.  
**Rootless контейнер** – Контейнер, запускаемый без привилегий
суперпользователя.  
**Песочница** – Изолированное ограниченное окружение, в котором исполняется
приложение с ограниченными правами.  
**Монтирование** – Процесс привязки файловой системы к определённой директории.  
**Недоверенный код** – Код, источник которого неизвестен или которому нельзя
доверять.  
**Конфигурация окружения** – Набор параметров и настроек, определяющих поведение
изолированной среды: монтируемые директории, права доступа, режимы запуска и
т. д.


# Введение
Несмотря на рост числа киберугроз и общий уровень осведомленности пользователей,
ответственность за обеспечение безопасности по-прежнему в значительной степени
лежит на специалистах по информационной безопасности. Однако даже они не в
состоянии предусмотреть все возможные векторы атак. При этом существует группа
пользователей – разработчики, которые часто работают с недоверенным кодом и
обладают достаточными знаниями, чтобы, например, отключать некоторые меры защиты
(вроде запрета на копирование команд с sudo), но при этом могут не иметь
глубоких технических знаний в области безопасности.

Существующие решения, такие как Docker, LXC, AppArmor, SELinux, systemd-nspawn
или Podman, изначально проектировались для профессионального использования – в
серверных или корпоративных инфраструктурах. Они предполагают наличие повышенных
привилегий, знание внутреннего устройства Linux и часто требуют предварительной
настройки. Более того, многие из них ориентированы не на запуск отдельных
процессов, а на полноценную оркестрацию окружений: с настройкой томов, сетей,
ресурсов, зависимостей, политик безопасности и доступа.

В результате попытка использовать такие инструменты для простой задачи –
например, разовое исполнение небольшого скрипта, скопированного с форума или
сгенерированного нейросетью – приводит к тому, что пользователь отказывается от
идеи изоляции вовсе. Так как он вряд ли будет готов тратить неоправданно много
времени на чтение документации и написание конфигурации ради скрипта, который,
как ему кажется, будет работать пару секунд. В результате вопрос изоляции и
безопасности откладывается «на потом» – до первого инцидента.

А так как проблема безопасного исполнения недоверенного кода сегодня стоит не
только перед специалистами в области информационной безопасности, но и перед
широкой аудиторией пользователей, которые регулярно сталкиваются с
необходимостью запускать потенциально опасные программы, то ее решение требует
инструментов новой направленности – достаточно надёжных, чтобы обеспечить
защиту, и достаточно простых, чтобы их было удобно использовать по принципу
«одна команда – и системе ничего не угрожает» (в большинстве случаев).

Целью данной работы является создание удобного в использовании инструмента,
позволяющего запускать недоверенный код в изолированной среде без необходимости
в привилегированных операциях и сложной конфигурации.

Для достижения поставленной цели необходимо решить следующие задачи:
1. Проанализировать существующие инструменты контейнеризации и их ограничения.
1. Определить ключевые требования к программному решению с учетом безопасности и
   удобства использования.
1. Разработать архитектуру программного решения.
1. Реализовать прототип программного решения.
1. Провести тестирование прототипа на соответствие требуемым критериям.


# Обзор существующих решений
Для формирования целостного представления о современных инструментах для
изоляции был проведен первичный сбор данных из нескольких авторитетных
источников. Основой для начального анализа послужили следующие ресурсы:

- awesome-linux-containers – Подборка фреймворков, библиотек и программного
  обеспечения для Linux-контейнеров;
- awesome-containers – Подборка технологий, связанных с Linux-контейнерами,
  вдохновлённая другими "Awesome" списками;
- Open Repository for Container Tools – Коллекция инструментов с открытым исходным
  кодом для создания, настройки и работы с контейнерами.

На основании информации из указанных источников была составлена обобщенная
таблица, включающая свыше восьмидесяти инструментов, связанных с изолированным
исполнением кода. Для сужения круга анализа использовались три критерия,
значения которых в работе зафиксированы на момент 20.04.2025:

- Популярность проекта оценивается с использованием открытых количественных
  метрик, таких как количество звёзд (число пользователей, добавивших проект в
  избранное) на GitHub или аналогичных показателей на других платформах. Эти
  метрики отражают уровень вовлеченности и интереса сообщества к проекту.
- Актуальность разработки: проект не должен находиться в архиве и иметь
  коммиты, слитые PR или решенные проблемы (issues) в течение последнего года –
  это исключает заброшенные и потенциально небезопасные решения.
- Открытый исходный код – это позволяет обеспечить прозрачность, проверяемость
  и возможность модификации кода сообществом, что критично для доверия и
  долгосрочной поддержки инструментов.

После фильтрации получилась выборка инструментов. Она представлена в таблице 1.

Таблица 1 – Отфильтрованный список инструментов.
| Название   | Звезд | Активность | Описание |
|------------|-------|------------|----------|
| **docker** | 69600 | 2025-04-20 |          |

Из данного списка были отобраны только те инструменты, основной задачей которых
является создание изолированной среды исполнения. Средства, предназначенные
исключительно для вспомогательных задач – таких как аудит, мониторинг, отладка
или анализ контейнеров – в обзор не включались.

Отобранные инструменты можно условно разделить на несколько групп. Первую
составляют полноценные системы управления контейнерами. Эти инструменты
предоставляют полный цикл работы с контейнерами: от подготовки образов до
управления жизненным циклом окружений.

Во вторую входят решения, сфокусированные на безопасности. Они применяют
аппаратную или программную изоляцию, моделируют системные вызовы или используют
собственные интерфейсы, снижая вероятность выхода процесса за пределы
контролируемого пространства.

Третья – низкоуровневые инструменты, соответствующие спецификации OCI, которые
не управляют окружением целиком, а отвечают только за непосредственный запуск
контейнера в уже подготовленной среде.

Инструменты из каждой группы решают свои задачи и подходят под разные сценарии,
рассмотрим их дальше по отдельности.

## Контейнерные менеджеры
Такие решения, как Docker, LXC/LXD и Podman, выходят за рамки задач изоляции как
таковой – они предоставляют полноценную инфраструктуру для упаковки, запуска и
управления приложениями в контейнерной среде. Их пользователь получает развитую
экосистему – от форматов образов и репозиториев до инструментов сетевой
настройки, логирования и мониторинга.

### Docker
Docker был разработан в 2013 году компанией dotCloud (впоследствии
переименованной в Docker Inc.) и за считанные годы стал одной из самых
узнаваемых технологий в мире разработки и эксплуатации программного обеспечения.
Он появился в тот момент, когда индустрия остро нуждалась в стандартизированном
способе упаковывать приложения вместе со всеми зависимостями, не полагаясь на
особенности окружения, в котором они будут запущены. Уже к 2015 году Docker
приобрел массовую популярность, а его экосистема начала стремительно расти:
появились реестры образов, инструменты оркестрации и полноценные
DevOps-платформы, основанные на контейнерах.

Тем не менее, при всех своих достоинствах, таких как высокая популярность и
экосистема, удобство использования, поддержка образов, оркестрация,
портируемость и стандартизация рабочих процессов, Docker не всегда подходит для
других задач – в частности, для изоляции недоверенного кода в пользовательских
сценариях. Архитектура Docker построена вокруг отдельного фонового демона
dockerd, который запускается с привилегиями суперпользователя и управляет всем
процессом запуска контейнеров.

Также в пользовательских средах без прав администратора, установка Docker
попросту невозможна без вмешательства в системную конфигурацию. Все
вышеперечисленное резко усложняет его использование в сценариях, где требуется
просто и быстро изолировать выполнение одного единственного скрипта.

### LXC и LXD
LXC (Linux Containers) появился в 2008 году как первая попытка собрать воедино
все возможности изоляции, которые к тому времени уже были в ядре Linux. Он не
требует гипервизора и позволяет запускать процессы прямо на хост-системе, но
так, будто они работают в собственной, полностью отдельной среде. Это делает LXC
лёгким и быстрым по сравнению с классической виртуализацией – никакой эмуляции
железа, минимум накладных расходов.

Сильные стороны LXC видны сразу при первоначальном изучении: это инструмент,
который даёт разработчику или системному инженеру практически полный контроль.
Настроить пользовательские идентификаторы, cgroups, capabilities – всё доступно
и подробно настраивается. Но именно эта свобода и становится опасностью. Без
глубокого знания Linux неизбежно возникнут сложности с правами, безопасностью и
интеграцией контейнера с хост-системой.

Кроме того, LXC больше ориентирован на долгоживущие контейнеры – с полноценной
init-системой и постоянным состоянием. Для задач временной изоляции, например,
одноразового запуска подозрительного скрипта, его использование оказывается
слишком сложным, тяжеловесным и избыточным.

Со временем, чтобы упростить работу с LXC, появился LXD – более высокоуровневый
инструмент, добавляющий REST API, автоматическую конфигурацию, управление
снапшотами и удобную командную строку. При этом сама архитектура осталась
прежней: LXC и LXD позволяют запускать полноценные «системные» контейнеры,
поведение которых близко к виртуальным машинам.

### Podman
Podman появился в 2018 году как попытка переосмыслить контейнеризацию с учётом
накопленного опыта и слабых мест Docker. Разработанный Red Hat, он с самого
начала стремился решить два главных недостатка предшественника: необходимость
фонового демона и запуск контейнеров с привилегиями.

На первый взгляд, Podman почти неотличим от Docker – команды те же, поведение
схожее, образы совместимы. Но за внешней схожестью скрывается иная архитектура.
Вместо единого демона, который требует root-доступ и централизованно управляет
контейнерами, Podman запускает каждый контейнер как обычный процесс, от имени
пользователя. Это простое на первый взгляд решение меняет очень многое: оно
устраняет потребность в лишнем фоновом сервисе, уменьшает поверхность атаки и
делает систему более предсказуемой.

Особенно хорошо Podman показывает себя в системах: где важна безопасность по
умолчанию, где root-доступ ограничен, где контейнеры живут долго и интегрируются
в более сложные цепочки – CI/CD, автоматизация, управляемая инфраструктура.

Тем не менее, несмотря на более современную архитектуру, Podman остаётся прежде
всего инструментом для разработчиков, инженеров и тех, кто регулярно работает с
контейнерами. Для обычного пользователя, перед которым стоит задача запустить
потенциально опасный скрипт в изолированной среде, Podman всё ещё может
показаться громоздким. Нужно установить зависимости, разобраться с тем, как
именно запускаются rootless-контейнеры, как работают user namespaces, как
правильно монтировать директории и т. д. То есть, даже без демона, это всё ещё
контейнерная платформа – мощная, гибкая, но не очевидно понятная.

## Инструменты с усиленной безопасностью
В неё попадают решения, в которых изоляция и защита явно приоритетнее
производительности, удобства или совместимости.

### gVisor
gVisor, разработанный Google, – реализует собственную «виртуальную» реализацию
системных вызовов, фактически создавая второе, минимальное ядро, работающее в
пространстве пользователя. Процессы не получают прямого доступа к системным
вызовам хоста, все обращения к ядру фильтруются и обрабатываются gVisor-ом.
Такая модель изоляции обеспечивает гораздо более жёсткий контроль и серьезно
снижает вероятность выхода из контейнера, но и дает о себе знать – она
медленнее, требовательнее, сложнее в отладке.

### Firecracker
Firecracker – продукт Amazon, направленный на запуск микро виртуальных машин
(микро-ВМ) в облаке. В отличие от gVisor, он не эмулирует ядро, а запускает
полноценные виртуальные машины поверх KVM, но делает это настолько быстро и
экономно, что граница между виртуализацией и контейнеризацией почти стирается.
Каждая такая микро-ВМ изолирована аппаратно, загружается за миллисекунды и почти
не требует ресурсов. На выходе – уровень защиты, сравнимый с полноценной
виртуалкой, но со скоростью и лёгкостью контейнеров. Для использования
Firecracker нужны права администратора, явное управление образами ядра и
root-файловой системой, понимание архитектуры виртуализации. В повседневной
разработке он скорее избыточен, но для инфраструктуры – идеален.

## Контейнерные рантаймы низкого уровня
Такие решения, как runc, crun и youki, работают на более низком уровне – они
занимаются исключительно созданием и запуском контейнеров на основе уже
подготовленного окружения. Эти компоненты отвечают за непосредственную работу с
пространствами имён, cgroups и mount-системами, реализуя минимальный необходимый
набор операций для запуска изолированного процесса.

### runc
runc – это эталонная реализация контейнерного рантайма, разрабатываемая в рамках
проекта Open Container Initiative (OCI). Его задача – запустить процесс в
окружении, которое соответствует спецификации контейнер. Это runc делает
напрямую, используя системные вызовы Linux.

При этом сам runc не заботится об удобстве пользователя: он не скачивает образы,
не управляет томами, не настраивает сеть. Так как он предназначен для запуска
другими инструментами – например, containerd или Docker, – когда уже нужно
подготовить и запустить контейнер в соответствии с заранее описанным
config.json.

### crun
crun – это легковесная и быстрая реализация контейнерного рантайма, полностью
совместимая со спецификацией OCI. В отличие от runc, написанного на Go, crun
реализован на C – это позволяет ему работать быстрее и занимать меньше системных
ресурсов. Что заметно при массовом запуске контейнеров или в системах с
ограниченными ресурсами. Также он поддерживает больше современных возможностей
ядра Linux, таких как cgroup v2, seccomp notify и systemd-интеграция.

### youki
youki – это контейнерный рантайм, разрабатываемый на языке Rust, с акцентом на
безопасность, читаемость кода и архитектурную строгость. Он также реализует
спецификацию OCI и служит аналогом runc и crun. Его основная цель – предложить
надёжную, легко сопровождаемую и безопасную альтернативу существующим рантаймам.
Использование Rust позволяет минимизировать риски, связанные с типичными
уязвимостями вроде ошибок управления памятью, которые критичны для программ,
работающих с низкоуровневыми механизмами Linux.

## Инструменты пользовательской изоляции
Инструменты, такие как uDocker, FireJail и bubblwrap, можно отнести к категории
утилит пользовательской изоляции – они не требуют прав суперпользователя и
работают в рамках возможностей обычного пользователя, предоставляя при этом
базовые или расширенные механизмы ограничения окружения. Их цель – предоставить
лёгкий и контролируемый способ запускать недоверенные или ограниченные процессы,
без вмешательства в системную конфигурацию и без необходимости поднимать службы.

### uDocker
udocker – это инструмент, который позволяет запускать контейнеризированные
приложения без привилегий и без установленного Docker-демона. Он ориентирован на
пользователей, работающих в ограниченных средах, например, в научных вычислениях
или на кластерах, где доступ к root закрыт и установка системных контейнеров
невозможна.

udocker не использует стандартные механизмы контейнеризации ядра напрямую.
Вместо этого он применяет комбинации пользовательских пространств имён, PRoot,
chroot и других приёмов, чтобы создать изолированное окружение. Он может
запускать образы в формате Docker, что делает его удобным мостом между
стандартной экосистемой и ограниченными средами исполнения. Инструмент написан
на Python и ориентирован в первую очередь на переносимость.

### nsjail
nsjail представляет собой инструмент для создания изолированных окружений,
ориентированный на детальный контроль над процессами и их взаимодействием с
системой. В его основе лежат механизмы пространств имён и фильтрация системных
вызовов через seccomp, что позволяет ограничивать доступ к ресурсам на уровне
ядра. Особенностью nsjail является гибкая настройка политик безопасности: можно
задать ограничения на использование памяти, времени выполнения и доступных
системных вызовов. При этом nsjail сохраняет низкие накладные расходы, что
выделяет его на фоне решений, использующих аппаратную виртуализацию или эмуляцию
системных вызовов.

В отличие от инструментов, которые стремятся к максимальной совместимости с
существующими экосистемами (например, Docker), nsjail фокусируется на
минимальной поверхности атаки. Он не требует привилегий суперпользователя для
запуска, что соответствует концепции rootless-контейнеров, однако для полной
функциональности может потребоваться предварительная настройка ядра и правил
seccomp. Это ограничивает его применение в средах, где пользователи не имеют
возможности изменять системные настройки.

### FireJail
Firejail представляет собой инструмент для изоляции приложений, ориентированный
на упрощение защиты пользовательских процессов в Linux-системах. В его основе
лежат механизмы пространств имён и фильтрация системных вызовов через
seccomp-bpf, что позволяет ограничивать взаимодействие приложений с системными
ресурсами. Особенностью Firejail является использование предопределённых
профилей безопасности, которые автоматически применяют политики изоляции для
популярных программ (например, браузеров, медиаплееров или офисных приложений).
Это делает его удобным для быстрой настройки среды без ручного конфигурирования.

В отличие от инструментов, требующих глубокой интеграции с инфраструктурой
(таких как Docker или LXC), Firejail фокусируется на изоляции отдельных
процессов в рамках существующей системы. Он не требует запуска фоновых служб или
сложной подготовки образов. Однако для реализации части функций (например,
монтирования системных директорий) могут потребоваться права суперпользователя,
что частично ограничивает его применение в строго rootless-сценариях. При этом
Firejail сохраняет совместимость с графическими приложениями, интегрируясь в
десктоп-окружения через стандартные механизмы запуска (например,
.desktop-файлы).

Стоит отметить, что Firejail активно используется в сценариях, где требуется
защита от уязвимостей в популярных приложениях, а не только изоляция
недоверенного кода. Его архитектура, сочетающая готовые профили и гибкие
настройки, делает его подходящим для повседневного применения в
десктоп-системах, где пользователи ищут компромисс между безопасностью и
функциональностью.

### bubblewrap
bubblewrap представляет собой минималистичный инструмент для изоляции процессов,
основанный на механизмах пространств имён Linux. Его ключевая особенность –
возможность запуска приложений в изолированном окружении без необходимости в
привилегиях суперпользователя, что соответствует концепции rootless-контейнеров.
В отличие от более сложных систем, bubblewrap фокусируется на базовой изоляции
файловой системы, сети и процессов, предоставляя пользователю прямой контроль
через командную строку. Инструмент не требует предварительной настройки демонов
или сложных конфигурационных файлов – все параметры задаются через аргументы
командной строки, что делает его удобным для интеграции в скрипты или
автоматизированные сценарии.

По сравнению с nsjail и firejail, bubblewrap отличается предельной простотой и
низкими накладными расходами. Он не включает встроенных профилей безопасности
или автоматических политик, предоставляя разработчику полную свободу в настройке
окружения. Это делает его оптимальным выбором для сценариев, где требуется
точечная изоляция процессов без избыточной функциональности.

На сегодняшний день bubblewrap активно используется в экосистеме Flatpak для
запуска приложений в изолированных средах, что подтверждает его надёжность и
соответствие требованиям современных дистрибутивов. Реализованный на языке C, он
демонстрирует высокую производительность и минимальное потребление ресурсов,
сохраняя фокус на безопасности и лёгкости интеграции.


# Обзор механизмов контейнеризации
Контейнеризация в Linux – это не отдельная технология, а набор функциональных
компонентов, встроенных в ядро. Они решают разные задачи, но собираются вместе,
когда нужно ограничить процесс: в доступе к системе, в использовании ресурсов, в
поведении. Изначально эти механизмы создавались для других целей – например,
учёт ресурсов в многопользовательских системах или изоляция сетевых стеков – но
со временем оказалось, что они хорошо сочетаются. И можно обойтись без
виртуальной машины, если достаточно просто задать жесткие рамки.

## Namespaces
Если нужно, чтобы запущенный процесс не взаимодействовал напрямую с остальной
системой, первым шагом почти всегда становится использование пространств имён.
Они позволяют изолировать отдельные части окружения так, что каждый процесс
видит свою «копию» этих ресурсов, не влияющую на остальную систему.

Эта идея оказалась настолько гибкой, что на неё теперь опирается почти всё, что
связано с контейнерами, так как позволяют задать минимальный уровень изоляции
без обращения к полноценной виртуализации.

Данный механизм детальнее будет рассмотрен позднее.

## cgroups
Когда среда изолирована, остаётся вопрос – сколько ресурсов ей можно дать. Без
ограничений один процесс может занять всю память или загрузить процессор до
предела. Контроль за этим берут на себя cgroups (control group). Они разбивают
доступные ресурсы на группы и распределяют их между процессами. И делают это на
уровне ядра, что гарантирует предсказуемость: даже если процесс пытается обойти
ограничения, они всё равно срабатывают. Поддерживаются ограничения на CPU,
память, ввод-вывод и другие подсистемы. Вторая версия cgroups упростила
конфигурацию и сделала поведение более стабильным, но общая логика осталась
прежней.

## Seccomp
Ограничить видимость и ресурсы недостаточно для надежной изоляции, так как
процесс может делать произвольные системные вызовы. Чаще всего это mount,
ptrace, execve и другие критичные операции, через которые можно повлиять на
окружение. Именно тут вступает в силу Seccomp (secure computing mode). Он
позволяет фильтровать какие вызовы разрешены, а какие нет. Всё, что выходит за
пределы, блокируется. Это снижает риск так как даже если процесс получил доступ
к какому-то ресурсу, без системного вызова он не сможет им воспользоваться.

## SElinux
SELinux представляет собой дополнительный уровень контроля, который работает не
через изоляцию или ограничение ресурсов, а через систему политик. Она задаёт,
какие процессы и при каких условиях могут взаимодействовать с другими
компонентами системы. Даже если у приложения формально есть права, и оно
выполняется в изолированном окружении, SELinux может запретить доступ к ресурсу,
если такой доступ не прописан явно.

В контексте rootless-инструментов – то есть утилит, работающих без прав
суперпользователя – SELinux выступает как внешняя система правил, полностью
находящаяся вне зоны управления приложения: процесс не знает о его наличии
напрямую, не может изменить активную политику, переключить режим работы или
запросить дополнительные разрешения. Ошибка будет выглядеть как обычный отказ в
доступе, без явной связи с SELinux.


# Linux namespaces
Linux namespaces – это один из основных механизмов, лежащих в основе
контейнеризации. Именно благодаря ним процессы в изолированных окружениях «не
видеть» друг друга, как будто работают на разных машинах, хотя физически
находятся на одном ядре. Это не какая-то новая надстройка, а часть ядра Linux,
развивающаяся уже более двух десятилетий.

Первые шаги в сторону изоляции в Linux начались еще в начале 2000-х годов, но в
полноценную систему пространства имён оформились с появлением CLONE_NEWNS в ядре
2.4.19 (2002 год), а позже начали появляться и остальные. Их развитие шло
постепенно: один namespace – одна изолированная часть системы. Всё вместе это
позволяет запускать процесс в «песочнице», где у него свои PID'ы, свои
смонтированные директории, своя сеть и даже свой root-пользователь, не
совпадающий с root'ом на хосте.

Интересный исторический момент связан с тем, почему именно namespace
монтирования в системных вызовах обозначается как CLONE_NEWNS, а не, скажем,
CLONE_NEWMOUNT. Всё дело в том, что он был первым реализованным пространством
имен в ядре Linux. На тот момент ещё не существовало общей концепции
"namespaces" как набора взаимосвязанных механизмов – был просто механизм
изоляции точек монтирования, и сокращённое newns (от new namespace) казалось
вполне логичным. Уже позже, когда начали появляться другие типы пространств
имён, их стали именовать более явно: CLONE_NEWPID, CLONE_NEWNET, CLONE_NEWUSER и
так далее.

Основная идея namespaces – обеспечить процессу видимость работы в собственной
системе. При этом, в отличие от виртуальных машин, здесь нет полной эмуляции:
ядро одно, ресурсы общие, а изоляция реализована средствами самого ядра, что
делает такую модель намного более легкой и быстрой.

Благодаря этому namespaces стали основой для таких инструментов, как Docker,
LXC, Podman, Firejail, Bubblewrap и других. Они позволяют запускать процессы в
контейнерах на том же ядре без виртуализации и без необходимости поднимать
отдельную ОС. Более того, namespaces можно использовать напрямую – например, с
помощью unshare или более удобных оберток (инструментов, упрощающих работу с
низкоуровневыми функциями).

## User namespace
User namespace – один из ключевых механизмов изоляции в Linux, появившийся в
ядре 3.8, который позволяет процессам внутри изолированной среды иметь отличные
от хостовых идентификаторы пользователя и групп. Благодаря этому обычный
пользователь может запустить процесс с правами root внутри контейнера, не
получая настоящего root-доступа на системе. Другими словами, пространство имен
user позволяет запускать «привилегированные» процессы в изолированной среде, где
эти привилегии действуют только внутри и не имеют силы за её пределами. Эта
особенность сделала возможным появление rootless-контейнеров, которые можно
запускать без повышенных прав.

На практике оно часто используется вместе с другими пространствами имён,
поскольку доступ к ним (например, к монтированию файловых систем или созданию
собственных PID-деревьев) тоже требует user namespace.

## Mount namespace
Mount namespace даёт каждому контейнеру своё собственное представление о том,
как устроена файловая система. Это позволяет перенастроить точки монтирования
так, чтобы процессы внутри видели только то, что им разрешено, и в том виде, в
каком это задумал автор окружения. Директории можно подменить, сделать
доступными только для чтения, заменить на временные или вообще исключить – всё
это будет касаться только контейнера, а хост же останется нетронутым. Один и тот
же файл, но в разных пространствах имен может оказаться в совершенно разных
местах, с разными правами и даже под разными именами.

В Linux, где почти всё – это файл: устройства, процессы, сокеты, настройки –
возможность контролировать, какие именно файлы видны и как они доступны,
оказывается критически важной. Неудивительно, что именно пространство имен mount
появилось первым: он дает очень точный и мощный инструмент управления средой
исполнения.

## UTS namespace
UTS namespace отвечает за изоляцию идентификаторов хоста – имени машины
(hostname) и домена (domainname). Это может показаться несущественным по
сравнению с пространствами имён, которые изолируют процессы или файловую
систему, но на практике дает важную гибкость. Это удобно и для организации
логов, и для отладки, и просто для визуального разделения сред.

## PID namespace
PID namespace изолирует процессы: внутри него каждый запущенный процесс получает
собственный идентификатор, независимый от остальной системы. Это значит, что
контейнер не только не будет иметь доступа к процессам за пределами своего
пространства имен, но и также даже не знать о их существовании.

Особенно важно то, что внутри такого namespace можно создать собственное дерево
процессов с отдельным init-процессом (обычно с PID 1), который будет выполнять
те же функции, что и в полноценной системе – обрабатывать сигналы, управлять
жизненным циклом дочерних процессов и так далее. Это приближает поведение
контейнера к виртуальной машине, но без всей тяжести гипервизоров.

## Network namespace
Network namespace позволяет каждому контейнеру иметь собственный сетевой стек.
Это значит, что у него будут свои интерфейсы, таблицы маршрутизации, правила
iptables, сокеты и даже отдельный экземпляр loopback-интерфейса (lo). В
результате контейнер можно отключить от сети вовсе, подключить к виртуальному
мосту, настроить NAT или дать прямой доступ к физическому интерфейсу – всё это
делается независимо от основной системы.

Такой подход особенно удобен для сценариев, где важно контролировать, с кем и
как общается запущенный процесс. Например, можно запустить подозрительное
приложение с полной изоляцией от интернета, сохранив при этом доступ к локальным
файлам. Или наоборот – дать выход в сеть, но запретить доступ к внутренним
сервисам хоста.

## IPC namespace
IPC (Inter-Process Communication) namespace отвечает за изоляцию механизмов
межпроцессного взаимодействия – таких как очереди сообщений, семафоры и общая
память. Без него процессы внутри разных контейнеров могут оказывать влияние друг
на друга (использовать одни и те же участки общей памяти и т. д.).


# Проектирование архитектуры
В этой главе определяется стек технологий, используемый при разработке утилиты –
от механизмов изоляции и готовых низкоуровневых инструментов до языка
программирования и сопутствующих библиотек.

## Выбор инструментов изоляции
Разработка механизма изоляции «с нуля» – через прямое использование clone,
unshare и других системных вызовов – даёт высокий уровень контроля: можно явно
задать, какие пространства имён использовать, как накладываются ограничения и в
каком порядке. Но такой подход плохо масштабируется в рамках прикладных утилит.
Эти вызовы чувствительны к контексту выполнения: важен порядок операций, права
процесса на каждом этапе, то, какие вызовы уже были сделаны. Ошибка в одном
месте может привести к тому, что изоляция окажется неполной, или, наоборот,
процесс потеряет доступ к нужным ресурсам. В некоторых случаях нужно заранее
сбросить привилегии, в других – наоборот, сохранить их до определённого момента.
Это делает реализацию хрупкой и трудно расширяемой.

И когда дело касается инструментов для виртуализации, в первую очередь внимание
падает на LXC. Это зрелое решение, позволяющее разворачивать контейнеры, близкие
по поведению к полноценным системам. У него широкие возможности: отдельная сеть,
снапшоты, интеграция с init-системой. Но всё это сказывается на использовании –
LXC рассчитан на долгоживущие контейнеры, где важна устойчивость и контроль. В
контексте кратковременных изолированных процессов – его использование не
оправдано.

AppArmor использует другой подход. Это не контейнер, а фильтр – он описывает, к
каким ресурсам может обращаться программа. Это мощный механизм, особенно в
сочетании с остальной политикой безопасности системы. Но для динамического
запуска или гибкой настройки под каждый новый скрипт он подходит плохо. Профили
создаются отдельно, требуют установки и не меняются на лету. Его применение
имеет смысл тогда, когда известно поведение программы и оно не будет меняться.

Сравнивая bubblewrap, nsjail и firejail, можно выделить ключевые различия.
nsjail фокусируется на детальном контроле системных вызовов и ресурсов, что
делает его подходящим для сценариев, где критична защита от низкоуровневых
уязвимостей. Однако его гибкость сопровождается сложностью конфигурации и
значительным объёмом кода, что усложняет интеграцию в минималистичные решения.
Firejail, напротив, предлагает готовые профили безопасности и удобство
использования, но требует прав суперпользователя для части функций, что
ограничивает его применение в строго rootless-сценариях.

bubblewrap выделяется на фоне остальных своей минималистичной моделью: никаких
файлов конфигурации, никаких профилей, только командная строка, в которой
напрямую указывается, какие изоляции применить. Он создавался как часть Flatpak
и ориентирован на запуск приложений от обычного пользователя. Пространства имён,
tmpfs, readonly точки монтирования, ограничение доступа – всё явно прописывается
при запуске.

## Выбор языка программирования
Когда базовая технология изоляции определена – в данном случае это Bubblewrap –
остаётся решить, каким образом строить вокруг нее удобную оболочку. Сам
Bubblewrap – это утилита командной строки, и взаимодействие с ней всегда
сводится к вызову процесса с набором параметров. Подход прямой, но быстро
становится громоздким: количество флагов растёт, логика усложняется, а
необходимость реагировать на разные сценарии требует хоть какой-то структуры.

На этом этапе становится ясно, что нужен язык, в котором можно было бы быстро
собрать утилиту, обрабатывающую аргументы, управляя логикой подготовки окружения
и запуском. Python оказался уместным выбором. Код на Python легко читается,
стандартная библиотека закрывает почти все базовые потребности – от работы с
путями и файлами до запуска процессов и логирования. Никакой дополнительной
сборки или компиляции не требуется, зависимости минимальны, запуск возможен на
большинстве современных Linux-систем без установки дополнительных компонентов,
Python чаще всего входит в стандартную поставку.

Это не самый производительный инструмент, но в этой задаче и не требуется
высокая производительность, так как это не CPU-bound задача. Гораздо важнее
простота изменений и прозрачность логики.


# Создание прототипа
Данная глава детализирует процесс создания прототипа для псевдо-изолированного
(или изолированного, в зависимости от настроек запуска) исполнения кода.
Рассматриваются используемые библиотеки, общая структура с описанием
предназначения каждого модуля (файла) и каждой функции.

## Библиотеки
**argparse** – стандартный инструмент для обработки аргументов командной строки.
Главное удобство в том, что описание структуры аргументов и разбор фактически
переданных значений аргументов объединяются в одном месте: один раз описываются
флаги, типы значений, что является обязательным, а что – опциональным. Дальше
argparse сам разбирает всё на нужные элементы, проверяет корректность, выдает
ошибки при неверном вводе и даже генерирует документацию, которую не нужно
писать отдельно, что намного удобнее чем обрабатывать sys.argv вручную.

Кроме этого, argparse полезен в архитектуре, где параметры можно задавать не
только для одной команды, но и как составные части – например, с флагами,
которые активируют разные режимы работы. Учитывая, что основа инструмента
строится вокруг запуска изолированных окружений с множеством вариантов – таких
как приватный том, оверлей, сохранение состояния, удаление и т. д. – без чёткого
описания структуры командной строки всё быстро деградировало бы в сложно
поддерживаемую кодовую базу с множеством условных операторов.

**shlex**, в отличие от argparse, работает на другом уровне – он парсит строки в
формате shell. Это удобно, если некоторые параметры передаются как готовый кусок
командной строки, который нужно разложить на отдельные аргументы, чтобы
корректно обработать дополнительные флаги, которые нужно просто передать дальше
без вмешательства. Потому что независимо от того, насколько много сценариев
использования можно предусмотреть, не стоит ограничивать пользователя, который
умеет работать с linux namespaces, от более точной настройки окружения.

**logging** позволяет управлять уровнем сообщений: во время разработки можно
включить подробный отладочный режим, а в стабильной сборке – оставить только
предупреждения и ошибки. Всё это без переписывания кода. Вместо того чтобы раз
за разом закомментировать строки с отладочным выводом, достаточно поменять
уровень логирования – и инструмент становится тише.

Кроме того, можно точно настроить формат сообщений: добавить время, имя файла,
строку, уровень важности. Это особенно полезно, если лог пишется в файл или
используется в CI. В случае ошибок будет видно не только что пошло не так, но и
где именно, и при каких условиях.

Работа с окружением на низком уровне редко обходится без стандартных библиотек
sys, os, shutil и pathlib. Все они решают разные задачи, и каждая из них дает
удобный доступ к какой-то стороне взаимодействия с операционной системой.

**sys** – один из базовых модулей. Он нужен для работы с аргументами командной
строки, завершения программы с нужным кодом или, например, перенаправления
вывода ошибок и прямое взаимодействие с механизмами, которые предоставляет сам
интерпретатор.

**os** – это удобная обертка над API операционной системы. Работа с переменными
окружения, запуск внешних процессов, создание директорий, установка прав.

**shutil** предоставляет функции для работы с файлами и директориями, которые
выходят за рамки возможностей os, такие как рекурсивное удаление, копирование и
перемещение.

## Общая структура
Проект состоит из нескольких модулей:

- __main__.py – точка входа в приложение, отвечает за обработку аргументов
  командной строки, построение параметров вызова bubblewrap;
- conf.py – отвечает за загрузку и интерпретацию конфигурационных файлов, в
  которых задаются дополнительные пути, доступные в изолированной среде;
- path.py – модуль, реализующий функцию расширенного поиска по шаблонам путей с
  использованием переменных окружения и регулярных выражений.

### Основная логика (main.py)
Запуск начинается с проверки наличия bubblewrap в системе – если он отсутствует,
выполнение завершается. Далее обрабатываются аргументы, среди которых можно
указать:

- имя окружения (если не указано, выводится автоматически из имени исполняемого
  файла или программы);
- режим изоляции домашней директории;
- подключение сетевого пространства имен;
- директории конфигурации и хранилища;
- дополнительные флаги очистки или удаления;
- аргументы, которые будут напрямую переданы в bubblewrap (для большей
  гибкости).

Если изоляция ранее не создавалась, для нее создается каталог, в котором, в
зависимости от режима, размещаются либо верхний слой overlayfs, либо привязанный
подкаталог для монтирования. Сбор аргументов bubblewrap происходит поэтапно:
сначала флаги пространств имён, затем базовые монтирования (/, /proc, /dev),
затем – домашний каталог, текущая директория (если указано), runtime-пути, и
пути из конфигурационных файлов. Конфигурация может быть задана как общая
(default.cfg), так и специфичная для конкретного приложения.

После подготовки всех аргументов производится вызов os.execvp, передающий
управление bubblewrap.

### Конфигурация (conf.py)
Загрузка конфигурации построена на двухуровневой модели: если присутствует файл,
специфический для текущего окружения, он используется в первую очередь. В
противном случае подгружается общий файл. При первом запуске, если ни один файл
не существует, создается шаблон с базовыми runtime-директориями – это минимально
необходимый набор, чтобы GUI-приложения могли запуститься в Wayland-сессии

### path.py
Данный модуль предоставляет собственную реализацию glob функции, позволяющую
интерпретировать шаблоны с переменными окружения и полноценными регулярными
выражениями, обеспечивая гибкость при описании путей. В стандартной библиотеке
Python для этих целей используется модуль pathlib, реализующий механизм
сопоставления путей с шаблонами, аналогичный Unix shell-стилю. Однако
стандартный pathlib.glob имеет ряд ограничений, препятствующих его использованию
в более сложных сценариях. В частности, он не поддерживает переменные окружения
и регулярные выражения, что значительно снижает его гибкость.

Для решения данной проблемы был реализован собственный модуль, предоставляющий
расширенную версию функции. Во-первых, он позволяет формировать шаблоны путей,
динамически зависящие от окружения. А во-вторых, поддерживает регулярные
выражения (regex). В частности, становится возможным явно задавать границы строк
(^, $), использовать квантификаторы (+, *, ?), группы, классы символов ([0-9],
[a-z], и т. д.).

Примером практической задачи, в которой стандартный glob оказывается
недостаточным, может служить необходимость отличить файл «wayland-1» от
«wayland-1.conf». При использовании шаблона «wayland-*» оба файла будут найдены,
так как шаблон соответствует любой последовательности символов после префикса
«wayland-». Однако если требуется выбрать только файлы с числовыми суффиксами,
например «wayland-1», «wayland-2», и исключить конфигурационные файлы вроде
«wayland-1.conf», стандартный инструмент оказывается неприменим. В разработанном
решении для этого можно использовать шаблон «wayland-[0-9]+$».

## Функции
**parse_args()** – данная функция является стандартным паттерном при работе с
библиотекой argparse. Она задает аргументы командной строки, настраивает их
параметры и поведение, специальным образом обрабатывает варианты по умолчанию и
введенные значения, а затем возвращает их в удобном объекте.

**check_bwrap()** – простейшая проверка, без которой запуск не имеет смысла.
Убеждается, что bubblewrap установлен в системе, иначе печатает сообщение об
ошибке и прерывает выполнение. bwrap – это единственный внешний бинарный модуль,
от которого зависит wraplify.

**main()** – главная точка входа в приложение. Сначала вызывается check_bwrap()
– без него дальнейшие действия невозможны, так как bubblewrap является
необходимой зависимостью разработанной утилиты. Затем разбираются аргументы с
помощью parse_args().

После этого начинается формирование аргументов для bubblewrap. Включаются
стандартные неймспейсы (--unshare-*), защита от зомби (--die-with-parent),
монтирование системных директорий (/proc, /dev, /run). Затем добавляется логика,
связанная с домашним каталогом: либо временный tmpfs, либо overlay с верхним
уровнем, либо постоянный bind.

Аналогично добавляются текущая директория и XDG_RUNTIME_DIR, если они нужны.
Дополнительно подгружаются пользовательские настройки из конфигурации через
conf.load_config(). В конце собирается итоговый список аргументов для
bubblewrap, логируются для отладки, и вызывается os.execvp() – фактически,
wraplify само заменяется на bwrap, передав управление изолированному процессу.

**parse_config(config_path: Path)** – открывает указанный конфигурационный файл
и разбирает его по строкам, для обработки которых используется функция glob().
Возвращается множество всех совпавших путей. Это дает пользователю гибкость:
можно указать шаблоны, соответствующие целым классам сокетов или временных
директорий (например, wayland и pipewire).

**load_config(config_path: Path, name: str)** – определяет, какой конфиг
использовать: сначала пробует найти специфический файл для приложения по имени,
если такого нет – откатывается к default.cfg. Возвращает множество путей,
которые затем будут подключены внутрь sandbox-а при запуске.

**sub_env(var: str)** – вспомогательная функция для подстановки переменных
окружения в шаблоне. Используется при разборе строк в конфигурации.

**expandvars(text: str)** – расширяет переменные окружения в переданной строке.
Применяется регулярное выражение для поиска переменных окружения в виде ${NAME}
(используется формат bash переменных) и замены их на соответствующие значения из
os.environ.

**_glob(pattern: str, path: Path, dbg_offset='') -> set[Path]** – функция
рекурсивного сопоставления пути. Работает как pathlib.glob, но с важным
отличием: она использует регулярные выражения вместо wildcard-символов (*, ?).
Каждый уровень пути сопоставляется отдельно, и, если совпадение найдено,
происходит углубление в соответствующую директорию. Если на каком-то этапе
возникает PermissionError, он логируется. Дополнительный аргумент dbg_offset
используется исключительно для отладочного вывода – он визуально показывает
глубину рекурсии в логах, добавляя отступы.

**glob(pattern: str) -> set[Path]** – публичная функция модуля. Приводит шаблон
к финальному виду, сначала удаляя лишние слеши и применяя expandvars(), затем
вызывает _glob(), начиная обход с корня файловой системы. Это тот интерфейс,
который используют функции из conf.py, чтобы собрать пути, указанные в
пользовательском конфиге.


# Демонстрация
Данная глава демонстрирует возможности разработанной утилиты.

## Описание условных обозначений в листингах
Демонстрационные листинги в данной главе имеют следующую структуру,
представленную в листинге 1.

Листинг 1 – Структура листинга.
```
[<user>@<hostname> <workdir>]<usertype> <command> # <comment>

<output>
```

Теперь рассмотрим каждый элемент подробнее:

- user – имя пользователя от имени которого исполняется команда;
- hostname – имя хоста, в примерах либо «host» - что значит, что команда
  исполняется на хостовой (основной) системе, либо «wrap» - значит что команда
  исполняется внутри изолированной среды созданной разработанной утилитой;
- workdir – путь до текущей рабочей директории, «~» – это корень домашней
  директории текущего пользователя;
- usertype – либо «$» - обычный пользователь, либо «#» - root пользователь;
- command – исполняемая команда;
- comment – комментарий к команде;
- output – результат исполнения команды, может содержать несколько строк или
  отсутствовать.

Дополнительно создадим псевдоним (alias) для более удобного использования
утилиты с помощью команды alias wraplify="uvx wraplify". Утилита uvx
автоматически скачает пакет с pypi при первом запуске.

## Подготовка стенда
Дальше во всех примерах предполагается, что данная структура файлов и директорий
из листинга 2 присутствует в корне домашней директории пользователя.

Листинг 2 – Команды для создания демонстрационной иерархии.
```
[user@host ~]$ mkdir -p dir/subdir1
[user@host ~]$ mkdir -p dir/subdir2
[user@host ~]$ mkdir -p dir/subdir3/nested_dir
[user@host ~]$ touch dir/file1.txt
[user@host ~]$ touch dir/file2.log
[user@host ~]$ touch dir/file3.csv
[user@host ~]$ touch dir/subdir1/subfile1.txt
[user@host ~]$ touch dir/subdir1/subfile2.md
[user@host ~]$ touch dir/subdir2/subfile3.json
[user@host ~]$ touch dir/subdir3/subfile4.xml
[user@host ~]$ touch dir/subdir3/nested_dir/nested_file1.txt
[user@host ~]$ touch dir/subdir3/nested_dir/nested_file2.dat
[user@host ~]$ mkdir -p dir/empty_dir
[user@host ~]$ mkdir -p dir/subdir3/another_empty_dir
[user@host ~]$ tree dir
dir
|-- empty_dir
|-- file1.txt
|-- file2.log
|-- file3.csv
|-- subdir1
|   |-- subfile1.txt
|   `-- subfile2.md
|-- subdir2
|   `-- subfile3.json
`-- subdir3
    |-- another_empty_dir
    |-- nested_dir
    |   |-- nested_file1.txt
    |   `-- nested_file2.dat
    `-- subfile4.xml
7 directories, 9 files
[user@host ~]$
```

## Режим по умолчанию
Пример, приведенный в листинге 3, показывает базовую логику автоматического
создания изолированных окружений для каждого запускаемого приложения в
отдельности.

Видно, что в режиме по умолчанию разработанная утилита полностью изолирует
пользовательскую домашнюю директорию, а также сохраняет все изменения отдельно,
для каждого запущенного приложения.

Листинг 3 – Демонстрация общего принципа разных окружений
```
[user@host ~]$ ls           # видим что на хосте присутствует host_file файл
host_file
[user@host ~]$ wraplify bash               # запускаем разработанную утилиту
[user@wrap ~]$ touch wrap_file              # создаем файл внутри контейнера
[user@wrap ~]$ ls            # видим что файла с хоста нет внутри контейнера
wrap_file
[user@wrap ~]$ exit                                  # выходим из контейнера
exit
[user@host ~]$ ls # на хосте по прежнему есть файл host_file и нет wrap_file
host_file
[user@host ~]$ wraplify bash   # повторно запускам утилиту с той же командой
[user@wrap ~]$ ls         # видим файл, который был создан внутри контейнера
wrap_file
[user@wrap ~]$ exit                                  # выходим из контейнера
exit
[user@host ~]$ wraplify sh                  # запускаем уже другую программу
sh-5.2$ ls                                              # никаких файлов нет
sh-5.2$ exit                                         # выходим из контейнера
exit
[user@host ~]$
```

## Режим OverlayFS
Этот пример (листинг 4) демонстрирует работу утилиты в режиме OverlayFS, когда
все пользовательские данные доступны, но их редактирование и удаление не
оказывает влияния на хостовую файловую систему.

Листинг 4 – Демонстрация OverlayFS.
```
[user@host ~]$ wraplify --overlay bash # заходим в изолированное окружение с
                                                        # ключиком --overlay
[user@wrap ~]$ ls                         # видим что папка с хоста на месте
dir
[user@wrap ~]$ find dir -name "*2*" -exec rm -vrf {} \;  # удаляем все файлы
                                                        # содержащие цифру 2
removed 'dir/subdir1/subfile2.md'
removed 'dir/subdir2/subfile3.json'
removed directory 'dir/subdir2'
find: 'dir/subdir2': No such file or directory
removed 'dir/subdir3/nested_dir/nested_file2.dat'
removed 'dir/file2.log'
[user@wrap ~]$ tree dir       # выводим оставшееся содержимое директории dir
dir
|-- empty_dir
|-- file1.txt
|-- file3.csv
|-- subdir1
|   `-- subfile1.txt
`-- subdir3
    |-- another_empty_dir
    |-- nested_dir
    |   `-- nested_file2.dat
    `-- subfile4.xml
6 directories, 5 files
[user@wrap ~]$ exit                                  # выходим из контейнера
exit
[user@host ~]$ tree dir      # и выводим содержимое хостовой директории dir,
                                     # видим, что все осталось без изменений
dir
|-- empty_dir
|-- file1.txt
|-- file2.log
|-- file3.csv
|-- subdir1
|   |-- subfile1.txt
|   `-- subfile2.md
|-- subdir2
|   `-- subfile3.json
`-- subdir3
    |-- another_empty_dir
    |-- nested_dir
    |   |-- nested_file1.txt
    |   `-- nested_file2.dat
    `-- subfile4.xml
7 directories, 9 files
[user@host ~]$ tree ~/.local/state/wraplify/bash/   # а все измененные файлы
                                                # хранятся в отдельном месте
/home/user/.local/state/wraplify/bash/
|-- home
|-- upper
|   `-- dir
|   |-- file2.log
|   |-- subdir1
|   |   `-- subfile2.md
|   |-- subdir2
|   `-- subdir3
|       `-- nested_dir
|           `-- nested_file2.dat
`-- work
    `-- work [error opening dir]
9 directories, 4 files
[user@host ~]$
```

## Приложение с GUI
Данный пример показывает, что даже приложение с графическим интерфейсом работает
без дополнительных настроек. Команды запуска представлены в листинге 5,
результат на рисунке 1.

Листинг 5 – Демонстрация запуска GUI приложений
```
[user@host ~]$ wraplify firefox
[user@host ~]$
```

![Image Placeholder]()  
Рисунок 1 – Просмотр локальных файлов через firefox

## Режим монтирования
В данном случае (листинг 6) можно видеть, как была смонтирована только рабочая
директория (вывод команды `tree ~`), и причем напрямую, без overlayfs.

Это означает что все изменения напрямую будут вноситься в хостовую систему, но
только внутри рабочей директории.

Используется данный режим, когда нужно перенести в контейнер текущую папку с
хоста, но, чтобы все изменения за ее пределами не оказывали влияния на систему.

Листинг 6 – Демонстрация монтирования текущей директории
```
[user@host ~]$ cd dir/subdir3                  # переходим в поддиректорию
[user@host subdir3]$ wraplify --current-dir bash # заходим в изолированное
                                            # окружение с ключик --overlay
[user@wrap subdir3]$ ls
another_empty_dir nested_dir subfile4.xml
[user@wrap subdir3]$ tree ~                      # выводим содержимое всей
                                             # пользовательской директории
/home/user
`-- dir
    `-- subdir3
    |-- another_empty_dir
    |-- nested_dir
    |   |-- nested_file1.txt
    |   `-- nested_file2.dat
    `-- subfile4.xml
5 directories, 3 files
[user@wrap subdir3]$ touch file_from_env         # создаем файл находясь в
                                                 # изолированном окружении
[user@wrap subdir3]$ exit                                # выходим из него
exit
[user@host subdir3]$ ls  # и видим что файл создался и на хостовой системе
another_empty_dir file_from_env nested_dir subfile4.xml
[user@wrap subdir3]
```

## Очистка окружений
В листинге 7 производится очистка окружений. Добавлена дополнительная проверка
подтверждения, которая в интерактивном режиме убеждается у пользователя, какие
директории должны быть удалены.

Листинг 7 – Демонстрация очистки созданных окружений.
```
[user@host ~]$ wraplify --clean-all
Remove directory '/home/vkr/.config/wraplify'? [y/N] y
Remove directory '/home/vkr/.local/state/wraplify'? [y/N] y
[user@host ~]$
```


# Тестирование
Разработка инструмента для изоляции недоверенного кода требует проверки его
соответствия ключевым требованиям: безопасности и удобству использования.

Цель тестирования – подтвердить выполнение сформулированных требований:

- Отсутствие уязвимостей, связанных с утечкой данных, эскалацией привилегий или
  неконтролируемым доступом к ресурсам хоста;
- Интуитивность интерфейса, минимальное время запуска и совместимость с
  типовыми сценариями, включая работу с GUI-приложениями.

## Проверка изоляции пространств имен
Цель данного раздела проверить, что процессы в изолированной среде не имеют
доступа к ресурсам хост-системы за пределами выделенных пространств имён. Для
этого было протестировано каждое пространство имен:
1. **User Namespace** – проверки подтвердили, что процессы внутри изолированной
   среды не обладают привилегиями root на хосте. Попытки изменить системные
   файлы, такие как /etc/passwd, завершались ошибкой доступа, несмотря на UID 0
   внутри контейнера.
1. **PID Namespace** – команда ps aux, выполненная в изолированной среде,
   отображала только внутренние процессы, что свидетельствует об отсутствии
   видимости процессов хост-системы.
1. **Mount Namespace** – файловая система была изолирована: при выполнении ls ~
   отображалось только содержимое разрешённых директорий.
1. **Network Namespace** – сетевой стек контейнера оказался полностью
   изолирован. Команда ip a показывала только виртуальные интерфейсы, созданные
   внутри среды. Интерфейсы хост-системы не были доступны.
1. **UTS Namespace** – команда uname -n показала, что имя хоста в изолированной
   среде отличалось от имени хоста, что подтверждает корректную настройку.
1. **IPC Namespace** – при выполнении ipcs не обнаруживались объекты
    межпроцессного взаимодействия, принадлежащие хост-системе, что говорит о
    полной изоляции IPC-ресурсов.

Разработанная утилита успешно проходит проверки, описанные выше. Что вполне
ожидаемо, так как низкоуровневая настройка пространств имен лежит на надежном
компоненте bubblewrap.

## Проверка защиты от известных эксплойтов
Проверки ниже позволяют убедиться, что изолированная среда устойчива к
эксплуатации уязвимостей, включая известные CVE (Common Vulnerabilities and
Exposures), и предотвращает эскалацию привилегий или доступ к ресурсам хоста:
1. Dirty COW (CVE-2016-5195) – тест с использованием эксплойта, направленного на
   модификацию защищённого файла в системе, завершился неудачей. Попытка
   получить доступ к защищённым областям памяти была заблокирована на уровне
   ядра, как и ожидалось.
1. Эксплойт через /proc/self/exe (CVE-2019-5736) - попытка подмены исполняемого
   файла внутри контейнера с использованием уязвимости была заблокирована.
   Сценарий завершился ошибкой доступа, что подтверждает корректную изоляцию и
   защиту файловой системы.
1. Доступ к устройствам хоста - проверки взаимодействия с критичными
   устройствами, такими как /dev/mem, /dev/sda и /dev/kvm, показали, что
   изолированная среда надёжно блокирует все попытки открытия и модификации. Все
   действия завершались с ошибками «Operation not permitted».

Результаты тестирования подтверждают устойчивость инструмента к ряду атак,
направленных на обход ограничений изоляции и нарушение целостности системы.

## Проверка удобства использования
Проверен запуск приложения с графическим интерфейсом. Приложение успешно
запускалось, интерфейс отображался корректно (рисунок 1), взаимодействие с
пользователем (мышь, клавиатура, окна) осуществлялось без сбоев, дополнительных
настроек разработанная утилита от пользователя не требовала.

## Оценка производительности
Для повышения объективности были проведены сравнительные замеры времени запуска
простейшей команды echo в различных сценариях с использованием утилиты
hyperfine, позволяющей производить точные микробенчмарки. Выбор на команду echo
пал так как время ее работы пренебрежимо мало, что позволяет точнее оценить
вклад именно утилит для создания изолированного окружения. hyperfine
автоматизирует процесс сбора статистики, он запускает требуемое приложение сотни
раз, замеряя время каждой итерации, а затем высчитывает характеристики
полученных данных.

Результаты измерений представлены в таблице 2.

Таблица 2 – Сравнение времени запуска команд.
| Команда    | Среднее время, мс | Стандартное отклонение, мс | User time, мс | System time, мс |
|------------|-------------------|----------------------------|---------------|-----------------|
| echo       | 0.45              | ± 0.04                     | 0.28          | 0.13            |
| bubblewrap | 3.5               | ± 0.2                      | 0.2           | 0.7             |
| wraplify   | 34.7              | ± 1.9                      | 26.4          | 5.3             |
| uvx        | 49                | ± 0.4                      | 33.9          | 12.8            |
| docker     | 216.3             | ± 13.0                     | 6.9           | 5.9             |

И те же самые данные в графическом виде для лучшего восприятия представлены на
рисунке 2.

![Image Placeholder]()  
Рисунок 2 – Сравнение времени запуска команд.

Рассмотрим результаты подробнее:

- команда echo служит базовым ориентиром: менее 0.5 мс;
- bubblewrap показывает, что изоляция на уровне пространств имён в чистом виде
  вносит около 3 мс задержки, что говорит об эффективности низкоуровневого
  механизма;
- wraplify в виде CLI-инструмента, написанного на Python, демонстрирует среднее
  время запуска 34.7 мс. Основной вклад вносит запуск интерпретатора Python.
- uvx реализует подход, схожий с pipx, позволяет автоматически загрузить пакет
  с PyPI и запустить его, что дает возможность в одну команду запустить
  разработанное программное обеспечение на любой системе, где установлены
  python, bubblewrap и uvx, конечно;
- docker демонстрирует наибольшее время запуска: каждая команда взаимодействует
  с фоновым демоном dockerd, который управляет контейнерами.

Тестирование показало, что разработанное решение отличается значительно меньшими
накладными расходами по сравнению с Docker. В сценариях, где важны безопасность
и минимальное вмешательство в систему, оно демонстрирует приемлемое время
запуска и подходит для интерактивного использования. Даже с учётом инициализации
среды и обработки логики запуска, среднее время старта остаётся в пределах
нескольких десятков миллисекунд. Это делает инструмент удобным выбором для
безопасного исполнения однократных задач, включая запуск скриптов, утилит и
других приложений.


# Доставка
Когда инструмент начинает работать стабильно, его нужно подготовить к
использованию вне локальной среды. Это значит не только обеспечить установку, но
и сделать ее повторяемой: зависимости должны устанавливаться корректно, команды
выполняться одинаково, а окружение не требовать ручной доводки. Даже если
утилита рассчитана на узкий круг задач, от того, как она оформлена и
распространяется, зависит, насколько быстро ее смогут использовать другие.

Формат распространения выбирается исходя из того, кто и как будет использовать
результат. Иногда достаточно обычного архива с бинарным файлом В других случаях
удобнее упаковать всё в Python-пакет и выложить в PyPI. А если требуется
зафиксировать окружение и исключить лишние зависимости, подойдёт сборка в
контейнер.

Но, к сожалению, последний самый контролируемый вариант для данной утилиты
совершенно не подходит, поскольку она ориентирована на использование в
rootless-сценариях, где доступ к системному контейнерному движку либо ограничен,
либо отсутствует вовсе. Кроме того, контейнер – это, по сути, изолированная
система, тогда как цель утилиты – интеграция с существующим окружением
пользователя, с сохранением его привычной среды, путей и настроек.

## PyPI
PyPI (Python Package Index) – это централизованное хранилище для
Python-библиотек и утилит, своего рода каталог, откуда любой может установить
пакет с помощью pip. Это упрощает распространение: достаточно один раз выгрузить
проект, и он становится доступен через стандартные инструменты во всех системах,
где установлен Python.

Поэтому если цель – сделать инструмент доступным другим разработчикам, особенно
в экосистеме Python, публикация туда является логичным выбором. Она не требует
настройки стороннего хранилища, и сам процесс сводится к нескольким командам.
Всё, что нужно – правильно оформить проект: указать метаинформацию, зависимости
и путь к исполняемому скрипту.

Это не единственный способ доставки, но один из самых очевидных, когда речь идет
о Python-утилите, которую планируется запускать из командной строки

## Конфигурация пакета
Чтобы опубликовать пакет на PyPI, нужно выполнить несколько базовых требований,
и первое из них – подготовить корректную структуру проекта и метаданные. PyPI
ожидает, что в составе проекта будет файл pyproject.toml, в котором указаны,
метаданные проекта, зависимости, настройки сборки.

pyproject.toml постепенно вытеснил setup.py и стал основным способом описания
Python-проектов. Причина довольно понятная – со временем в setup.py начинала
появляться не только метаинформация, но и логика, что противоречило его
использованию в качестве универсального формата. Требовалось что-то более
структурированное, что можно было бы легко читать и обрабатывать
автоматически.

Новый формат решает проблемы setup.py за счёт разделения обязанностей: вся
информация о проекте – его имя, версия, авторы, список зависимостей – теперь
явно задаётся в одном месте, без смешивания с кодом. При этом pyproject.toml
может использоваться не только setuptools, но и другими инструментами – flit,
poetry, uv, и это делает экосистему более гибкой.

Листинг 8 – Пример минимальной конфигураций проекта
```
[project]
name = "wraplify"
version = "0.2.3"
description = "Wraplify simplifies the process of isolating untrusted code by
providing a user-friendly Python wrapper around bubblewrap"
readme = "README.md"
requires-python = ">=3.13"
dependencies = []
```

Этого достаточно, чтобы pip и другие аналогичные инструменты понимали, как
собрать и установить пакет. Если скрипт предполагается запускать из терминала, в
pyproject.toml можно также указать точку входа – команду, которая будет
устанавливаться как исполняемая, что в данном случае очень удобно:

Листинг 9 – Указание точки входа
```
[project.scripts]
wraplify = "main:main"
```

## Сборка и загрузка пакета
Для публикации на PyPI одного pyproject.toml недостаточно. Помимо описания
проекта, необходим специально подготовленный образ, представляющий собой пакет
строго определенной структуры, который соответствует требованиям Python
Packaging Authority. Он представляет собой либо sdist (source distribution),
либо wheel (формат .whl), а чаще – оба варианта одновременно. Это делается для
того, чтобы охватить как можно больше сценариев установки: исходники можно
собрать под специфическую платформу, а предсобранный образ ставится сразу, если
всё совпадает по окружению.

Формат sdist – это tar.gz-архив с исходным кодом и всей метаинформацией о
пакете. Он дает максимальную гибкость, но требует компиляции на стороне
пользователя при установке, что очевидно, занимает дополнительное время и
требует некоторых вычислительных ресурсов целевой системы. В отличие от него,
wheel – это бинарный формат: предварительно собранный и готовый к установке.
Если пакет не зависит от платформы (например, написан полностью на Python), то
wheel будет универсальным – py3-none-any. Кроме того, wheel позволяет избежать
потенциальных проблем, связанных с отсутствием необходимых компиляторов или
библиотек на целевой системе.


# Заключение
Проведён обзор более 80 инструментов контейнеризации и изоляции, выделены их
ограничения. Установлено, что существующие средства либо требуют повышенных
прав, либо сложны в конфигурации, либо недостаточно гибки для пользовательских
сценариев.

Сформулированы критерии эффективности: минимальная задержка при запуске, полная
изоляция ресурсов, совместимость с GUI-приложениями, интуитивный интерфейс и
отсутствие зависимости от демонов или глобальной конфигурации.

Был выбран Bubblewrap в качестве основы из-за его простоты, поддержки режима
rootless и низких накладных расходов. Реализация на Python обеспечила
переносимость и простоту расширения, а использование Linux namespaces позволило
достичь необходимого уровня изоляции.

Разработан инструмент wraplify - прототип, поддерживающий режимы: изоляция
домашней директории с сохранением изменений для каждого приложения, OverlayFS
для безопасного редактирования файлов без влияния на хост, монтирование текущей
директории для работы с локальными ресурсами, очистку созданных окружений с
защитой от случайного удаления.

В ходе тестирования было подтверждено соответствие требованиям безопасности:
процессы не могут получить доступ к ресурсам хоста, защита от популярных
эксплойтов, осуществляющих выход за пределы изолированного окружения, а также
была продемонстрирована высокая скорость запуска.

Инструмент упакован в Python-пакет и размещён на PyPI, что обеспечивает простую
установку через pip и совместимость с системами, поддерживающими Python 3.13+.

Разработанный инструмент wraplify успешно решает поставленные задачи, предлагая
простой и безопасный способ запуска недоверенного кода. Он компенсирует
недостатки существующих решений, сочетая минимальные системные требования,
rootless-режим и гибкость настройки. Тесты подтвердили его устойчивость к атакам
и высокую скорость, что делает его подходящим для повседневного использования
разработчиками и пользователями без глубоких навыков системной администраторской
работы.

Таким образом, поставленная в данной работе цель создания удобного
непривилегированного инструмента для запуска недоверенного кода в изолированной
среде успешно достигнута.


# Список использованных источников
1. The internals and the latest trends of container runtimes (2023) // Medium
   URL:
   https://medium.com/nttlabs/the-internals-and-the-latest-trends-of-container-runtimes-2023-22aa111d7a93
   (дата обращения: 01.04.2025).
1. Awesome Linux Containers // GitHub URL:
   https://github.com/Friz-zy/awesome-linux-containers (дата обращения:
   20.04.2025).
1. Awesome Containers // GitHub URL:
   https://github.com/pditommaso/awesome-containers (дата обращения:
   20.04.2025).
1. Containers // GitHub URL: https://github.com/containers/ (дата обращения:
   20.04.2025).
1. What is Docker? // dockerdocs URL:
   https://docs.docker.com/get-started/docker-overview/ (дата обращения:
   20.04.2025).
1. Базовые возможности LXD --- системы контейнеров в Linux // Habr URL:
   https://habr.com/ru/articles/496492/ (дата обращения: 20.04.2025).
1. Rootless containers using Podman // Red Hat Blog URL:
   https://www.redhat.com/en/blog/rootless-containers-podman (дата обращения:
   01.04.2025).
1. What is gVisor? // gVisor URL: https://gvisor.dev/docs/ (дата обращения:
   20.04.2025).
1. Firecracker – Lightweight Virtualization for Serverless Computing // AWS Blog
   Home URL:
   https://aws.amazon.com/blogs/aws/firecracker-lightweight-virtualization-for-serverless-computing
   (дата обращения: 20.04.2025).
1. runc // GitHub URL: https://github.com/opencontainers/runc (дата обращения:
   20.04.2025).
1. An introduction to crun, a fast and low-memory footprint container runtime //
   Red Hat Blog URL: https://www.redhat.com/en/blog/introduction-crun (дата
   обращения: 20.04.2025).
1. Youki User and Developer Documentation // Youki URL:
   https://youki-dev.github.io/youki/youki.html (дата обращения: 20.04.2025).
1. udocker // GitHub URL: https://github.com/indigo-dc/udocker (дата обращения:
   20.04.2025).
1. nsjail // nsjail URL: https://nsjail.dev (дата обращения: 20.04.2025).
1. Firejail // ArchWiki URL: https://wiki.archlinux.org/title/Firejail (дата
   обращения: 20.04.2025).
1. Bubblewrap // ArchWiki URL: https://wiki.archlinux.org/title/Bubblewrap (дата
   обращения: 20.04.2025).
1. namespaces(7) // Arch manual pages URL:
   https://man.archlinux.org/man/namespaces.7 (дата обращения: 21.04.2025).
1. cgroups(7) // Arch manual pages URL: https://man.archlinux.org/man/cgroups.7
   (дата обращения: 23.04.2025).
1. seccomp(2) // Arch manual pages URL: https://man.archlinux.org/man/seccomp.2
   (дата обращения: 23.04.2025).
1. selinux(8) // Linux manual page URL:
   https://man7.org/linux/man-pages/man8/selinux.8.html (дата обращения:
   23.04.2025).
1. Containers and Threads from the POV of `clone` // Igor Minin URL:
   https://minin.tech/posts/containers-and-threads-from-the-pov-of-clone/ (дата
   обращения: 21.04.2025).
1. user_namespaces(7) // Arch manual pages URL:
   https://man.archlinux.org/man/core/man-pages/user_namespaces.7 (дата
   обращения: 21.04.2025).
1. mount_namespaces(7) // Arch manual pages URL:
   https://man.archlinux.org/man/core/man-pages/mount_namespaces.7 (дата
   обращения: 21.04.2025).
1. utc_namespaces(7) // Arch manual pages URL:
   https://man.archlinux.org/man/core/man-pages/utc_namespaces.7 (дата
   обращения: 21.04.2025).
1. pid_namespaces(7) // Arch manual pages URL:
   https://man.archlinux.org/man/core/man-pages/pid_namespaces.7 (дата
   обращения: 21.04.2025).
1. network_namespaces(7) // Arch manual pages URL:
   https://man.archlinux.org/man/core/man-pages/network_namespaces.7 (дата
   обращения: 21.04.2025).
1. ipc_namespaces(7) // Arch manual pages URL:
   https://man.archlinux.org/man/core/man-pages/ipc_namespaces.7 (дата
   обращения: 21.04.2025).
1. clone(2) // Arch manual pages URL: https://man.archlinux.org/man/clone.2
   (дата обращения: 21.04.2025).
1. unshare(2) // Arch manual pages URL: https://man.archlinux.org/man/unshare.2
   (дата обращения: 21.04.2025).
1. The Python Standard Library // Python 3.13.3 documentation URL:
   https://docs.python.org/3.13/library/index.html (дата обращения: 22.04.2025).
