# Список сокращений и условных обозначений
**API** – Application Programming Interface – программный интерфейс приложения  
**CI/CD** – Continuous Integration / Continuous Delivery – непрерывная
интеграция / доставка  
**CLI** – Command Line Interface – интерфейс командной строки  
**CPU** – Central Processing Unit – центральный процессор  
**GUI** – Graphical User Interface – графический интерфейс пользователя  
**KVM** – Kernel-based Virtual Machine – виртуализация на уровне ядра  
**OCI** – Open Container Initiative – стандарт контейнеризации  
**PID** – Process Identifier – идентификатор процесса  
**REST** – Representational State Transfer – архитектурный стиль взаимодействия
с API  
**SSH** – Secure Shell – безопасный протокол удалённого доступа к системе  
**UID** – User Identifier – уникальный идентификатор пользователя  
**VM** – Virtual Machine – виртуальная машина  
**YAML** – YAML Ain't Markup Language – формат сериализации данных, удобный для
конфигураций


# Термины и определения
**Изоляция** – Ограничение взаимодействия процесса с системой – включая файловую
систему, сеть, IPC и идентификаторы пользователей.  
**Контейнер** – Изолированная среда выполнения, позволяющая запускать приложения
с ограниченным доступом к ресурсам системы, используя общее ядро ОС.  
**Rootless контейнер** – Контейнер, запускаемый без привилегий
суперпользователя.  
**Песочница** – Изолированное ограниченное окружение, в котором исполняется
приложение с ограниченными правами.  
**Монтирование** – Процесс привязки файловой системы к определённой директории.  
**Недоверенный код** – Код, источник которого неизвестен или которому нельзя
доверять.  
**Конфигурация окружения** – Набор параметров и настроек, определяющих поведение
изолированной среды: монтируемые директории, права доступа, режимы запуска и
т.д.


# Введение
Несмотря на рост числа киберугроз и общий уровень осведомленности пользователей,
ответственность за обеспечение безопасности по-прежнему в значительной степени
лежит на специалистах по информационной безопасности. Однако даже они не в
состоянии предусмотреть все возможные векторы атак. При этом существует группа
пользователей – разработчики, которые часто работают с недоверенным кодом и
обладают достаточными знаниями, чтобы, например, отключать некоторые меры защиты
(вроде запрета на копирование команд с sudo), но при этом могут не иметь
глубоких технических знаний в области безопасности.

Существующие решения, такие как Docker, LXC, AppArmor, SELinux, systemd-nspawn
или Podman, изначально проектировались для профессионального использования – в
серверных или корпоративных инфраструктурах. Они предполагают наличие повышенных
привилегий, знание внутреннего устройства Linux и часто требуют предварительной
настройки. Более того, многие из них ориентированы не на запуск отдельных
процессов, а на полноценную оркестрацию окружений: с настройкой томов, сетей,
ресурсов, зависимостей, политик безопасности и доступа. В результате попытка
использовать такие инструменты для простой задачи – например, разовое исполнение
небольшого скрипта, скопированного с форума или сгенерированного нейросетью –
приводит к тому, что пользователь отказывается от идеи изоляции вовсе. Так как
он вряд ли будет готов тратить неоправданно много времени на чтение документации
и написание конфигурации ради скрипта, который, как ему кажется, будет работать
пару секунд. В результате вопрос изоляции и безопасности откладывается «на
потом» – до первого инцидента.

А так как проблема безопасного исполнения недоверенного кода сегодня стоит не
только перед специалистами в области информационной безопасности, но и перед
широкой аудиторией пользователей, которые регулярно сталкиваются с
необходимостью запускать потенциально опасные программы, то ее решение требует
инструментов новой направленности – достаточно надёжных, чтобы обеспечить
защиту, и достаточно простых, чтобы их было удобно использовать по принципу
«одна команда – и системе ничего не угрожает» (в большинстве случаев).

Целью данной работы является создание удобного в использовании инструмента,
позволяющего запускать недоверенный код в изолированной среде без необходимости
в привилегированных операциях и сложной конфигурации.

Для достижения поставленной цели необходимо решить следующие задачи:
1. Проанализировать существующие инструменты контейнеризации и их ограничения.
1. Определить ключевые требования к программному решению с учетом безопасности и
   удобства использования.
1. Разработать архитектуру программного решения.
1. Реализовать прототип программного решения.
1. Провести тестирование прототипа на соответствие требуемым критериям.


# Обзор существующих решений
Для формирования целостного представления о современных инструментах для
изоляции был проведен первичный сбор данных из нескольких авторитетных
источников. Основой для начального анализа послужили следующие ресурсы:

- [awesome-linux-containers](https://github.com/Friz-zy/awesome-linux-containers)
  – A curated list of awesome Linux Containers frameworks, libraries and
  software;
- [awesome-containers](https://github.com/pditommaso/awesome-containers) – A
  curated list of awesome Linux containers related technologies inspired by
  other Awesome lists;
- [Open Repository for Container Tools](https://github.com/containers/) – A
  collection of open source tools that create, configure, and work with
  containers.

На основании информации из указанных источников была составлена обобщенная
таблица, включающая свыше восьмидесяти инструментов, связанных с изолированным
исполнением кода. Для сужения круга анализа использовались три критерия,
значения которых в работе зафиксированы на момент 20.04.2025:

- Популярность проекта оценивается с использованием открытых количественных
  метрик, таких как количество звёзд (stars) на GitHub или аналогичных
  показателей на других платформах. Эти метрики отражают уровень вовлеченности
  и интереса сообщества к проекту.
- Актуальность разработки: проект не должен находиться в архиве и иметь
  коммиты, слитые PR или решенные issues в течение последнего года – это
  исключает заброшенные и потенциально небезопасные решения.
- Иметь открытый исходный код – что позволяет обеспечить прозрачность,
  проверяемость и возможность модификации кода сообществом, что критично для
  доверия и долгосрочной поддержки инструментов.

После фильтрации получилась выборка инструментов. Она представлена в таблице
ниже:

Таблица 1 – Отфильтрованный список инструментов.
| Название   | Звезд | Активность | Описание |
|------------|-------|------------|----------|
| **docker** | 69600 | 2025-04-20 |          |

Из данного списка были отобраны только те инструменты, основной задачей которых
является создание изолированной среды исполнения. Средства, предназначенные
исключительно для вспомогательных задач – таких как аудит, мониторинг, отладка
или анализ контейнеров – в обзор не включались.

Отобранные инструменты можно условно разделить на несколько групп. Первую
составляют полноценные системы управления контейнерами. Эти инструменты
предоставляют полный цикл работы с контейнерами: от подготовки образов до
управления жизненным циклом окружений.

Во вторую входят решения, сфокусированные на безопасности. Они применяют
аппаратную или программную изоляцию, моделируют системные вызовы или используют
собственные интерфейсы, снижая вероятность выхода процесса за пределы
контролируемого пространства.

Третья – низкоуровневые инструменты, соответствующие спецификации OCI, которые
не управляют окружением целиком, а отвечают только за непосредственный запуск
контейнера в уже подготовленной среде.

Инструменты из каждой группы решают свои задачи и подходят под разные сценарии,
рассмотрим их дальше по отдельности.

## Контейнерные менеджеры

⁂

### Docker
Docker был разработан в 2013 году компанией dotCloud (впоследствии
переименованной в Docker Inc.) и за считанные годы стал одной из самых
узнаваемых технологий в мире разработки и эксплуатации программного обеспечения.
Он появился в тот момент, когда индустрия остро нуждалась в стандартизированном
способе упаковывать приложения вместе со всеми зависимостями, не полагаясь на
особенности окружения, в котором они будут запущены. Уже к 2015 году Docker
приобрел массовую популярность, а его экосистема начала стремительно расти:
появились реестры образов, инструменты оркестрации и полноценные
DevOps-платформы, основанные на контейнерах.

Тем не менее, при всех своих достоинствах, Docker не всегда подходит для других
задач – в частности, для изоляции недоверенного кода в пользовательских
сценариях. Архитектура Docker построена вокруг отдельного фонового демона
dockerd, который запускается с привилегиями суперпользователя и управляет всем
процессом запуска контейнеров.

Также в пользовательских средах без прав администратора, установка Docker
попросту невозможна без вмешательства в системную конфигурацию. Все
вышеперечисленное резко усложняет его использование в сценариях, где требуется
просто и быстро изолировать выполнение одного единственного скрипта.

### LXC и LXD
LXC (Linux Containers) появился в 2008 году как первая попытка собрать воедино
все возможности изоляции, которые к тому времени уже были в ядре Linux. Он не
требует гипервизора и позволяет запускать процессы прямо на хост-системе, но
так, будто они работают в собственной, полностью отдельной среде. Это делает LXC
лёгким и быстрым по сравнению с классической виртуализацией – никакой эмуляции
железа, минимум накладных расходов.

Сильные стороны LXC видны сразу при первоначальном изучении: это инструмент,
который даёт разработчику или системному инженеру практически полный контроль.
Настроить пользовательские идентификаторы, cgroups, capabilities – всё доступно
и подробно настраивается. Но именно эта свобода и становится опасностью. Без
глубокого знания Linux неизбежно возникнут сложности с правами, безопасностью и
интеграцией контейнера с хост-системой.

Кроме того, LXC больше ориентирован на долгоживущие контейнеры – с полноценной
init-системой, постоянным состоянием и отдельной жизнью. Для задач временной
изоляции, например, одноразового запуска подозрительного скрипта, его
использование оказывается слишком сложным, тяжеловесным и избыточным.

Со временем, чтобы упростить работу с LXC, появился LXD – более высокоуровневый
инструмент, добавляющий REST API, автоматическую конфигурацию, управление
снапшотами и удобную командную строку. При этом сама архитектура осталась
прежней: LXC и LXD позволяют запускать полноценные «системные» контейнеры,
поведение которых близко к виртуальным машинам. Что тоже не является целью
данной работы.

### Podman
Podman появился в 2018 году как попытка переосмыслить контейнеризацию с учётом
накопленного опыта и слабых мест Docker. Разработанный Red Hat, он с самого
начала стремился решить два главных недостатка предшественника: необходимость
фонового демона и запуск контейнеров с привилегиями.

На первый взгляд, Podman почти неотличим от Docker – команды те же, поведение
схожее, образы совместимы. Но за внешней схожестью скрывается иная архитектура.
Вместо единого демона, который требует root-доступ и централизованно управляет
контейнерами, Podman запускает каждый контейнер как обычный процесс, от имени
пользователя. Это простое на первый взгляд решение меняет очень многое: оно
устраняет потребность в лишнем фоновом сервисе, уменьшает поверхность атаки и
делает систему более предсказуемой.

Особенно хорошо Podman показывает себя в системах: где важна безопасность по
умолчанию, где root-доступ ограничен, где контейнеры живут долго и интегрируются
в более сложные цепочки – CI/CD, автоматизация, управляемая инфраструктура.

Тем не менее, несмотря на более современную архитектуру, Podman остаётся прежде
всего инструментом для разработчиков, инженеров и тех, кто регулярно работает с
контейнерами. Для обычного пользователя, перед которым стоит задача запустить
потенциально опасный скрипт в изолированной среде, Podman всё ещё может
показаться громоздким. Нужно установить зависимости, разобраться с тем, как
именно запускаются rootless-контейнеры, как работают user namespaces, как
правильно монтировать директории и т. д. То есть, даже без демона, это всё ещё
контейнерная платформа – мощная, гибкая, но не мгновенно понятная.

## Инструменты с усиленной безопасностью
В неё попадают решения, в которых изоляция и защита явно приоритетнее
производительности, удобства или совместимости.

### gVisor
gVisor, разработанный Google, – реализует собственную «виртуальную» реализацию
системных вызовов, фактически создавая второе, минимальное ядро, работающее в
пространстве пользователя. Процессы не получают прямого доступа к системным
вызовам хоста, все обращения к ядру фильтруются и обрабатываются gVisor-ом.
Такая модель изоляции обеспечивает гораздо более жёсткий контроль и серьезно
снижает вероятность выхода из контейнера, но и дает о себе знать – она
медленнее, требовательнее, сложнее в отладке.

### Firecracker
Firecracker – продукт Amazon, направленный на запуск микро виртуальных машин
(микро-ВМ) в облаке. В отличие от gVisor, он не эмулирует ядро, а запускает
полноценные виртуальные машины поверх KVM, но делает это настолько быстро и
экономно, что граница между виртуализацией и контейнеризацией почти стирается.
Каждая такая микро-ВМ изолирована аппаратно, загружается за миллисекунды и почти
не требует ресурсов. На выходе – уровень защиты, сравнимый с полноценной
виртуалкой, но со скоростью и лёгкостью контейнеров. Для использования
Firecracker нужны права администратора, явное управление образами ядра и
root-файловой системой, понимание архитектуры виртуализации. В повседневной
разработке он скорее избыточен, но для инфраструктуры – идеален.

## Контейнерные рантаймы низкого уровня

⁂

### runc

⁂

### crun

⁂

### youki

⁂

## Инструменты пользовательской изоляции

⁂

### udocker

⁂

### nsjail

⁂

### firejail

⁂

### apparmor

⁂

### bubblewrap

⁂


# Обзор механизмов контейнеризации
Контейнеризация в Linux – это не отдельная технология, а набор возможностей,
встроенных в ядро. Они решают разные задачи, но собираются вместе, когда нужно
ограничить процесс: в доступе к системе, в использовании ресурсов, в поведении.
Изначально эти механизмы создавались для других целей – например, учёт ресурсов
в многопользовательских системах или изоляция сетевых стеков – но со временем
оказалось, что они хорошо сочетаются. И можно обойтись без виртуальной машины,
если достаточно просто задать жесткие рамки.

Не существует одного способа собрать «правильный» контейнер. Все зависит от
того, что именно нужно ограничить, насколько серьезна угроза, и кто в итоге
будет пользоваться системой. Где-то важнее производительность, где-то контроль.
Поэтому, прежде чем что-то собирать, стоит понять, из чего вообще можно строить.

## Namespaces
Если нужно, чтобы запущенный процесс не взаимодействовал напрямую с остальной
системой, первым шагом почти всегда становится использование пространств имён.
Они позволяют создать копии частей окружения.

Эта идея оказалась настолько гибкой, что на неё теперь опирается почти всё, что
связано с контейнерами, так как позволяют задать минимальный уровень изоляции
без обращения к полноценной виртуализации.

Данный механизм детальнее будет рассмотрен позднее.

## cgroups
Когда среда изолирована, остаётся вопрос – сколько ресурсов ей можно дать. Без
ограничений один процесс может занять всю память или загрузить процессор до
предела. Контроль за этим берут на себя cgroups (control group). Они разбивают
доступные ресурсы на группы и распределяют их между процессами. И делают это на
уровне ядра, что гарантирует предсказуемость: даже если процесс пытается обойти
ограничения, они всё равно срабатывают.

Поддерживаются ограничения на CPU, память, ввод-вывод и другие подсистемы.
Вторая версия cgroups упростила конфигурацию и сделала поведение более
стабильным, но общая логика осталась прежней.

## Seccomp
Ограничить видимость и ресурсы – этого недостаточно, если процесс может делать
произвольные системные вызовы. Чаще всего это mount, ptrace, execve и другие
критичные точки, через которые можно повлиять на окружение. Именно тут вступает
в силу Seccomp (secure computing mode). Он даёт способ задать фильтр: какие
вызовы разрешены, а какие нет. Всё, что выходит за пределы, блокируется. Это
снижает риск так как даже если процесс получил доступ к какому-то ресурсу, без
системного вызова он не сможет им воспользоваться.

## SElinux
SELinux представляет собой дополнительный уровень контроля, который работает не
через изоляцию или ограничение ресурсов, а через систему политик. Она задаёт,
какие процессы и при каких условиях могут взаимодействовать с другими
компонентами системы. Даже если у приложения формально есть права и оно
выполняется в изолированном окружении, SELinux может запретить доступ к ресурсу,
если такой доступ не прописан явно.

В контексте rootless-инструментов – то есть утилит, работающих без прав
суперпользователя – SELinux выступает как внешняя система правил, полностью
находящаяся вне зоны управления приложения: процесс не знает о его наличии
напрямую, не может изменить активную политику, переключить режим работы или
запросить дополнительные разрешения. Ошибка будет выглядеть как обычный отказ в
доступе, без явной связи с SELinux.


# Linux namespaces
Linux namespaces – это один из основных механизмов, лежащих в основе
контейнеризации. Именно благодаря ним процессы в изолированных окружениях могут
«не видеть» друг друга, как будто работают на разных машинах, хотя физически
находятся на одном ядре. Это не какая-то новая надстройка, а часть ядра Linux,
развивающаяся уже более двух десятилетий.

Первые шаги в сторону изоляции в Linux начались еще в начале 2000-х годов, но в
полноценную систему пространства имён оформились с появлением CLONE_NEWNS в ядре
2.4.19 (2002 год), а позже начали появляться и остальные. Их развитие шло
постепенно: один namespace – одна изолированная часть системы. Всё вместе это
позволяет запускать процесс в «песочнице», где у него свои PID'ы, свои
смонтированные директории, своя сеть и даже свой root-пользователь, не
совпадающий с root'ом на хосте.

Интересный исторический момент связан с тем, почему именно namespace
монтирования в системных вызовах обозначается как CLONE_NEWNS, а не, скажем,
CLONE_NEWMOUNT. Всё дело в том, что он был первым реализованным пространством
имен в ядре Linux. На тот момент ещё не существовало общей концепции
"namespaces" как набора взаимосвязанных механизмов – был просто механизм
изоляции точек монтирования, и сокращённое newns (от new namespace) казалось
вполне логичным. Уже позже, когда начали появляться другие типы пространств
имён, их стали именовать более явно: CLONE_NEWPID, CLONE_NEWNET, CLONE_NEWUSER и
так далее.

Основная идея namespaces – дать процессу иллюзию того, что он находится в
собственной системе. При этом, в отличие от виртуальных машин, здесь нет полной
эмуляции: ядро одно, ресурсы общие, а изоляция реализована средствами самого
ядра, что делает такую модель намного более легкой и быстрой.

Благодаря этому namespaces стали основой для таких инструментов, как Docker,
LXC, Podman, Firejail, Bubblewrap и других. Они позволяют запускать процессы в
контейнерах на том же ядре без виртуализации и без необходимости поднимать
отдельную ОС. Более того, namespaces можно использовать напрямую – например, с
помощью unshare или более удобных оберток.

## User
User namespace – один из ключевых механизмов изоляции в Linux, появившийся в
ядре 3.8. Он позволяет процессам внутри изолированной среды иметь отличные от
хостовых идентификаторы пользователя и групп. Благодаря этому обычный
пользователь может запустить процесс с правами root внутри контейнера, не
получая настоящего root-доступа на системе. Другими словами, он позволяет
запускать «привилегированные» процессы в изолированной среде, где эти привилегии
действуют только внутри и не имеют силы за её пределами. Эта особенность сделала
возможным появление rootless-контейнеров, которые можно запускать без повышенных
прав.

На практике он часто используется вместе с другими пространствами имён,
поскольку доступ к ним (например, к монтированию файловых систем или созданию
собственных PID-деревьев) тоже требует user namespace.

## Mount
Mount namespace даёт каждому контейнеру своё собственное представление о том,
как устроена файловая система. Это позволяет перенастроить точки монтирования
так, чтобы процессы внутри видели только то, что им разрешено, и в том виде, в
каком это задумал автор окружения. Директории можно подменить, сделать
доступными только для чтения, заменить на временные или вообще исключить – всё
это будет касаться только контейнера, а хост же останется нетронутым. Один и тот
же файл но в разных пространствах имен может оказаться в совершенно разных
местах, с разными правами и даже под разными именами.

В Linux, где почти всё – это файл: устройства, процессы, сокеты, настройки –
возможность контролировать, какие именно файлы видны и как они доступны,
оказывается критически важной. Неудивительно, что именно mount namespace
появился первым: он дает очень точный и мощный инструмент управления средой
исполнения.

## UTS
UTS namespace отвечает за изоляцию идентификаторов хоста – имени машины
(hostname) и домена (domainname). Это может показаться несущественным по
сравнению с пространствами имён, которые изолируют процессы или файловую
систему, но на практике дает важную гибкость. Это удобно и для организации
логов, и для отладки, и просто для визуального разделения сред.

## PID
PID namespace изолирует процессы: внутри него каждый запущенный процесс получает
собственный идентификатор, независимый от остальной системы. Это значит, что
контейнер не только не будет иметь доступа к процессам за пределами своего
пространства имен, но и также даже не знать о их существовании.

Особенно важно то, что внутри такого namespace можно создать собственное дерево
процессов с отдельным init-процессом (обычно с PID 1), который будет выполнять
те же функции, что и в полноценной системе – обрабатывать сигналы, управлять
жизненным циклом дочерних процессов и так далее. Это приближает поведение
контейнера к виртуальной машине, но без всей тяжести гипервизоров.

## Network
Network namespace позволяет каждому контейнеру иметь собственный сетевой стек.
Это значит, что у него будут свои интерфейсы, таблицы маршрутизации, правила
iptables, сокеты и даже отдельный экземпляр loopback-интерфейса (lo). В
результате контейнер можно отключить от сети вовсе, подключить к виртуальному
мосту, настроить NAT или дать прямой доступ к физическому интерфейсу – всё это
делается независимо от основной системы.

Такой подход особенно удобен для сценариев, где важно контролировать, с кем и
как общается запущенный процесс. Например, можно запустить подозрительное
приложение с полной изоляцией от интернета, сохранив при этом доступ к локальным
файлам. Или наоборот – дать выход в сеть, но запретить доступ к внутренним
сервисам хоста.

## IPC
IPC namespace отвечает за изоляцию механизмов межпроцессного взаимодействия –
таких как очереди сообщений, семафоры и общая память. Без него процессы внутри
разных контейнеров могут оказывать влияние друг на друга (использовать одни и те
же участки общей памяти и т. д.).


# Проектирование архитектуры
В этой главе определяется стек технологий, используемый при разработке утилиты –
от механизмов изоляции и готовых низкоуровневых инструментов до языка
программирования и сопутствующих библиотек.

## Выбор инструментов изоляции
Разработка механизма изоляции «с нуля» – через прямое использование clone(2),
unshare(2) и других системных вызовов – даёт высокий уровень контроля: можно
явно задать, какие пространства имён использовать, как накладываются ограничения
и в каком порядке. Но такой подход плохо масштабируется в рамках прикладных
утилит. Эти вызовы чувствительны к контексту выполнения: важен порядок операций,
права процесса на каждом этапе, то, какие вызовы уже были сделаны. Ошибка в
одном месте может привести к тому, что изоляция окажется неполной, или,
наоборот, процесс потеряет доступ к нужным ресурсам. В некоторых случаях нужно
заранее сбросить привилегии, в других – наоборот, сохранить их до определённого
момента. Это делает реализацию хрупкой и трудно расширяемой.

И когда дело касается инструментов для виртуализации, в первую очередь внимание
падает на LXC. Это зрелое решение, позволяющее разворачивать контейнеры, близкие
по поведению к полноценным системам. У него широкие возможности: отдельная сеть,
снапшоты, интеграция с init-системой. Но всё это сказывается на использовании –
LXC рассчитан на долгоживущие контейнеры, где важна устойчивость и контроль. В
контексте кратковременных изолированных процессов – его использование не
оправдано.

AppArmor использует другой подход. Это не контейнер, а фильтр – он описывает, к
каким ресурсам может обращаться программа. Это мощный механизм, особенно в
сочетании с остальной политикой безопасности системы. Но для динамического
запуска или гибкой настройки под каждый новый скрипт он подходит плохо. Профили
создаются отдельно, требуют установки и не меняются на лету. Его применение
имеет смысл тогда, когда известно поведение программы и оно не будет меняться.

⁂

bubblewrap выделяется на фоне остальных своей минималистичной моделью: никаких
конфигов, никаких профилей, только командная строка, в которой напрямую
указывается, какие изоляции применить. Он создавался как часть Flatpak и
ориентирован на запуск приложений от обычного пользователя. Пространства имён,
tmpfs, readonly точки монтирования, ограничение доступа – всё явно прописывается
при запуске.

## Выбор языка программирования
Когда базовая технология изоляции определена – в данном случае это Bubblewrap –
остаётся решить, каким образом строить вокруг нее удобную оболочку. Сам
Bubblewrap – это утилита командной строки, и взаимодействие с ней всегда
сводится к вызову процесса с набором параметров. Подход прямой, но быстро
становится громоздким: количество флагов растёт, логика усложняется, а
необходимость реагировать на разные сценарии требует хоть какой-то структуры.

На этом этапе становится ясно, что нужен язык, в котором можно было бы быстро
собрать утилиту, обрабатывающую аргументы, управляя логикой подготовки окружения
и запуском. Python оказался уместным выбором. Он легко читается, стандартная
библиотека закрывает почти все базовые потребности – от работы с путями и
файлами до запуска процессов и логирования. Никакой дополнительной сборки или
компиляции не требуется, зависимости минимальны, запуск возможен на большинстве
современных Linux-систем без установки дополнительных компонентов, Python чаще
всего входит в стандартную поставку.

Это не самый производительный инструмент, но в этой задаче и не требуется
высокая производительность, так как это не CPU-bound задача. Гораздо важнее
простота изменений и прозрачность логики.


# Создание прототипа
Данная глава детализирует процесс создания прототипа для псевдно-изолированного
(или изолированного, в зависимости от настроек запуска) исполнения кода.
Рассматриваются назначения используемых библиотек, общая структура с описанием
предназначения каждого модуля (файла), а также выполняемая функция каждой
функции.

## Библиотеки
**argparse** – стандартный инструмент для обработки аргументов командной строки.
Главное удобство в том, что логика определения и логика разбора аргументов
объединяются в одном месте: один раз описываются флаги, типы значений, что
является обязательным, а что – опциональным. Дальше argparse сам разбирает всё
на нужные элементы, проверяет корректность, выдает ошибки при неверном вводе и
даже генерирует справку, которую не нужно писать отдельно, что намного удобнее
чем обрабатывать sys.argv вручную.

Кроме этого, argparse полезен в архитектуре, где параметры можно задавать не
только для одной команды, но и как составные части – например, с флагами,
которые активируют разные режимы работы. Учитывая, что основа инструмента
строится вокруг запуска изолированных окружений с множеством вариантов – таких
как приватный том, оверлей, сохранение состояния, удаление и т. д. – без чёткого
описания структуры командной строки всё быстро деградировало бы в сложно
поддерживаемую кодовую базу с множеством условных операторов.

**shlex**, в отличие от argparse, работает на другом уровне – он парсит строки в
формате shell. Это удобно, если некоторые параметры передаются как готовый кусок
командной строки, который нужно разложить на отдельные аргументы, чтобы
корректно обработать дополнительные флаги, которые нужно просто передать дальше
без вмешательства. Потому что независимо от того, насколько много сценариев
использования можно предусмотреть, не стоит ограничивать пользователя, который
умеет работать с linux namespaces, от более точной настройки окружения.

**logging** позволяет управлять уровнем сообщений: во время разработки можно
включить подробный отладочный режим, а в стабильной сборке – оставить только
предупреждения и ошибки. Всё это без переписывания кода. Вместо того чтобы раз
за разом закомментировать строки с отладочным выводом, достаточно поменять
уровень логирования – и инструмент становится тише.

Кроме того, можно точно настроить формат сообщений: добавить время, имя файла,
строку, уровень важности. Это особенно полезно, если лог пишется в файл или
используется в CI. В случае ошибок будет видно не только что пошло не так, но и
где именно, и при каких условиях.

Работа с окружением на низком уровне редко обходится без стандартных библиотек
sys, os, shutil и pathlib. Все они решают разные задачи, и каждая из них дает
удобный доступ к какой-то стороне взаимодействия с операционной системой.

**sys** – один из самых базовых модулей. Он нужен для работы с аргументами
командной строки, завершения программы с нужным кодом или, например,
перенаправления вывода ошибок. Никакой логики, только прямое взаимодействие с
механизмами, которые предоставляет сам интерпретатор.

**os** – это удобная обертка над API операционной системы. Работа с переменными
окружения, запуск внешних процессов, создание директорий, установка прав.

**shutil** предоставляет функции для работы с файлами и директориями, которые
выходят за рамки возможностей os, такие как рекурсивное удаление, копирование и
перемещение.

## Общая структура
Проект состоит из нескольких модулей:

- __main__.py – точка входа в приложение, отвечает за парсинг аргументов
  командной строки, построение параметров вызова bubblewrap;
- conf.py – отвечает за загрузку и интерпретацию конфигурационных файлов, в
  которых задаются дополнительные пути, доступные в изолированной среде;
- path.py – модуль, реализующий функцию расширенного поиска по шаблонам путей с
  использованием переменных окружения и регулярных выражений.

### Основная логика (main.py)
Запуск начинается с проверки наличия bubblewrap в системе – если он отсутствует,
выполнение завершается. Далее парсятся аргументы, среди которых можно указать:

- имя окружения (если не указано, выводится автоматически из имени исполняемого
  файла или программы);
- режим изоляции домашней директории;
- подключение сетевого пространства;
- директории конфигурации и хранилища;
- дополнительные флаги очистки или удаления;
- аргументы которые будут напрямую переданы в bubblewrap (для большей
  гибкости).

Если изоляция ранее не создавалась, под нее создается каталог, в котором, в
зависимости от режима, размещаются либо верхний слой overlayfs, либо привязанный
подкаталог для монтирования. Сбор аргументов bubblewrap происходит поэтапно:
сначала флаги пространств имён, затем базовые монтирования (/, /proc, /dev),
затем – домашний каталог, текущая директория (если указано), runtime-пути, и
пути из конфигурационных файлов. Конфигурация может быть задана как общая
(default.cfg), так и специфичная для конкретного приложения.

После подготовки всех аргументов производится вызов os.execvp, передающий
управление bubblewrap.

### Конфигурация (conf.py)
Загрузка конфигурации построена на двухуровневой модели: если присутствует файл,
специфичный для текущего окружения, он используется в первую очередь. В
противном случае подгружается общий файл. При первом запуске, если ни один файл
не существует, создается шаблон с базовыми runtime-директориями – это минимально
необходимый набор, чтобы GUI-приложения могли запуститься в Wayland-сессии

### path.py
Данный модуль предоставляет собственную реализацию glob функции, позволяющую
интерпретировать шаблоны с переменными окружения и полноценными регулярными
выражениями, обеспечивая гибкость при описании путей. Стандартный поиск путей не
является достаточно гибким – нельзя задать шаблон, который бы разграничивал
имена файлов wayland-1 и wayland-1.conf. Так как под "wayland-*" подойдут оба
файла, а "wayland-*$" ("$" в regex значит конец строки) или "wayland-[0-9]+"
([0-9] - любые символы из промежутка) не поддерживаются.

## Функции
**parse_args()** – данная функция является стандартным подходом при работе с
библиотекой argparse. Она задает аргументы командной строки, настраивает их
параметры и поведение, специальным образом обрабатывает варианты по умолчанию и
введенные значения, а затем возвращает их в удобном объекте.

**check_bwrap()** – простейшая проверка, без которой запуск не имеет смысла.
Убеждается, что bubblewrap установлен в системе, иначе печатает сообщение об
ошибке и прерывает выполнение. bwrap – это единственный внешний бинарник, от
которого зависит wraplify.

**main()** – главная точка входа в приложение. Сначала вызывается check_bwrap()
– без него дальнейшие действия бессмысленны. Затем разбираются аргументы с
помощью parse_args().

После этого начинается формирование аргументов для bubblewrap. Включаются
стандартные неймспейсы (--unshare-*), защита от зомби (--die-with-parent),
монтирование системных директорий (/proc, /dev, /run). Затем добавляется логика,
связанная с домашним каталогом: либо временный tmpfs, либо overlay с верхним
уровнем, либо постоянный bind.

Аналогично добавляются текущая директория и XDG_RUNTIME_DIR, если они нужны.
Дополнительно подгружаются пользовательские бинды из конфигурации через
conf.load_config(). В конце собирается итоговый список аргументов для
bubblewrap, логируются для отладки, и вызывается os.execvp() – фактически,
wraplify само заменяется на bwrap, передав управление изолированному процессу.

**parse_config(config_path: Path)** – открывает указанный конфигурационный файл
и разбирает его по строкам, для обработки которых используется функция glob().
Возвращается множество всех совпавших путей. Это дает пользователю гибкость:
можно указать шаблоны, соответствующие целым классам сокетов или временных
директорий (например, wayland и pipewire).

**load_config(config_path: Path, name: str)** – определяет, какой конфиг
использовать: сначала пробует найти специфический файл для приложения по имени,
если такого нет – откатывается к default.cfg. Возвращает множество путей,
которые затем будут подключены внутрь sandbox-а при запуске.

**sub_env(var: str)** – вспомогательная функция для подстановки переменных
окружения в шаблоне. Используется при разборе строк в конфигурации.

**expandvars(text: str)** – расширяет переменные окружения в переданной строке.
Применяется регулярное выражение для поиска переменных окружения в виде ${NAME}
(используется формат bash переменных) и замены их на соответствующие значения из
os.environ.

**_glob(pattern: str, path: Path, dbg_offset='') -> set[Path]** – функция
рекурсивного сопоставления пути. Работает как pathlib.glob, но с важным
отличием: он использует регулярные выражения вместо wildcard-символов (*, ?).
Каждый уровень пути сопоставляется отдельно, и если совпадение найдено,
происходит углубление в соответствующую директорию. Если на каком-то этапе
возникает PermissionError, он логируется. Дополнительный аргумент dbg_offset
используется исключительно для отладочного вывода – он визуально показывает
глубину рекурсии в логах, добавляя отступы.

**glob(pattern: str) -> set[Path]** – публичная функция модуля. Приводит шаблон
к финальному виду, сначала удаляя лишние слеши и применяя expandvars(), затем
вызывает _glob(), начиная обход с корня файловой системы. Это тот интерфейс,
который используют функции из conf.py, чтобы собрать пути, указанные в
пользовательском конфиге.


# Демонстрация

⁂

## Описание условных обозначений в листингах
Демонстрационные листинги в данной главе имеют следущуюю структуру,
представленную в листинге 1.
Листинг 1 – Структура листинга.
```
[<пользователь>@<имя хоста> <рабочая директория>]<тип пользователя> <команда> # <комментарий>

<вывод команды>
```

Теперь рассмотрим каждый элемент подробнее:

- пользователь - имя пользователя от имени которого исполняется команда;
- имя хоста - имя хоста, в примерах либо "host" - что значит что команда
  исполняется на хостовой (основной) системе, либо "wrap" - значит что команда
  исполняется внутри изолированной среды созданной разработанной утилитой;
- рабочая директория - путь до текущей директории, "~" - это корень домашней
  директории текущего пользователя;
- тип пользователя - либо "$" - обычный пользователь, либо "#" - root
  пользователь;
- команда - текст исполняемой команды;
- комментарий - комментарий к команде;
- вывод команды - результат исполнения команды, возможно многострочный,
  возможно отсутствует.

Дополнительно создадим алиас (alias) для более удобного использования утилиты с
помощью команды `alias wraplify="uvx wraplify"`. Утилита uvx автоматически скачает
пакет с pypi при первом запуске.

## Подготовка стенда
Дальше во всех примерах предполагается, что данная структура файлов и директорий
из листинга 2 присутствует в корне домашней директории пользователя.

Листинг 2 – Команды для создания демонстрационной иерархии директорий и файлов.
```
[user@host ~]$ mkdir -p dir/subdir1
[user@host ~]$ mkdir -p dir/subdir2
[user@host ~]$ mkdir -p dir/subdir3/nested_dir
[user@host ~]$ touch dir/file1.txt
[user@host ~]$ touch dir/file2.log
[user@host ~]$ touch dir/file3.csv
[user@host ~]$ touch dir/subdir1/subfile1.txt
[user@host ~]$ touch dir/subdir1/subfile2.md
[user@host ~]$ touch dir/subdir2/subfile3.json
[user@host ~]$ touch dir/subdir3/subfile4.xml
[user@host ~]$ touch dir/subdir3/nested_dir/nested_file1.txt
[user@host ~]$ touch dir/subdir3/nested_dir/nested_file2.dat
[user@host ~]$ mkdir -p dir/empty_dir
[user@host ~]$ mkdir -p dir/subdir3/another_empty_dir
[user@host ~]$ tree dir
dir
|-- empty_dir
|-- file1.txt
|-- file2.log
|-- file3.csv
|-- subdir1
|   |-- subfile1.txt
|   `-- subfile2.md
|-- subdir2
|   `-- subfile3.json
`-- subdir3
    |-- another_empty_dir
    |-- nested_dir
    |   |-- nested_file1.txt
    |   `-- nested_file2.dat
    `-- subfile4.xml
7 directories, 9 files
[user@host ~]$
```

## Общий принцип
Пример, приведенный в листинге 3, показывает базовую логику автоматического
создания изолированных окружений под каждое запускаемое приложение в
отдельности.

Видно, что в режиме по умолчанию разработанная утилита полностью изолирует
пользовательскую домашнюю директорию. А также сохраняет все изменения отдельно,
для каждого запущенного приложения.

Листинг 3 – Демонстрация общего принципа разных окружений
```
[user@host ~]$ ls           # видим что на хосте присутствует host_file файл
host_file
[user@host ~]$ wraplify bash               # запускаем разработанную утилиту
[user@wrap ~]$ touch wrap_file              # создаем файл внутри контейнера
[user@wrap ~]$ ls            # видим что файла с хоста нет внутри контейнера
wrap_file
[user@wrap ~]$ exit                                  # выходим из контейнера
exit
[user@host ~]$ ls # на хосте по прежнему есть файл host_file и нет wrap_file
host_file
[user@host ~]$ wraplify bash   # повторно запускам утилиту с той же командой
[user@wrap ~]$ ls         # видим файл, который был создан внутри контейнера
wrap_file
[user@wrap ~]$ exit                                  # выходим из контейнера
exit
[user@host ~]$ wraplify sh                  # запускаем уже другую программу
sh-5.2$ ls                                              # никаких файлов нет
sh-5.2$ exit                                         # выходим из контейнера
exit
[user@host ~]$
```

## OverlayFS
Этот пример (листинг 4) демонстрирует работу утилиты в режиме overlayfs, когда
все пользовательские данные по прежнему доступны, но их редактирование и
удаление не оказывает влияния на хостовую файловую систему.

Листинг 4 – Демонстрация overlayfs.
```
[user@host ~]$ wraplify --overlay bash # заходим в изолированное окружение с
                                                        # ключиком --overlay
[user@wrap ~]$ ls                         # видим что папка с хоста на месте
dir
[user@wrap ~]$ find dir -name "*2*" -exec rm -vrf {} \;  # удаляем все файлы
                                                        # содержащие цифру 2
removed 'dir/subdir1/subfile2.md'
removed 'dir/subdir2/subfile3.json'
removed directory 'dir/subdir2'
find: 'dir/subdir2': No such file or directory
removed 'dir/subdir3/nested_dir/nested_file2.dat'
removed 'dir/file2.log'
[user@wrap ~]$ tree dir       # выводим оставщееся содержимое директории dir
dir
|-- empty_dir
|-- file1.txt
|-- file3.csv
|-- subdir1
|   `-- subfile1.txt
`-- subdir3
    |-- another_empty_dir
    |-- nested_dir
    |   `-- nested_file2.dat
    `-- subfile4.xml
6 directories, 5 files
[user@wrap ~]$ exit                                  # выходим из контейнера
exit
[user@host ~]$ tree dir      # и выводим содержимое хостовой директории dir,
                                      # видим что все осталось без изменений
dir
|-- empty_dir
|-- file1.txt
|-- file2.log
|-- file3.csv
|-- subdir1
|   |-- subfile1.txt
|   `-- subfile2.md
|-- subdir2
|   `-- subfile3.json
`-- subdir3
    |-- another_empty_dir
    |-- nested_dir
    |   |-- nested_file1.txt
    |   `-- nested_file2.dat
    `-- subfile4.xml
7 directories, 9 files
[user@host ~]$ tree ~/.local/state/wraplify/bash/   # а все измененные файлы
                                                # хранятся в отдельном месте
/home/user/.local/state/wraplify/bash/
|-- home
|-- upper
|   `-- dir
|   |-- file2.log
|   |-- subdir1
|   |   `-- subfile2.md
|   |-- subdir2
|   `-- subdir3
|       `-- nested_dir
|           `-- nested_file2.dat
`-- work
    `-- work [error opening dir]
9 directories, 4 files
[user@host ~]$
```

Этот пример демонстрирует работу утилиты в режиме overlayfs, когда все
пользовательские данные по прежнему доступны, но их редактирование и удаление не
оказывает влияния на хостовую файловую систему.

Листинг 5 – Демонстрация запуска GUI приложений
```
python -m wraplify firefox
```

![Image Placeholder]()  
Рисунок 1 – Просмотр локальных файлов через firefox

Листинг 6 – Демонстрация бинда текущей директории
```
[user@host ~]$ cd dir/subdir3                  # переходим в поддиректорию
[user@host subdir3]$ wraplify --current-dir bash # заходим в изолированное
                                          # окружение с ключиком --overlay
[user@wrap subdir3]$ ls
another_empty_dir nested_dir subfile4.xml
[user@wrap subdir3]$ tree ~                      # выводим содержимое всей
                                             # пользовательской директории
/home/user
`-- dir
    `-- subdir3
    |-- another_empty_dir
    |-- nested_dir
    |   |-- nested_file1.txt
    |   `-- nested_file2.dat
    `-- subfile4.xml
5 directories, 3 files
[user@wrap subdir3]$ touch file_from_env         # создаем файл находясь в
                                                 # изолированном окружении
[user@wrap subdir3]$ exit                                # выходим из него
exit
[user@host subdir3]$ ls  # и видим что файл создался и на хостовой системе
another_empty_dir file_from_env nested_dir subfile4.xml
[user@wrap subdir3]
```

В данном случае можно видеть, как была смонтирована только рабочяя директория
(вывод команды `tree ~`), и причем напрямую, без overlayfs.

Это означает что все изменения напрямую будут вноситься в хостовую систему, но
только внутри рабочей директории.

Используется данный режим когда нужно перенести в контейнер текущую папку с
хоста, но чтобы все изменения за ее пределами не оказывали влияение на систему.

Листинг 7 – Демонстрация очистки созданных окружений.
```
[user@host ~]$ wraplify --clean-all
Remove directory '/home/vkr/.config/wraplify'? [y/N] y
Remove directory '/home/vkr/.local/state/wraplify'? [y/N] y
[user@host ~]$
```


# Тестирование
Основная задача тестирования – убедиться в том, что процессы, запущенные в
изолированной среде:

- Не могут воздействовать на компоненты хост-системы.
- Лишены возможности эскалации привилегий.
- Ограничены в доступе к файловой системе и системным ресурсам.
- Защищены от попыток выхода за пределы установленных ограничений через
  типичные техники атаки.

Функциональные требования к безопасности программного решения включают в себя:

- Изоляция пространств имён: процессы не должны иметь доступа к пространствам
  процессов, файловых систем и сетевых интерфейсов хост-системы.
- Ограничение привилегий (capabilities): выполнение в рамках ограниченного
  набора возможностей без наличия критических прав (CAP_SYS_ADMIN,
  CAP_SYS_PTRACE, CAP_DAC_READ_SEARCH и других).
- Изоляция файловой системы: изменения, вносимые приложением, должны быть
  ограничены выделенным оверлеем, исключающим модификацию исходной файловой
  структуры хоста.
- Устойчивость к известным методикам атак: система должна противостоять
  эксплойтам, нацеленным на уязвимости в ядре Linux, механизмах изоляции (таких
  как OverlayFS и пространства имён) и обход ограничения возможностей.

⁂


# Доставка
Когда инструмент начинает работать стабильно, его нужно подготовить к
использованию вне локальной среды. Это значит не только обеспечить установку, но
и сделать ее повторяемой: зависимости должны устанавливаться корректно, команды
выполняться одинаково, а окружение не требовать ручной доводки. Даже если
утилита рассчитана на узкий круг задач, от того, как она оформлена и
распространяется, зависит, насколько быстро ее смогут попробовать другие.

Формат распространения выбирается исходя из того, кто и как будет использовать
результат. Иногда достаточно обычного архива с бинарником. В других случаях
удобнее упаковать всё в Python-пакет и выложить в PyPI. А если требуется
зафиксировать окружение и исключить лишние зависимости, подойдёт сборка в
контейнер. Но, к сожалению, последний самый контролируемый вариант для данной
утилиты совершенно не подходит.

## PyPI
PyPI (Python Package Index) – это центральное хранилище для Python-библиотек и
утилит, своего рода каталог, откуда любой может установить пакет с помощью pip.
Это упрощает распространение: достаточно один раз загрузить проект, и он
становится доступен через стандартные инструменты во всех системах, где
установлен Python.

У PyPI есть важное преимущество – его используют по умолчанию. Поэтому если цель
– сделать инструмент доступным другим разработчикам, особенно в экосистеме
Python, публикация туда выглядит естественным выбором. Она не требует настройки
стороннего хранилища, и сам процесс сводится к нескольким командам. Всё, что
нужно – правильно оформить проект: указать метаинформацию, зависимости и путь к
исполняемому скрипту.

Это не единственный способ доставки, но один из самых прямых, когда речь идет о
Python-утилите, которую планируется запускать из командной строки

## Конфигурация пакета
Чтобы опубликовать пакет на PyPI, нужно выполнить несколько базовых требований,
и первое из них – подготовить корректную структуру проекта и метаданные. PyPI
ожидает, что у проекта будет файл pyproject.toml, в котором указано, как его
собирать и что он из себя представляет.

pyproject.toml постепенно вытеснил setup.py и стал основным способом описания
Python-проектов. Причина довольно понятная – со временем в setup.py начинала
появляться не только метаинформация, но и логика, и это мешало его использовать
как универсальный формат. Требовалось что-то более структурированное, что можно
было бы легко читать и обрабатывать автоматически.

Новый формат решает это за счёт разделения обязанностей: вся информация о
проекте – его имя, версия, авторы, список зависимостей – теперь явно задаётся в
одном месте, без смешивания с кодом. При этом pyproject.toml может
использоваться не только setuptools, но и другими инструментами – flit, poetry,
uv, и это делает экосистему более гибкой.

Листинг 8 – Пример минимальной конфигураций проекта
```
[project]
name = "wraplify"
version = "0.2.3"
description = "Wraplify simplifies the process of isolating untrusted code by
providing a user-friendly Python wrapper around bubblewrap"
readme = "README.md"
requires-python = ">=3.13"
dependencies = []
```

Этого достаточно, чтобы pip и другие аналогичные инструменты понимали, как
собрать и установить пакет. Если скрипт предполагается запускать из терминала, в
pyproject.toml можно также указать точку входа – команду, которая будет
устанавливаться как исполняемая, что в данном случае очень удобно:

Листинг 9 – Указание точки входа
```
[project.scripts]
wrapify = "main:main"
```

## Сборка и загрузка пакета
Для публикации на PyPI одного pyproject.toml недостаточно. Помимо описания
проекта, нужен специальным образом подготовленный образ – это не просто архив с
исходниками, а строго оформленный пакет, который должен соответствовать
требованиям Python Packaging Authority. Он представляет собой либо sdist (source
distribution), либо wheel (формат .whl), а чаще – оба варианта одновременно. Это
делается для того, чтобы охватить как можно больше сценариев установки:
исходники можно собрать под специфическую платформу, а колесико (wheel) ставится
сразу, если всё совпадает по окружению.

Формат sdist – это tar.gz-архив с исходным кодом и всей метаинформацией о
пакете. Он дает максимальную гибкость, но требует компиляции на стороне
пользователя при установке, что очевидно, занимает дополнительное время и
требует некоторых вычислительных ресурсов целевой системы. В отличие от него,
wheel – это бинарный формат: предкомпилированный и готовый к установке. Если
пакет не зависит от платформы (например, написан полностью на Python), то wheel
будет универсальным – py3-none-any.

Раньше для процесса публикации приходилось использовать несколько отдельных
инструментов: один для сборки (setuptools, flit, hatch), другой для загрузки
(twine). С недавнего времени всё же это может заменить uv – универсальный
инструмент от команды astral.sh, который упрощает цепочку сборки и публикации.
Он берёт на себя сразу несколько ролей: управляет зависимостями, собирает проект
и публикует его. uv стремится быть не только быстрее, но и проще: меньше внешних
конфигураций, меньше подводных камней, больше предсказуемости. Он работает
напрямую с pyproject.toml и подходит для тех случаев, когда не требуется тонкая
настройка процесса, а нужно просто получить работающее решение без лишних
промежуточных шагов.


# Заключение
⁂


# Список использованных источников
⁂
